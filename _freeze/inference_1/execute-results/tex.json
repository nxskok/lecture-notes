{
  "hash": "61ffcfd8e855a8e9b0dc424bf4203301",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical inference: one and two-sample t-tests\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Statistical Inference and Science\n\n-   Previously: descriptive statistics. \"Here are data; what do they\n    say?\".\n-   May need to take some action based on information in data.\n-   Or want to generalize beyond data (sample) to larger world\n    (population).\n-   Science: first guess about how world works.\n-   Then collect data, by sampling.\n-   Is guess correct (based on data) for whole world, or not?\n\n## Sample data are imperfect\n\n-   Sample data never entirely represent what you're observing.\n-   There is always random error present.\n-   Thus you can never be entirely certain about your conclusions.\n-   The Toronto Blue Jays' average home attendance in part of 2015\n    season was 25,070 (up to May 27 2015, from baseball-reference.com).\n-   Does that mean the attendance at every game was exactly 25,070?\n    Certainly not. Actual attendance depends on many things, eg.:\n    -   how well the Jays are playing\n    -   the opposition\n    -   day of week\n    -   weather\n    -   random chance\n\n## Packages for this section\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n## Reading the attendances\n\n...as a `.csv` file:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/jays15-home.csv\"\njays <- read_csv(my_url) \njays\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 25 x 21\n     row  game date   box   team  venue opp   result  runs Oppruns innings wl   \n   <dbl> <dbl> <chr>  <chr> <chr> <lgl> <chr> <chr>  <dbl>   <dbl>   <dbl> <chr>\n 1    82     7 Monda~ boxs~ TOR   NA    TBR   L          1       2      NA 4-3  \n 2    83     8 Tuesd~ boxs~ TOR   NA    TBR   L          2       3      NA 4-4  \n 3    84     9 Wedne~ boxs~ TOR   NA    TBR   W         12       7      NA 5-4  \n 4    85    10 Thurs~ boxs~ TOR   NA    TBR   L          2       4      NA 5-5  \n 5    86    11 Frida~ boxs~ TOR   NA    ATL   L          7       8      NA 5-6  \n 6    87    12 Satur~ boxs~ TOR   NA    ATL   W-wo       6       5      10 6-6  \n 7    88    13 Sunda~ boxs~ TOR   NA    ATL   L          2       5      NA 6-7  \n 8    89    14 Tuesd~ boxs~ TOR   NA    BAL   W         13       6      NA 7-7  \n 9    90    15 Wedne~ boxs~ TOR   NA    BAL   W          4       2      NA 8-7  \n10    91    16 Thurs~ boxs~ TOR   NA    BAL   W          7       6      NA 9-7  \n# i 15 more rows\n# i 9 more variables: position <dbl>, gb <chr>, winner <chr>, loser <chr>,\n#   save <chr>, `game time` <time>, Daynight <chr>, attendance <dbl>,\n#   streak <chr>\n```\n\n\n:::\n:::\n\n\n\n\n## Another way\n\n-   This is a \"big\" data set: only 25 observations, but a lot of\n    *variables*.\n\n-   To see the first few values in all the variables, can also use\n    `glimpse`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(jays)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 25\nColumns: 21\n$ row         <dbl> 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96~\n$ game        <dbl> 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 27, 28, 29, 30, 31, 3~\n$ date        <chr> \"Monday, Apr 13\", \"Tuesday, Apr 14\", \"Wednesday, Apr 15\", ~\n$ box         <chr> \"boxscore\", \"boxscore\", \"boxscore\", \"boxscore\", \"boxscore\"~\n$ team        <chr> \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"T~\n$ venue       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n$ opp         <chr> \"TBR\", \"TBR\", \"TBR\", \"TBR\", \"ATL\", \"ATL\", \"ATL\", \"BAL\", \"B~\n$ result      <chr> \"L\", \"L\", \"W\", \"L\", \"L\", \"W-wo\", \"L\", \"W\", \"W\", \"W\", \"W\", ~\n$ runs        <dbl> 1, 2, 12, 2, 7, 6, 2, 13, 4, 7, 3, 3, 5, 7, 7, 3, 10, 2, 3~\n$ Oppruns     <dbl> 2, 3, 7, 4, 8, 5, 5, 6, 2, 6, 1, 6, 1, 0, 1, 6, 6, 3, 4, 4~\n$ innings     <dbl> NA, NA, NA, NA, NA, 10, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n$ wl          <chr> \"4-3\", \"4-4\", \"5-4\", \"5-5\", \"5-6\", \"6-6\", \"6-7\", \"7-7\", \"8~\n$ position    <dbl> 2, 3, 2, 4, 4, 3, 4, 2, 2, 1, 4, 5, 3, 3, 3, 3, 5, 5, 5, 5~\n$ gb          <chr> \"1\", \"2\", \"1\", \"1.5\", \"2.5\", \"1.5\", \"1.5\", \"2\", \"1\", \"Tied~\n$ winner      <chr> \"Odorizzi\", \"Geltz\", \"Buehrle\", \"Archer\", \"Martin\", \"Cecil~\n$ loser       <chr> \"Dickey\", \"Castro\", \"Ramirez\", \"Sanchez\", \"Cecil\", \"Marimo~\n$ save        <chr> \"Boxberger\", \"Jepsen\", NA, \"Boxberger\", \"Grilli\", NA, \"Gri~\n$ `game time` <time> 02:30:00, 03:06:00, 03:02:00, 03:00:00, 03:09:00, 02:41:0~\n$ Daynight    <chr> \"N\", \"N\", \"N\", \"N\", \"N\", \"D\", \"D\", \"N\", \"N\", \"N\", \"N\", \"N\"~\n$ attendance  <dbl> 48414, 17264, 15086, 14433, 21397, 34743, 44794, 14184, 15~\n$ streak      <chr> \"-\", \"--\", \"+\", \"-\", \"--\", \"+\", \"-\", \"+\", \"++\", \"+++\", \"+\"~\n```\n\n\n:::\n:::\n\n\n\n\n## Attendance histogram\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(jays, aes(x = attendance)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](inference_1_files/figure-beamer/inference-1-R-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   Attendances have substantial variability, ranging from just over\n    10,000 to around 50,000.\n-   Distribution somewhat skewed to right (but no outliers).\n-   These are a sample of \"all possible games\" (or maybe \"all possible\n    games played in April and May\"). What can we say about mean\n    attendance in all possible games based on this evidence?\n-   Think about:\n    -   Confidence interval\n    -   Hypothesis test.\n\n## Getting CI for mean attendance\n\n-   `t.test` function does CI and test. Look at CI first:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n\n\n-   From 20,500 to 29,600.\n\n## Or, 90% CI\n\n-   by including a value for conf.level:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance, conf.level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n90 percent confidence interval:\n 21303.93 28836.39\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n\n\n-   From 21,300 to 28,800. (Shorter, as it should be.)\n\n## Comments\n\n-   Need to say \"column attendance within data frame `jays`\" using \\$.\n-   95% CI from about 20,000 to about 30,000.\n-   Not estimating mean attendance well at all!\n-   Generally want confidence interval to be shorter, which happens if:\n    -   SD smaller\n    -   sample size bigger\n    -   confidence level smaller\n-   Last one is a cheat, really, since reducing confidence level\n    increases chance that interval won't contain pop. mean at all!\n\n## Another way to access data frame columns\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(jays, t.test(attendance))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n\n\n## Hypothesis test\n\n-   CI answers question \"what is the mean?\"\n-   Might have a value $\\mu$ in mind for the mean, and question \"Is the\n    mean equal to $\\mu$, or not?\"\n-   For example, 2014 average attendance was 29,327.\n-   \"Is the mean this?\" answered by **hypothesis test**.\n-   Value being assessed goes in **null hypothesis**: here,\n    $H_0 : \\mu = 29327$.\n-   **Alternative hypothesis** says how null might be wrong, eg.\n    $H_a : \\mu \\ne 29327$.\n-   Assess evidence against null. If that evidence strong enough,\n    *reject null hypothesis;* if not, *fail to reject null hypothesis*\n    (sometimes *retain null*).\n-   Note asymmetry between null and alternative, and utter absence of\n    word \"accept\".\n\n## $\\alpha$ and errors\n\n-   Hypothesis test ends with decision:\n    -   reject null hypothesis\n    -   do not reject null hypothesis.\n-   but decision may be wrong:\n\n|                | Decision          |                 |\n|----------------|-------------------|-----------------|\n| **Truth**      | **Do not reject** | **reject null** |\n| **Null true**  | Correct           | Type I error    |\n| **Null false** | Type II error     | Correct         |\n\n-   Either type of error is bad, but for now focus on controlling Type I\n    error: write $\\alpha$ = P(type I error), and devise test so that\n    $\\alpha$ small, typically 0.05.\n-   That is, **if null hypothesis true**, have only small chance to\n    reject it (which would be a mistake).\n-   Worry about type II errors later (when we consider power of test).\n\n## Why 0.05? This man.\n\n::: columns\n::: {.column width=\"40%\"}\n![](fisher.png)\n:::\n\n::: {.column width=\"60%\"}\n-   analysis of variance\n-   Fisher information\n-   Linear discriminant analysis\n-   Fisher's $z$-transformation\n-   Fisher-Yates shuffle\n-   Behrens-Fisher problem\n\nSir Ronald A. Fisher, 1890--1962.\n:::\n:::\n\n## Why 0.05? (2)\n\n-   From The Arrangement of Field Experiments (1926):\n\n![](fisher1.png){width=\"200%\"}\n\n-   and\n\n![](fisher2.png){width=\"200%\"}\n\n## Three steps:\n\n-   from data to test statistic\n    -   how far are data from null hypothesis\n-   from test statistic to P-value\n    -   how likely are you to see \"data like this\" **if the null\n        hypothesis is true**\n-   from P-value to decision\n    -   reject null hypothesis if P-value small enough, fail to reject\n        it otherwise\n\n## Using `t.test`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance, mu=29327)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = -1.9338, df = 24, p-value = 0.06502\nalternative hypothesis: true mean is not equal to 29327\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n\n\n-   See test statistic $-1.93$, P-value 0.065.\n-   Do not reject null at $\\alpha=0.05$: no evidence that mean\n    attendance has changed.\n\n## Assumptions\n\n-   Theory for $t$-test: assumes normally-distributed data.\n-   What actually matters is sampling distribution of sample mean: if\n    this is approximately normal, $t$-test is OK, even if data\n    distribution is not normal.\n-   Central limit theorem: if sample size large, sampling distribution\n    approx. normal even if data distribution somewhat non-normal.\n-   So look at shape of data distribution, and make a call about whether\n    it is normal enough, given the sample size.\n\n## Blue Jays attendances again:\n\n-   You might say that this is not normal enough for a sample size of\n    $n = 25$, in which case you don't trust the $t$-test result:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(jays, aes(x = attendance)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](inference_1_files/figure-beamer/inference-1-R-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Another example: learning to read\n\n-   You devised new method for teaching children to read.\n-   Guess it will be more effective than current methods.\n-   To support this guess, collect data.\n-   Want to generalize to \"all children in Canada\".\n-   So take random sample of all children in Canada.\n-   Or, argue that sample you actually have is \"typical\" of all children\n    in Canada.\n-   Randomization (1): whether or not a child in sample or not has\n    nothing to do with anything else about that child.\n-   Randomization (2): randomly choose whether each child gets new\n    reading method (t) or standard one (c).\n\n## Reading in data\n\n-   File at <http://ritsokiguess.site/datafiles/drp.txt>.\n-   Proper reading-in function is `read_delim` (check file to see)\n-   Read in thus:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/drp.txt\"\nkids <- read_delim(my_url,\" \")\n```\n:::\n\n\n\n\n## The data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 44 x 2\n   group score\n   <chr> <dbl>\n 1 t        24\n 2 t        61\n 3 t        59\n 4 t        46\n 5 t        43\n 6 t        44\n 7 t        52\n 8 t        43\n 9 t        58\n10 t        67\n# i 34 more rows\n```\n\n\n:::\n:::\n\n\n\n\nIn `group`, `t` is \"treatment\" (the new reading method) and `c` is\n\"control\" (the old one).\n\n## Boxplots\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kids, aes(x = group, y = score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](inference_1_files/figure-beamer/inference-1-R-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Two kinds of two-sample t-test\n\n-   pooled (derived in B57):\n    $t = { \\bar{x}_1 - \\bar{x}_2 \\over s_p \\sqrt{(1 / n_1) + (1 / n_2)}}$,\n    -   where\n        $s_p^2 = {(n_1 - 1) s_1^2 + (n_2 - 1)s_2^2 \\over n_1 + n_2 -2}$\n-   Welch-Satterthwaite:\n    $t = {\\bar{x}_1 - \\bar{x}_2 \\over \\sqrt {{s_1^2 / n_1} + {s_2^2 / n_2}}}$\n    -   this $t$ does not have exact $t$-distribution, but is approx $t$\n        with non-integer df.\n\n## Two kinds of two-sample t-test\n\n-   Do the two groups have same spread (SD, variance)?\n    -   If yes (shaky assumption here), can use pooled t-test.\n    -   If not, use Welch-Satterthwaite t-test (safe).\n-   Pooled test derived in STAB57 (easier to derive).\n-   Welch-Satterthwaite is test used in STAB22 and is generally safe.\n-   Assess (approx) equality of spreads using boxplot.\n\n## The (Welch-Satterthwaite) t-test\n\n-   `c` (control) before `t` (treatment) alphabetically, so proper\n    alternative is \"less\".\n-   R does Welch-Satterthwaite test by default\n-   Answer to \"does the new reading program really help?\"\n-   (in a moment) how to get R to do pooled test?\n\n## Welch-Satterthwaite\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids, alternative = \"less\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  score by group\nt = -2.3109, df = 37.855, p-value = 0.01319\nalternative hypothesis: true difference in means between group c and group t is less than 0\n95 percent confidence interval:\n      -Inf -2.691293\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n\n\n## The pooled t-test\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids, \n       alternative = \"less\", var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  score by group\nt = -2.2666, df = 42, p-value = 0.01431\nalternative hypothesis: true difference in means between group c and group t is less than 0\n95 percent confidence interval:\n      -Inf -2.567497\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n\n\n## Two-sided test; CI\n\n-   To do 2-sided test, leave out `alternative`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  score by group\nt = -2.3109, df = 37.855, p-value = 0.02638\nalternative hypothesis: true difference in means between group c and group t is not equal to 0\n95 percent confidence interval:\n -18.67588  -1.23302\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n\n\n## Comments:\n\n-   P-values for pooled and Welch-Satterthwaite tests very similar (even\n    though the pooled test seemed inferior): 0.013 vs.Â 0.014.\n-   Two-sided test also gives CI: new reading program increases average\n    scores by somewhere between about 1 and 19 points.\n-   Confidence intervals inherently two-sided, so do 2-sided test to get\n    them.\n\n## Jargon for testing\n\n-   Alternative hypothesis: what we are trying to prove (new reading\n    program is effective).\n-   Null hypothesis: \"there is no difference\" (new reading program no\n    better than current program). Must contain \"equals\".\n-   One-sided alternative: trying to prove better (as with reading\n    program).\n-   Two-sided alternative: trying to prove different.\n-   Test statistic: something expressing difference between data and\n    null (eg. difference in sample means, $t$ statistic).\n-   P-value: probability of observing test statistic value as extreme or\n    more extreme, if null is true.\n-   Decision: either reject null hypothesis or do not reject null\n    hypothesis. **Never \"accept\"**.\n\n## Logic of testing\n\n-   Work out what would happen if null hypothesis were true.\n-   Compare to what actually did happen.\n-   If these are too far apart, conclude that null hypothesis is not\n    true after all. (Be guided by P-value.)\n-   As applied to our reading programs:\n    -   If reading programs equally good, expect to see a difference in\n        means close to 0.\n    -   Mean reading score was 10 higher for new program.\n    -   Difference of 10 was unusually big (P-value small from t-test).\n        So conclude that new reading program is effective.\n-   Nothing here about what happens if null hypothesis is false. This is\n    power and type II error probability.\n",
    "supporting": [
      "inference_1_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}