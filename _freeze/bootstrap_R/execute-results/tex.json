{
  "hash": "4beaef5c4cb18a2d961f99e34b4f8cc1",
  "result": {
    "markdown": "---\ntitle: \"Bootstrap for sampling distribution of sample mean\"\n---\n\n\n\n## Assessing assumptions\n\n-   Our $t$-tests assume normality of variable being tested\n-   but, Central Limit Theorem says that normality matters less if\n    sample is \"large\"\n-   in practice \"approximate normality\" is enough, but how do we assess\n    whether what we have is normal enough?\n-   so far, use histogram/boxplot and make a call, allowing for sample\n    size.\n\n## What actually has to be normal\n\n-   is: **sampling distribution of sample mean**\n-   the distribution of sample mean over *all possible samples*\n-   but we only have *one* sample!\n-   Idea: assume our sample is representative of the population, and\n    draw samples from our sample (!), with replacement.\n-   This gives an idea of what different samples from the population\n    might look like.\n-   Called *bootstrap*, after expression \"to pull yourself up by your\n    own bootstraps\".\n\n## Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n## Blue Jays attendances\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\njays$attendance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 48414 17264 15086 14433 21397 34743 44794 14184 15606 18581 19217 21519\n[13] 21312 30430 42917 42419 29306 15062 16402 19014 21195 33086 37929 15168\n[25] 17276\n```\n:::\n:::\n\n\n\n-   A bootstrap sample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- sample(jays$attendance, replace = TRUE)\ns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 21195 34743 21312 44794 16402 19014 34743 21195 17264 18581 19014 19217\n[13] 34743 19217 14433 15062 16402 15062 34743 15062 15086 15168 15086 48414\n[25] 30430\n```\n:::\n:::\n\n\n\n-   It is easier to see what is happening if we sort both the actual\n    attendances and the bootstrap sample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort(jays$attendance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 14184 14433 15062 15086 15168 15606 16402 17264 17276 18581 19014 19217\n[13] 21195 21312 21397 21519 29306 30430 33086 34743 37929 42419 42917 44794\n[25] 48414\n```\n:::\n\n```{.r .cell-code}\nsort(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 14433 15062 15062 15062 15086 15086 15168 16402 16402 17264 18581 19014\n[13] 19014 19217 19217 21195 21195 21312 30430 34743 34743 34743 34743 44794\n[25] 48414\n```\n:::\n:::\n\n\n\n## Getting mean of bootstrap sample\n\n-   A bootstrap sample is same size as original, but contains repeated\n    values (eg. 15062) and missing ones (42917).\n-   We need the mean of our bootstrap sample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 23055.28\n```\n:::\n:::\n\n\n\n-   This is a little different from the mean of our actual sample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(jays$attendance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 25070.16\n```\n:::\n:::\n\n\n\n-   Want a sense of how the sample mean might vary, if we were able to\n    take repeated samples from our population.\n-   Idea: take lots of *bootstrap* samples, and see how *their* sample\n    means vary.\n\n## Setting up bootstrap sampling\n\n-   Begin by setting up a dataframe that contains a row for each\n    bootstrap sample. I usually call this column `sim`. Do just 4 to get\n    the idea:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 1\n    sim\n  <int>\n1     1\n2     2\n3     3\n4     4\n```\n:::\n:::\n\n\n\n## Drawing the bootstrap samples\n\n-   Then set up to work one row at a time, and draw a bootstrap sample\n    of the attendances in each row:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:4) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(jays$attendance, replace = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 2\n# Rowwise: \n    sim sample    \n  <int> <list>    \n1     1 <dbl [25]>\n2     2 <dbl [25]>\n3     3 <dbl [25]>\n4     4 <dbl [25]>\n```\n:::\n:::\n\n\n\n-   Each row of our dataframe contains *all* of a bootstrap sample of 25\n    observations drawn with replacement from the attendances.\n\n## Sample means\n\n-   Find the mean of each sample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:4) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(jays$attendance, replace = TRUE))) %>%   \n  mutate(my_mean = mean(sample))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 3\n# Rowwise: \n    sim sample     my_mean\n  <int> <list>       <dbl>\n1     1 <dbl [25]>  28472.\n2     2 <dbl [25]>  28648.\n3     3 <dbl [25]>  23329.\n4     4 <dbl [25]>  24808.\n```\n:::\n:::\n\n\n\n-   These are (four simulated values of) the bootstrapped sampling\n    distribution of the sample mean.\n\n## Make a histogram of them\n\n-   rather pointless here, but to get the idea:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:4) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(jays$attendance, replace = TRUE))) %>% \n  mutate(my_mean = mean(sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 3)  -> g\n```\n:::\n\n\n\n## The (pointless) histogram\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](bootstrap_R_files/figure-beamer/bootstrap-R-10-1.pdf)\n:::\n:::\n\n\n\n## Now do again with a decent number of bootstrap samples\n\n-   say 1000, and put a decent number of bins on the histogram also:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(jays$attendance, replace = TRUE))) %>% \n  mutate(my_mean = mean(sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 10) -> g\n```\n:::\n\n\n\n## The (better) histogram\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](bootstrap_R_files/figure-beamer/bootstrap-R-12-1.pdf)\n:::\n:::\n\n\n\n## Comments\n\n-   This is very close to normal\n-   The bootstrap says that the sampling distribution of the sample mean\n    is close to normal, even though the distribution of the data is not\n-   A sample size of 25 is big enough to overcome the skewness that we\n    saw\n-   This is the Central Limit Theorem in practice\n-   It is surprisingly powerful.\n-   Thus, the $t$-test is actually perfectly good here.\n\n## Comments on the code 1/2\n\n-   You might have been wondering about this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:4) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(jays$attendance, replace = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 2\n# Rowwise: \n    sim sample    \n  <int> <list>    \n1     1 <dbl [25]>\n2     2 <dbl [25]>\n3     3 <dbl [25]>\n4     4 <dbl [25]>\n```\n:::\n:::\n\n\n\n## Comments on the code 2/2\n\n-   how did we squeeze all 25 sample values into one cell?\n    -   sample is a so-called \"list-column\" that can contain anything.\n-   why did we have to put `list()` around the `sample()`?\n    -   because `sample` produces a collection of numbers, not just a\n        single one\n    -   the `list()` signals this: \"make a list-column of samples\".\n\n## Two samples\n\n-   Assumption: *both* samples are from a normal distribution.\n-   In this case, each sample should be \"normal enough\" given its sample\n    size, since Central Limit Theorem will help.\n-   Use bootstrap on each group independently, as above.\n\n## Kids learning to read\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 44 x 2\n   group score\n   <chr> <dbl>\n 1 t        24\n 2 t        61\n 3 t        59\n 4 t        46\n 5 t        43\n 6 t        44\n 7 t        52\n 8 t        43\n 9 t        58\n10 t        67\n# i 34 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kids, aes(x=group, y=score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](bootstrap_R_files/figure-beamer/bootstrap-R-15-1.pdf)\n:::\n:::\n\n\n\n## Getting just the control group\n\n-   Use `filter` to select rows where something is true:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids %>% filter(group==\"c\") -> controls\ncontrols\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 23 x 2\n   group score\n   <chr> <dbl>\n 1 c        42\n 2 c        33\n 3 c        46\n 4 c        37\n 5 c        43\n 6 c        41\n 7 c        10\n 8 c        42\n 9 c        55\n10 c        19\n# i 13 more rows\n```\n:::\n:::\n\n\n\n## Bootstrap these\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(controls$score, replace = TRUE))) %>% \n  mutate(my_mean = mean(sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 10) \n```\n\n::: {.cell-output-display}\n![](bootstrap_R_files/figure-beamer/bootstrap-R-17-1.pdf)\n:::\n:::\n\n\n\n## ... and the treatment group:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids %>% filter(group==\"t\") -> treats\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(treats$score, replace = TRUE))) %>% \n  mutate(my_mean = mean(sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 15) \n```\n\n::: {.cell-output-display}\n![](bootstrap_R_files/figure-beamer/bootstrap-R-19-1.pdf)\n:::\n:::\n\n\n\n## Comments\n\n-   sampling distributions of sample means both look pretty normal,\n    though treatment group is a tiny bit left-skewed\n-   as we thought, no problems with our two-sample $t$ at all.\n",
    "supporting": [
      "bootstrap_R_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}