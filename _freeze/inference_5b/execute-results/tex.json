{
  "hash": "331ea71080f4994788932be05d81ec7d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analysis of variance\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(smmr)\nlibrary(PMCMRplus)\n```\n:::\n\n\n\n\n## Jumping rats\n\n-   Link between exercise and healthy bones (many studies).\n-   Exercise stresses bones and causes them to get stronger.\n-   Study (Purdue): effect of jumping on bone density of growing rats.\n-   30 rats, randomly assigned to 1 of 3 treatments:\n    -   No jumping (control)\n    -   Low-jump treatment (30 cm)\n    -   High-jump treatment (60 cm)\n-   8 weeks, 10 jumps/day, 5 days/week.\n-   Bone density of rats (mg/cm$^3$) measured at end.\n\n## Jumping rats 2/2\n\n-   See whether larger amount of exercise (jumping) went with higher\n    bone density.\n-   Random assignment: rats in each group similar in all important ways.\n-   So entitled to draw conclusions about cause and effect.\n\n## Reading the data\n\nValues separated by spaces:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/jumping.txt\"\nrats <- read_delim(my_url,\" \")\n```\n:::\n\n\n\n\n## The data (some random rows)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rats %>% slice_sample(n=10)\nrats\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 x 2\n   group   density\n   <chr>     <dbl>\n 1 Control     611\n 2 Control     621\n 3 Control     614\n 4 Control     593\n 5 Control     593\n 6 Control     653\n 7 Control     600\n 8 Control     554\n 9 Control     603\n10 Control     569\n# i 20 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Boxplots\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rats, aes(y=density, x=group)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](inference_5b_files/figure-beamer/inference-5-R-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Or, arranging groups in data (logical) order\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rats, aes(y=density, x=fct_inorder(group))) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](inference_5b_files/figure-beamer/inference-5-R-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Analysis of Variance\n\n-   Comparing \\> 2 groups of independent observations (each rat only\n    does one amount of jumping).\n-   Standard procedure: analysis of variance (ANOVA).\n-   Null hypothesis: all groups have same mean.\n-   Alternative: \"not all means the same\", at least one is different\n    from others.\n\n## Testing: ANOVA in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrats.aov <- aov(density~group,data=rats)\nsummary(rats.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)   \ngroup        2   7434    3717   7.978 0.0019 **\nResiduals   27  12579     466                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n-   Usual ANOVA table, small P-value: significant result.\n-   Conclude that the mean bone densities are not all equal.\n-   Reject null, but not very useful finding.\n\n## Which groups are different from which?\n\n-   ANOVA really only answers half our questions: it says \"there are\n    differences\", but doesn't tell us which groups different.\n-   One possibility (not the best): compare all possible pairs of\n    groups, via two-sample t.\n-   First pick out each group:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrats %>% filter(group==\"Control\") -> controls\nrats %>% filter(group==\"Lowjump\") -> lows\nrats %>% filter(group==\"Highjump\") -> highs\n```\n:::\n\n\n\n\n## Control vs. low\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(controls$density, lows$density)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  controls$density and lows$density\nt = -1.0761, df = 16.191, p-value = 0.2977\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -33.83725  11.03725\nsample estimates:\nmean of x mean of y \n    601.1     612.5 \n```\n\n\n:::\n:::\n\n\n\n\nNo sig. difference here.\n\n## Control vs. high\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(controls$density, highs$density)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  controls$density and highs$density\nt = -3.7155, df = 14.831, p-value = 0.002109\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -59.19139 -16.00861\nsample estimates:\nmean of x mean of y \n    601.1     638.7 \n```\n\n\n:::\n:::\n\n\n\n\nThese are different.\n\n## Low vs. high\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(lows$density, highs$density)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  lows$density and highs$density\nt = -3.2523, df = 17.597, p-value = 0.004525\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -43.15242  -9.24758\nsample estimates:\nmean of x mean of y \n    612.5     638.7 \n```\n\n\n:::\n:::\n\n\n\n\nThese are different too.\n\n## But...\n\n-   We just did 3 tests instead of 1.\n-   So we have given ourselves 3 chances to reject $H_0:$ all means\n    equal, instead of 1.\n-   Thus $\\alpha$ for this combined test is not 0.05.\n\n## John W. Tukey\n\n::: columns\n::: {.column width=\"40%\"}\n![](John_Tukey.jpg){width=\"200\"}\n:::\n\n::: {.column width=\"60%\"}\n-   American statistician, 1915--2000\n-   Big fan of exploratory data analysis\n-   Popularized boxplot\n-   Invented \"honestly significant differences\"\n-   Invented jackknife estimation\n-   Coined computing term \"bit\"\n-   Co-inventor of Fast Fourier Transform\n:::\n:::\n\n## Honestly Significant Differences\n\n-   Compare several groups with one test, telling you which groups\n    differ from which.\n-   Idea: if all population means equal, find distribution of highest\n    sample mean minus lowest sample mean.\n-   Any means unusually different compared to that declared\n    significantly different.\n\n## Tukey on rat data\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrats.aov <- aov(density~group, data = rats)\nTukeyHSD(rats.aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = density ~ group, data = rats)\n\n$group\n                  diff       lwr       upr     p adj\nHighjump-Control  37.6  13.66604 61.533957 0.0016388\nLowjump-Control   11.4 -12.53396 35.333957 0.4744032\nLowjump-Highjump -26.2 -50.13396 -2.266043 0.0297843\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n-   Again conclude that bone density for highjump group significantly\n    higher than for other two groups.\n\n## Why Tukey's procedure better than all t-tests\n\nLook at P-values for the two tests:\n\n```         \nComparison        Tukey    t-tests\n----------------------------------\nHighjump-Control 0.0016     0.0021\nLowjump-Control  0.4744     0.2977\nLowjump-Highjump 0.0298     0.0045\n```\n\n-   Tukey P-values (mostly) higher.\n-   Proper adjustment for doing three t-tests at once, not just one in\n    isolation.\n\n## Checking assumptions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rats,aes(y = density, x = fct_inorder(group)))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](inference_5b_files/figure-beamer/inference-5-R-21-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nAssumptions:\n\n-   Normally distributed data within each group\n-   with equal group SDs.\n\n## Normal quantile plots by group\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rats, aes(sample = density)) + stat_qq() + \n  stat_qq_line() + facet_wrap( ~ group)\n```\n\n::: {.cell-output-display}\n![](inference_5b_files/figure-beamer/inference-5-R-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## The assumptions\n\n-   Normally-distributed data within each group\n-   Equal group SDs.\n-   These are shaky here because:\n    -   control group has outliers\n    -   highjump group appears to have less spread than others.\n-   Possible remedies (in general):\n    -   Transformation of response (usually works best when SD increases\n        with mean)\n    -   If normality OK but equal spreads not, can use Welch ANOVA.\n        (Regular ANOVA like pooled t-test; Welch ANOVA like\n        Welch-Satterthwaite t-test.)\n    -   Can also use Mood's Median Test (see over). This works for any\n        number of groups.\n\n## Mood's median for multiple groups\n\n-   Find median of all bone densities, regardless of group\n\n-   Count up how many observations in each group above or below overall\n    median\n    \n- Test association between group and above/below\n\n-   Mood's `median_test` (over).\n\n## Mood's median test here\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian_test(rats, density, group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$grand_median\n[1] 621.5\n\n$table\n          above\ngroup      above below\n  Control      1     9\n  Highjump    10     0\n  Lowjump      4     6\n\n$test\n       what        value\n1 statistic 1.680000e+01\n2        df 2.000000e+00\n3   P-value 2.248673e-04\n```\n\n\n:::\n:::\n\n\n\n\n## Comments\n\n-   No doubt that medians differ between groups (not all same).\n-   This test is equivalent of $F$-test, not of Tukey.\n-   To determine which groups differ from which, can compare all\n    possible pairs of groups via (2-sample) Mood's median tests, then\n    adjust P-values by multiplying by number of 2-sample Mood tests done\n    (Bonferroni):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairwise_median_test(rats, density, group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 4\n  g1       g2        p_value adj_p_value\n  <chr>    <chr>       <dbl>       <dbl>\n1 Control  Highjump 0.000148    0.000443\n2 Control  Lowjump  0.371       1       \n3 Highjump Lowjump  0.371       1       \n```\n\n\n:::\n:::\n\n\n\n\n-   Now, lowjump-highjump difference no longer significant.\n\n## Welch ANOVA\n\n-   For these data, Mood's median test probably best because we doubt\n    both normality and equal spreads.\n-   When normality OK but spreads differ, Welch ANOVA way to go.\n-   Welch ANOVA done by `oneway.test` as shown (for illustration):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noneway.test(density~group, data=rats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne-way analysis of means (not assuming equal variances)\n\ndata:  density and group\nF = 8.8164, num df = 2.000, denom df = 17.405, p-value = 0.002268\n```\n\n\n:::\n:::\n\n\n\n\n-   P-value very similar, as expected.\n-   Appropriate Tukey-equivalent here called Games-Howell.\n\n## Games-Howell\n\n-   Lives in package `PMCMRplus`. Install first.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gamesHowellTest(density ~ group, data = rats)\ngamesHowellTest(density ~ factor(group), data = rats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Control Highjump\nHighjump 0.0056  -       \nLowjump  0.5417  0.0120  \n```\n\n\n:::\n:::\n\n\n\n\nCareful: explanatory must be `factor` (so commented-out line does not work).\n\n## Deciding which test to do\n\nFor two or more samples:\n\n![](testflow.png)\n",
    "supporting": [
      "inference_5b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}