{
  "hash": "eb23e64f35638000b628226ffd2fbbdd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Case study: asphalt\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## The asphalt data\n\n-   31 asphalt pavements prepared under different conditions. How does\n    quality of pavement depend on these?\n-   Variables:\n    -   `pct.a.surf` Percentage of asphalt in surface layer\n    -   `pct.a.base` Percentage of asphalt in base layer\n    -   `fines` Percentage of fines in surface layer\n    -   `voids` Percentage of voids in surface layer\n    -   `rut.depth` Change in rut depth per million vehicle passes\n    -   `viscosity` Viscosity of asphalt\n    -   `run` 2 data collection periods: 1 for run 1, 0 for run 2.\n-   `rut.depth` response. Depends on other variables, how?\n\n## Packages for this section\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS, exclude = \"select\")\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(leaps)\n```\n:::\n\n\n\n\nMake sure to load `MASS` before `tidyverse` (for annoying technical\nreasons), or to load `MASS` excluding its `select` (as above).\n\n## Getting set up\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/asphalt.txt\"\nasphalt <- read_delim(my_url, \" \")\n```\n:::\n\n\n\n\n-   Quantitative variables with one response: multiple regression.\n-   Some issues here that don't come up in \"simple\" regression; handle\n    as we go. (STAB27/STAC67 ideas.)\n\n## The data (some)\n\n\\small\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 31 x 7\n   pct.a.surf pct.a.base fines voids rut.depth viscosity   run\n        <dbl>      <dbl> <dbl> <dbl>     <dbl>     <dbl> <dbl>\n 1       4.68       4.87   8.4  4.92      6.75      2.8      1\n 2       5.19       4.5    6.5  4.56     13         1.4      1\n 3       4.82       4.73   7.9  5.32     14.8       1.4      1\n 4       4.85       4.76   8.3  4.86     12.6       3.3      1\n 5       4.86       4.95   8.4  3.78      8.25      1.7      1\n 6       5.16       4.45   7.4  4.40     10.7       2.9      1\n 7       4.82       5.05   6.8  4.87      7.28      3.7      1\n 8       4.86       4.7    8.6  4.83     12.7       1.7      1\n 9       4.78       4.84   6.7  4.86     12.6       0.92     1\n10       5.16       4.76   7.7  4.03     20.6       0.68     1\n# i 21 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Plotting response \"rut depth\" against everything else\n\nSame idea as for plotting separate predictions on one plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt %>%\n  pivot_longer(\n    -rut.depth,\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(x = x, y = rut.depth)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g\n```\n:::\n\n\n\n\n\"collect all the x-variables together into one column called x, with\nanother column xname saying which x they were, then plot these x's\nagainst rut.depth, a separate facet for each x-variable.\"\n\nI saved this graph to plot later (on the next page).\n\n## The plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Interpreting the plots\n\n-   One plot of rut depth against each of the six other variables.\n-   Get rough idea of what's going on.\n-   Trends mostly weak.\n-   `viscosity` has strong but non-linear trend.\n-   `run` has effect but variability bigger when run is 1.\n-   Weak but downward trend for `voids`.\n-   Non-linearity of `rut.depth`-`viscosity` relationship should concern\n    us.\n\n## Log of `viscosity`: more nearly linear?\n\n-   Take this back to asphalt engineer: suggests log of `viscosity`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(asphalt, aes(y = rut.depth, x = log(viscosity))) +\n  geom_point() + geom_smooth(se = FALSE) -> g\n```\n:::\n\n\n\n\n(plot overleaf)\n\n## Rut depth against log-viscosity\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments and next steps\n\n-   Not very linear, but better than before.\n-   In multiple regression, hard to guess which x's affect response. So\n    typically start by predicting from everything else.\n-   Model formula has response on left, squiggle, explanatories on right\n    joined by plusses:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1 <- lm(rut.depth ~ pct.a.surf + pct.a.base + fines +\n  voids + log(viscosity) + run, data = asphalt)\n```\n:::\n\n\n\n\n## Regression output:\n\n\\scriptsize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rut.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = rut.depth ~ pct.a.surf + pct.a.base + fines + voids + \n    log(viscosity) + run, data = asphalt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1211 -1.9075 -0.7175  1.6382  9.5947 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)   \n(Intercept)    -12.9937    26.2188  -0.496   0.6247   \npct.a.surf       3.9706     2.4966   1.590   0.1248   \npct.a.base       1.2631     3.9703   0.318   0.7531   \nfines            0.1164     1.0124   0.115   0.9094   \nvoids            0.5893     1.3244   0.445   0.6604   \nlog(viscosity)  -3.1515     0.9194  -3.428   0.0022 **\nrun             -1.9655     3.6472  -0.539   0.5949   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.324 on 24 degrees of freedom\nMultiple R-squared:  0.806,\tAdjusted R-squared:  0.7575 \nF-statistic: 16.62 on 6 and 24 DF,  p-value: 1.743e-07\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Comments\n\n-   R-squared 81%, not so bad.\n\n-   P-value in `glance` asserts that something helping to predict\n    rut.depth.\n\n-   Table of coefficients says `log(viscosity)`.\n\n-   But confused by clearly non-significant variables: remove those to\n    get clearer picture of what is helpful.\n\n\n## Before we do anything, look at residual plots:\n\n- (a) of residuals against fitted values (as usual)\n\n-  (b) of residuals against each explanatory.\n\n-   Problem fixes:\n\n    -   with (a): fix response variable;\n    -   with some plots in (b): fix those explanatory variables.\n\n## Plot fitted values against residuals\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rut.1, aes(x = .fitted, y = .resid)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Normal quantile plot of residuals\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rut.1, aes(sample = .resid)) + stat_qq() + \n  stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Plotting residuals against $x$ variables\n\n-   Problem here is that residuals are in the fitted model, and the\n    observed $x$-values are in the original data frame `asphalt`.\n-   Package broom contains a function `augment` that combines these two\n    together so that they can later be plotted: start with a model\n    first, and then augment with a data frame:\n\n\\scriptsize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1 %>% augment(asphalt) -> rut.1a\nrut.1a\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 31 x 13\n   pct.a.surf pct.a.base fines voids rut.depth viscosity   run .fitted .resid\n        <dbl>      <dbl> <dbl> <dbl>     <dbl>     <dbl> <dbl>   <dbl>  <dbl>\n 1       4.68       4.87   8.4  4.92      6.75      2.8      1    10.4 -3.65 \n 2       5.19       4.5    6.5  4.56     13         1.4      1    13.7 -0.718\n 3       4.82       4.73   7.9  5.32     14.8       1.4      1    13.1  1.60 \n 4       4.85       4.76   8.3  4.86     12.6       3.3      1    10.4  2.22 \n 5       4.86       4.95   8.4  3.78      8.25      1.7      1    12.1 -3.87 \n 6       5.16       4.45   7.4  4.40     10.7       2.9      1    11.2 -0.577\n 7       4.82       5.05   6.8  4.87      7.28      3.7      1    10.1 -2.81 \n 8       4.86       4.7    8.6  4.83     12.7       1.7      1    12.4  0.221\n 9       4.78       4.84   6.7  4.86     12.6       0.92     1    14.0 -1.46 \n10       5.16       4.76   7.7  4.03     20.6       0.68     1    16.0  4.57 \n# i 21 more rows\n# i 4 more variables: .hat <dbl>, .sigma <dbl>, .cooksd <dbl>, .std.resid <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## What does rut.1a contain?\n\n\\small\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(rut.1a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"pct.a.surf\" \"pct.a.base\" \"fines\"      \"voids\"      \"rut.depth\" \n [6] \"viscosity\"  \"run\"        \".fitted\"    \".resid\"     \".hat\"      \n[11] \".sigma\"     \".cooksd\"    \".std.resid\"\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n-   all the stuff in original data frame, plus:\n-   quantities from regression (starting with a dot)\n\n## Plotting residuals against $x$-variables\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1a %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(x = x, y = .resid)) +\n  geom_point() + facet_wrap(~xname, scales = \"free\") -> g\n```\n:::\n\n\n\n\n## The plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   There is serious curve in plot of residuals vs. fitted values.\n    Suggests a transformation of $y$.\n-   The residuals-vs-$x$'s plots don't show any serious trends. Worst\n    probably that potential curve against log-viscosity.\n-   Also, large positive residual, 10, that shows up on all plots.\n    Perhaps transformation of $y$ will help with this too.\n-   If residual-fitted plot OK, but some residual-$x$ plots not, try\n    transforming those $x$'s, eg. by adding $x^2$ to help with curve.\n\n## Which transformation?\n\n-   Best way: consult with person who brought you the data.\n-   Can't do that here!\n-   No idea what transformation would be good.\n-   Let data choose: \"Box-Cox transformation\".\n-   Scale is that of \"ladder of powers\": power transformation, but 0 is\n    log.\n\n## Running Box-Cox\n\nFrom package `MASS`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxcox(rut.depth ~ pct.a.surf + pct.a.base + fines + voids +\n  log(viscosity) + run, data = asphalt)\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments on Box-Cox plot\n\n-   $\\lambda$ represents power to transform $y$ with.\n-   Best single choice of transformation parameter $\\lambda$ is peak of\n    curve, close to 0.\n-   Vertical dotted lines give CI for $\\lambda$, about (−0.05, 0.2).\n-   $\\lambda = 0$ means \"log\".\n-   Narrowness of confidence interval mean that these not supported by\n    data:\n    -   No transformation ($\\lambda = 1$)\n    -   Square root ($\\lambda = 0.5$)\n    -   Reciprocal ($\\lambda = −1$).\n\n## Relationships with explanatories\n\n-   As before: plot response (now `log(rut.depth)`) against other\n    explanatory variables, all in one shot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(y = log(rut.depth), x = x)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g3\n```\n:::\n\n\n\n\n## The new plots\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng3\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-17-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Modelling with transformed response\n\n-   These trends look pretty straight, especially with `log.viscosity`.\n-   Values of `log.rut.depth` for each `run` have same spread.\n-   Other trends weak, but are straight if they exist.\n-   Start modelling from the beginning again.\n-   Model `log.rut.depth` in terms of everything else, see what can be\n    removed:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.2 <- lm(log(rut.depth) ~ pct.a.surf + pct.a.base +\n  fines + voids + log(viscosity) + run, data = asphalt)\n```\n:::\n\n\n\n\n-   use `tidy` from `broom` to display just the coefficients.\n\n## Output\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)     -1.57      2.44      -0.646 0.525      \n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 pct.a.base      -0.103     0.369     -0.280 0.782      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 voids            0.199     0.123      1.62  0.119      \n6 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n7 run              0.340     0.339      1.00  0.326      \n```\n\n\n:::\n:::\n\n\n\n\n## Taking out everything non-significant\n\n-   Try: remove everything but pct.a.surf and log.viscosity:\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.3 <- lm(log(rut.depth) ~ pct.a.surf + log(viscosity), data = asphalt)\ntidy(rut.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       0.900    1.08       0.833 4.12e- 1\n2 pct.a.surf        0.391    0.219      1.79  8.46e- 2\n3 log(viscosity)   -0.619    0.0271   -22.8   1.27e-19\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n\n## Check that removing all those variables wasn't too much\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(rut.3, rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: log(rut.depth) ~ pct.a.surf + log(viscosity)\nModel 2: log(rut.depth) ~ pct.a.surf + pct.a.base + fines + voids + log(viscosity) + \n    run\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     28 2.8809                           \n2     24 2.2888  4   0.59216 1.5523 0.2191\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n-   $H_0$ : two models equally good; $H_a$ : bigger model better.\n-   Null not rejected here; small model as good as the big one, so\n    prefer simpler smaller model `rut.3`.\n\n## Find the largest P-value by eye:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)     -1.57      2.44      -0.646 0.525      \n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 pct.a.base      -0.103     0.369     -0.280 0.782      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 voids            0.199     0.123      1.62  0.119      \n6 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n7 run              0.340     0.339      1.00  0.326      \n```\n\n\n:::\n:::\n\n\n\n\n-   Largest P-value is 0.78 for `pct.a.base`, not significant.\n-   So remove this first, re-fit and re-assess.\n-   Or, as over.\n\n## Get the computer to find the largest P-value for you\n\n-   Output from `tidy` is itself a data frame, thus:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 voids            0.199     0.123      1.62  0.119      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 run              0.340     0.339      1.00  0.326      \n6 (Intercept)     -1.57      2.44      -0.646 0.525      \n7 pct.a.base      -0.103     0.369     -0.280 0.782      \n```\n\n\n:::\n:::\n\n\n\n\n-   Largest P-value at the bottom.\n\n## Take out `pct.a.base`\n\n-   Copy and paste the `lm` code and remove what you're removing:\n\n\\small\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.4 <- lm(log(rut.depth) ~ pct.a.surf + fines + voids + \n              log(viscosity) + run, data = asphalt)\ntidy(rut.4) %>% arrange(p.value) %>% select(term, p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 2\n  term               p.value\n  <chr>                <dbl>\n1 log(viscosity) 0.000000448\n2 pct.a.surf     0.0143     \n3 voids          0.109      \n4 (Intercept)    0.208      \n5 run            0.279      \n6 fines          0.316      \n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n-   `fines` is next to go, P-value 0.32.\n\n## \"Update\"\n\nAnother way to do the same thing:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.4 <- update(rut.2, . ~ . - pct.a.base)\ntidy(rut.4) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 log(viscosity)  -0.552     0.0818     -6.75 0.000000448\n2 pct.a.surf       0.593     0.225       2.63 0.0143     \n3 voids            0.200     0.121       1.66 0.109      \n4 (Intercept)     -2.08      1.61       -1.29 0.208      \n5 run              0.360     0.325       1.11 0.279      \n6 fines            0.0889    0.0870      1.02 0.316      \n```\n\n\n:::\n:::\n\n\n\n\n-   Again, `fines` is the one to go. (Output identical as it should be.)\n\n## Take out fines:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.5 <- update(rut.4, . ~ . - fines)\ntidy(rut.5) %>% arrange(p.value) %>% select(term, p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  term                p.value\n  <chr>                 <dbl>\n1 log(viscosity) 0.0000000559\n2 pct.a.surf     0.0200      \n3 voids          0.0577      \n4 run            0.365       \n5 (Intercept)    0.375       \n```\n\n\n:::\n:::\n\n\n\n\nCan't take out intercept, so `run`, with P-value 0.36, goes next.\n\n## Take out run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.6 <- update(rut.5, . ~ . - run)\ntidy(rut.6) %>% arrange(p.value) %>% select(term, p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 2\n  term            p.value\n  <chr>             <dbl>\n1 log(viscosity) 5.29e-19\n2 pct.a.surf     1.80e- 2\n3 voids          4.36e- 2\n4 (Intercept)    4.61e- 1\n```\n\n\n:::\n:::\n\n\n\n\nAgain, can't take out intercept, so largest P-value is for `voids`,\n0.044. But this is significant, so we shouldn't remove `voids`.\n\n## Comments\n\n-   Here we stop: `pct.a.surf`, `voids` and `log.viscosity` would all\n    make fit significantly worse if removed. So they stay.\n-   Different final result from taking things out one at a time (top),\n    than by taking out 4 at once (bottom):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(rut.6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)     pct.a.surf          voids log(viscosity) \n    -1.0207945      0.5554686      0.2447934     -0.6464911 \n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(rut.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)     pct.a.surf log(viscosity) \n     0.9001389      0.3911481     -0.6185628 \n```\n\n\n:::\n:::\n\n\n\n\n-   Point: Can make difference which way we go.\n\n## Comments on variable selection\n\n-   Best way to decide which $x$'s belong: expert knowledge: which of\n    them should be important.\n-   Best automatic method: what we did, \"backward selection\".\n-   Do not learn about \"stepwise regression\"! [**eg.\n    here**](https://towardsdatascience.com/stopping-stepwise-why-stepwise-selection-is-bad-and-what-you-should-use-instead-90818b3f52df)\n-   R has function `step` that does backward selection, like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(rut.2, direction = \"backward\", test = \"F\")\n```\n:::\n\n\n\nGets same answer as we did (by removing least significant x).\n\n-   Removing non-significant $x$'s may remove interesting ones whose\n    P-values happened not to reach 0.05. Consider using less stringent\n    cutoff like 0.20 or even bigger.\n-   Can also fit all possible regressions, as over (may need to do\n    `install.packages(\"leaps\")` first).\n\n## All possible regressions (output over)\n\nUses package `leaps`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleaps <- regsubsets(log(rut.depth) ~ pct.a.surf + \n                      pct.a.base + fines + voids + \n                      log(viscosity) + run, \n                    data = asphalt, nbest = 2)\ns <- summary(leaps)\nwith(s, data.frame(rsq, outmat)) -> d\n```\n:::\n\n\n\n\n## The output\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\\scriptsize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rownames_to_column(\"model\") %>% arrange(desc(rsq))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model       rsq pct.a.surf pct.a.base fines voids log.viscosity. run\n1  6  ( 1 ) 0.9609642          *          *     *     *              *   *\n2  5  ( 1 ) 0.9608365          *                *     *              *   *\n3  5  ( 2 ) 0.9593265          *          *     *     *              *    \n4  4  ( 1 ) 0.9591996          *                      *              *   *\n5  4  ( 2 ) 0.9589206          *                *     *              *    \n6  3  ( 1 ) 0.9578631          *                      *              *    \n7  3  ( 2 ) 0.9534561          *                *                    *    \n8  2  ( 1 ) 0.9508647          *                                     *    \n9  2  ( 2 ) 0.9479541                                 *              *    \n10 1  ( 1 ) 0.9452562                                                *    \n11 1  ( 2 ) 0.8624107                                                    *\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Comments\n\n-   Problem: even adding a worthless x increases R-squared. So try for\n    line where R-squared stops increasing \"too much\", eg. top line (just\n    log.viscosity), first 3-variable line (backwards-elimination model).\n    Hard to judge.\n-   One solution (STAC67): adjusted R-squared, where adding worthless\n    variable makes it go down.\n-   `data.frame` rather than `tibble` because there are several columns\n    in `outmat`.\n\n## All possible regressions, adjusted R-squared\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\\scriptsize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(s, data.frame(adjr2, outmat)) %>% \n  rownames_to_column(\"model\") %>% \n  arrange(desc(adjr2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      model     adjr2 pct.a.surf pct.a.base fines voids log.viscosity. run\n1  3  ( 1 ) 0.9531812          *                      *              *    \n2  5  ( 1 ) 0.9530038          *                *     *              *   *\n3  4  ( 1 ) 0.9529226          *                      *              *   *\n4  4  ( 2 ) 0.9526007          *                *     *              *    \n5  6  ( 1 ) 0.9512052          *          *     *     *              *   *\n6  5  ( 2 ) 0.9511918          *          *     *     *              *    \n7  3  ( 2 ) 0.9482845          *                *                    *    \n8  2  ( 1 ) 0.9473550          *                                     *    \n9  2  ( 2 ) 0.9442365                                 *              *    \n10 1  ( 1 ) 0.9433685                                                *    \n11 1  ( 2 ) 0.8576662                                                    *\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Revisiting the best model\n\n-   Best model was our `rut.6`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      -1.02     1.36      -0.748 4.61e- 1\n2 pct.a.surf        0.555    0.220      2.52  1.80e- 2\n3 voids             0.245    0.116      2.12  4.36e- 2\n4 log(viscosity)   -0.646    0.0288   -22.5   5.29e-19\n```\n\n\n:::\n:::\n\n\n\n\n## Revisiting (2)\n\n-   Regression slopes say that rut depth increases as log-viscosity\n    decreases, `pct.a.surf` increases and `voids` increases. This more\n    or less checks out with out scatterplots against `log.viscosity`.\n-   We should check residual plots again, though previous scatterplots\n    say it's unlikely that there will be a problem:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(rut.6, aes(y = .resid, x = .fitted)) + \ngeom_point()\n```\n:::\n\n\n\n\n## Residuals against fitted values\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-39-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Normal quantile plot of residuals\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rut.6, aes(sample = .resid)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Plotting residuals against x's\n\n-   Do our trick again to put them all on one plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(rut.6, asphalt) %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\",\n  ) %>%\n  ggplot(aes(y = .resid, x = x)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g2\n```\n:::\n\n\n\n\n## Residuals against the x's\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng2\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-41-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   None of the plots show any sort of pattern. The points all look\n    random on each plot.\n-   On the plot of fitted values (and on the one of log.viscosity), the\n    points seem to form a \"left half\" and a \"right half\" with a gap in\n    the middle. This is not a concern.\n-   One of the pct.a.surf values is low outlier (4), shows up top left\n    of that plot.\n-   Only two possible values of run; the points in each group look\n    randomly scattered around 0, with equal spreads.\n-   Residuals seem to go above zero further than below, suggesting a\n    mild non-normality, but not enough to be a problem.\n\n## Variable-selection strategies\n\n-   Expert knowledge.\n-   Backward elimination.\n-   All possible regressions.\n-   Taking a variety of models to experts and asking their opinion.\n-   Use a looser cutoff to eliminate variables in backward elimination\n    (eg. only if P-value greater than 0.20).\n-   If goal is prediction, eliminating worthless variables less\n    important.\n-   If goal is understanding, want to eliminate worthless variables\n    where possible.\n-   Results of variable selection not always reproducible, so caution\n    advised.\n",
    "supporting": [
      "asphalt_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}