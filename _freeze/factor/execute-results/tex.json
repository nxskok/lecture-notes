{
  "hash": "345f0b955fa63af98c894b887a4c84e3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Factor analysis\"\n---\n\n\n\n\n##  Vs. principal components \n\n\n* Principal components: \n\n\n  * Purely mathematical.\n\n  * Find eigenvalues, eigenvectors of correlation matrix.\n\n  * No testing whether observed components reproducible, or even probability model behind it.\n\n\n* Factor analysis: \n\n\n  * some way towards fixing this (get test of appropriateness)\n\n  * In factor analysis, each variable modelled as: \"common factor\" (eg. verbal ability) and \"specific factor\" (left over).\n\n  * Choose the common factors to \"best\" reproduce pattern seen in correlation matrix.\n\n  * Iterative procedure, different answer from principal components.\n\n\n\n##  Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggbiplot)\nlibrary(tidyverse)\nlibrary(conflicted)\nconflict_prefer(\"mutate\", \"dplyr\")\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"arrange\", \"dplyr\")\n```\n:::\n\n\n\n\n \n\n\n##  Example\n\n\n* 145 children given 5 tests, called PARA, SENT, WORD, ADD and DOTS. 3 linguistic tasks (paragraph comprehension, sentence completion  and word meaning), 2 mathematical ones (addition and counting dots).\n\n* Correlation matrix of scores on the tests:\n\n\n```\n\npara 1     0.722 0.714 0.203 0.095\nsent 0.722 1     0.685 0.246 0.181\nword 0.714 0.685 1     0.170 0.113\nadd  0.203 0.246 0.170 1     0.585\ndots 0.095 0.181 0.113 0.585 1\n\n```\n\n\n\n* Is there small number of underlying \"constructs\" (unobservable) that explains this pattern of correlations?\n\n\n\n##  To start: principal components\n\nUsing correlation matrix. Read that first:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rex2.txt\"\nkids <- read_delim(my_url, \" \")\nkids\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 6\n  test   para  sent  word   add  dots\n  <chr> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 para  1     0.722 0.714 0.203 0.095\n2 sent  0.722 1     0.685 0.246 0.181\n3 word  0.714 0.685 1     0.17  0.113\n4 add   0.203 0.246 0.17  1     0.585\n5 dots  0.095 0.181 0.113 0.585 1    \n```\n\n\n:::\n:::\n\n\n\n\n\n## Principal components on correlation matrix\n\n\nTurn into R `matrix`, using column `test` as column names:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids %>% \ncolumn_to_rownames(\"test\") %>% \nas.matrix() -> m\n```\n:::\n\n\n\n\nPrincipal components:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.0 <- princomp(covmat = m) \n```\n:::\n\n\n\n\nI used `kids.0` here since I want `kids.1` and `kids.2` later.\n\n\n##  Scree plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggscreeplot(kids.0)\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/bFactor-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n \n\n\n##  Principal component results\n\n\n* Need 2 components. Loadings:\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.0$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n     Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\npara  0.534  0.245  0.114         0.795\nsent  0.542  0.164         0.660 -0.489\nword  0.523  0.247 -0.144 -0.738 -0.316\nadd   0.297 -0.627  0.707              \ndots  0.241 -0.678 -0.680         0.143\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Comments\n\n* First component has a bit of everything, though especially the\nfirst three tests.\n\n* Second component rather more clearly `add` and `dots`.\n\n* No scores, plots since no actual data.\n\n- See how factor analysis compares on these data.\n\n\n##  Factor analysis\n\n\n* Specify number of factors first, get solution with exactly\nthat many factors.\n\n* Includes hypothesis test, need to specify how many children\nwrote the tests.\n\n* Works from correlation matrix via `covmat` or actual\ndata, like `princomp`.\n\n* Introduces extra feature, *rotation*, to make\ninterpretation of loadings (factor-variable relation) easier.\n\n\n\n##  Factor analysis for the kids data\n\n\n* Create \"covariance list\" to include number of children who\nwrote the tests.\n\n* Feed this into `factanal`, specifying how many factors (2).\n\n- Start with the matrix we made before.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      para  sent  word   add  dots\npara 1.000 0.722 0.714 0.203 0.095\nsent 0.722 1.000 0.685 0.246 0.181\nword 0.714 0.685 1.000 0.170 0.113\nadd  0.203 0.246 0.170 1.000 0.585\ndots 0.095 0.181 0.113 0.585 1.000\n```\n\n\n:::\n\n```{.r .cell-code}\nml <- list(cov = m, n.obs = 145)\nkids.2 <- factanal(factors = 2, covmat = ml)\n```\n:::\n\n\n\n\n \n\n\n\n##  Uniquenesses\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.2$uniquenesses\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     para      sent      word       add      dots \n0.2424457 0.2997349 0.3272312 0.5743568 0.1554076 \n```\n\n\n:::\n:::\n\n\n\n\n\n* Uniquenesses say how \"unique\" a variable is (size of\nspecific factor). Small\nuniqueness means that the variable is summarized by a factor (good).\n\n* Very large uniquenesses are bad; `add`'s uniqueness is largest but not large enough to be worried about.\n\n* Also see \"communality\" for this idea, where *large* is good and *small* is bad.\n\n\n\n##  Loadings\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.2$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n     Factor1 Factor2\npara 0.867          \nsent 0.820   0.166  \nword 0.816          \nadd  0.167   0.631  \ndots         0.918  \n\n               Factor1 Factor2\nSS loadings      2.119   1.282\nProportion Var   0.424   0.256\nCumulative Var   0.424   0.680\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n* Loadings show how each factor depends on variables. Blanks\nindicate \"small\", less than 0.1.\n\n## Comments\n\n* Factor 1 clearly the \"linguistic\" tasks, factor 2 clearly\nthe \"mathematical\" ones.\n\n* Two factors together explain 68\\% of variability (like\nregression R-squared).\n  \n- Which variables belong to which factor is *much* clearer than with principal components.\n\n##  Are 2 factors enough? \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.2$STATISTIC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nobjective \n0.5810578 \n```\n\n\n:::\n\n```{.r .cell-code}\nkids.2$dof\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\nkids.2$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nobjective \n 0.445898 \n```\n\n\n:::\n:::\n\n\n\n\n \n\nP-value not small, so 2 factors OK.\n\n\n##  1 factor\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids.1 <- factanal(factors = 1, covmat = ml)\nkids.1$STATISTIC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nobjective \n 58.16534 \n```\n\n\n:::\n\n```{.r .cell-code}\nkids.1$dof\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n```{.r .cell-code}\nkids.1$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   objective \n2.907856e-11 \n```\n\n\n:::\n:::\n\n\n\n\n \n\n1 factor rejected (P-value small). Definitely need more than 1.\n\n## Places rated, again\n\n- Read data, transform, rerun principal components, get biplot: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/places.txt\"\nplaces0 <- read_table(my_url)\nplaces0 %>% \nmutate(across(-id, \\(x) log(x))) -> places\nplaces %>% select(-id) -> places_numeric\nplaces.1 <- princomp(places_numeric, cor = TRUE)\ng <- ggbiplot(places.1, labels = places$id,\n       labels.size = 0.8)\n```\n:::\n\n\n\n\n- This is all exactly as for principal components (nothing new here).\n\n## The biplot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/bFactor-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n- Most of the criteria are part of components 1 *and* 2. \n- If we can rotate the arrows counterclockwise:\n  - economy and crime would point straight up\n    - part of component 2 only\n  - health and education would point to the right\n    - part of component 1 only\n- would be easier to see which variables belong to which component.\n- Factor analysis includes a rotation to help with interpretation.\n\n## Factor analysis\n\n- Have to pick a number of factors *first*. \n- Do this by running principal components and looking at scree plot.\n- In this case, 3 factors seemed good (revisit later):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.3 <- factanal(places_numeric, 3, scores = \"r\")\n```\n:::\n\n\n\n\n- There are different ways to get factor scores. These called \"regression\" scores.\n\n## A bad biplot \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbiplot(places.3$scores, places.3$loadings,\n  xlabs = places$id)\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/bFactor-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n## Comments\n\n- I have to find a way to make a better biplot!\n- Some of the variables now point straight up and some straight across (if you look carefully for the red arrows among the black points).\n- This should make the factors more interpretable than the components were.\n\n## Factor loadings\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.3$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Factor1 Factor2 Factor3\nclimate                   0.994 \nhousing   0.360   0.482   0.229 \nhealth    0.884   0.164         \ncrime     0.115   0.400   0.205 \ntrans     0.414   0.460         \neducate   0.511                 \narts      0.655   0.552   0.102 \nrecreate  0.148   0.714         \necon              0.318  -0.114 \n\n               Factor1 Factor2 Factor3\nSS loadings      1.814   1.551   1.120\nProportion Var   0.202   0.172   0.124\nCumulative Var   0.202   0.374   0.498\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Comments on loadings\n\n- These are at least somewhat clearer than for the principal components:\n- Factor 1: health, education, arts: \"well-being\"\n- Factor 2: housing, transportation, arts (again), recreation: \"places to be\"\n- Factor 3: climate (only): \"climate\"\n- In this analysis, economic factors don't seem to be important.\n\n## Factor scores\n\n- Make a dataframe with the city IDs and factor scores:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(id = places$id, places.3$scores) %>% \nas_tibble() -> places_scores\n```\n:::\n\n\n\n\n- Make percentile ranks again (for checking):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces %>% \nmutate(across(-id, \\(x) percent_rank(x))) -> places_pr\n```\n:::\n\n\n\n\n## Highest scores on factor 1, \"well-being\":\n\n- for the top 4 places:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_scores %>% \nslice_max(Factor1, n = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n     id Factor1 Factor2 Factor3\n  <dbl>   <dbl>   <dbl>   <dbl>\n1   213    2.47   1.78    0.506\n2    65    2.39   0.925  -0.287\n3   234    2.32   0.122   0.524\n4   314    2.22   0.671   0.521\n```\n\n\n:::\n:::\n\n\n\n\n## Check percentile ranks for factor 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_pr %>% \nselect(id, health, educate, arts) %>% \nfilter(id %in% c(213, 65, 234, 314))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n     id health educate  arts\n  <dbl>  <dbl>   <dbl> <dbl>\n1    65  0.997   0.963 0.997\n2   213  1       0.723 1    \n3   234  0.991   1     0.985\n4   314  0.985   0.994 0.991\n```\n\n\n:::\n:::\n\n\n\n\n- These are definitely high on the well-being variables.\n- City #213 is not so high on education, but is highest of all on the others.\n\n## Highest scores on factor 2, \"places to be\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_scores %>% \nslice_max(Factor2, n = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n     id Factor1 Factor2 Factor3\n  <dbl>   <dbl>   <dbl>   <dbl>\n1   318  -1.01     2.05 -0.0957\n2    12  -0.540    2.02 -3.80  \n3   168  -1.35     1.94  0.273 \n4    44  -0.149    1.92 -0.556 \n```\n\n\n:::\n:::\n\n\n\n\n## Check percentile ranks for factor 2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_pr %>% \nselect(id, housing, trans, arts, recreate) %>% \nfilter(id %in% c(318, 12, 168, 44))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 5\n     id housing trans  arts recreate\n  <dbl>   <dbl> <dbl> <dbl>    <dbl>\n1    12   0.933 0.729 0.604    0.896\n2    44   0.927 0.963 0.735    0.988\n3   168   0.832 0.872 0.442    0.979\n4   318   0.881 0.744 0.668    0.963\n```\n\n\n:::\n:::\n\n\n\n\n- These are definitely high on housing and recreation.\n- Some are (very) high on transportation, but not so much on arts.\n- Could look at more cities to see if #168 being low on arts is a fluke.\n\n## Highest scores on factor 3, \"climate\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_scores %>% \nslice_max(Factor3, n = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n     id Factor1 Factor2 Factor3\n  <dbl>   <dbl>   <dbl>   <dbl>\n1   227  -0.184   0.385    2.04\n2   218   0.881   0.897    2.02\n3   269   0.932   1.19     1.98\n4   270   1.50    1.84     1.94\n```\n\n\n:::\n:::\n\n\n\n\n## Check percentile ranks for factor 3\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_pr %>% \nselect(id, climate) %>% \nfilter(id %in% c(227, 218, 269, 270))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 2\n     id climate\n  <dbl>   <dbl>\n1   218   0.997\n2   227   0.991\n3   269   0.994\n4   270   0.997\n```\n\n\n:::\n:::\n\n\n\n\nThis is very clear.\n\n## Uniquenesses\n\n- We said earlier that the economy was not part of any of our factors:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.3$uniquenesses\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  climate   housing    health     crime     trans   educate \n0.0050000 0.5859175 0.1854084 0.7842407 0.6165449 0.7351921 \n     arts  recreate      econ \n0.2554663 0.4618143 0.8856382 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n- The higher the uniqueness, the less the variable concerned is part of any of our factors (and that  maybe another factor is needed to accommodate it).\n- This includes economy and maybe crime.\n\n\n## Test of significance\n\nWe can test whether the three factors that we have is enough, or whether we need more to describe our data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.3$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   objective \n1.453217e-14 \n```\n\n\n:::\n:::\n\n\n\n\n- 3 factors are not enough. \n- What would 5 factors look like?\n\n## Five factors\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.5 <- factanal(places_numeric, 5, scores = \"r\")\nplaces.5$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Factor1 Factor2 Factor3 Factor4 Factor5\nclimate                           0.131   0.559 \nhousing   0.286   0.505   0.289  -0.113   0.475 \nhealth    0.847   0.214                   0.187 \ncrime             0.196   0.143   0.948   0.181 \ntrans     0.389   0.515           0.175         \neducate   0.534                                 \narts      0.611   0.564           0.172   0.145 \nrecreate          0.705           0.115   0.136 \necon                      0.978   0.135         \n\n               Factor1 Factor2 Factor3 Factor4 Factor5\nSS loadings      1.628   1.436   1.087   1.023   0.658\nProportion Var   0.181   0.160   0.121   0.114   0.073\nCumulative Var   0.181   0.340   0.461   0.575   0.648\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Comments 1/2\n\n- On (new) 5 factors:\n- Factor 1 is health, education, arts: same as factor 1 before.\n- Factor 2 is housing, transportation, arts, recreation: as factor 2 before.\n- Factor 3 is economy.\n- Factor 4 is crime.\n- Factor 5 is climate and housing: like factor 3 before.\n\n## Comments 2/2\n\n- The two added factors include the two \"missing\" variables.\n- Is this now enough?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.5$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   objective \n0.0009741394 \n```\n\n\n:::\n:::\n\n\n\n\n- No. My guess is that the authors of Places Rated chose their 9 criteria to capture different aspects of what makes a city good or bad to live in, and so it was too much to hope that a small number of factors would come out of these.\n\n\n##  A bigger example: BEM sex role inventory\n\n\n* 369 women asked to rate themselves on 60 traits, like \"self-reliant\" or \"shy\".\n\n* Rating 1 \"never or almost never true of me\" to 7 ``always or\nalmost always true of me''.\n\n* 60 personality traits is a lot. Can we find a smaller number\nof factors that capture aspects of personality?\n\n* The whole BEM sex role inventory on next page.\n\n\n\n##  The whole inventory\n\n\n![](bem.png){width=450px}\n\n\n\n\n##  Some of the data\n\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/factor.txt\"\nbem <- read_tsv(my_url)\nbem\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 369 x 45\n   subno helpful reliant defbel yielding cheerful indpt athlet   shy assert\n   <dbl>   <dbl>   <dbl>  <dbl>    <dbl>    <dbl> <dbl>  <dbl> <dbl>  <dbl>\n 1     1       7       7      5        5        7     7      7     1      7\n 2     2       5       6      6        6        2     3      3     3      4\n 3     3       7       6      4        4        5     5      2     3      4\n 4     4       6       6      7        4        6     6      3     4      4\n 5     5       6       6      7        4        7     7      7     2      7\n 6     7       5       6      7        4        6     6      2     4      4\n 7     8       6       4      6        6        6     3      1     3      3\n 8     9       7       6      7        5        6     7      5     2      5\n 9    10       7       6      6        4        4     5      2     2      5\n10    11       7       4      7        4        7     5      2     1      5\n# i 359 more rows\n# i 35 more variables: strpers <dbl>, forceful <dbl>, affect <dbl>,\n#   flatter <dbl>, loyal <dbl>, analyt <dbl>, feminine <dbl>, sympathy <dbl>,\n#   moody <dbl>, sensitiv <dbl>, undstand <dbl>, compass <dbl>, leaderab <dbl>,\n#   soothe <dbl>, risk <dbl>, decide <dbl>, selfsuff <dbl>, conscien <dbl>,\n#   dominant <dbl>, masculin <dbl>, stand <dbl>, happy <dbl>, softspok <dbl>,\n#   warm <dbl>, truthful <dbl>, tender <dbl>, gullible <dbl>, ...\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\n\n##  Principal components first\n\\ldots to decide on number of factors:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem.pc <- bem %>%\nselect(-subno) %>%\nprincomp(cor = T)\n```\n:::\n\n\n\n\n \n\n\n##  The scree plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(g <- ggscreeplot(bem.pc))\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/genoa-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n* No obvious elbow.\n\n\n\n\n##  Zoom in to search for elbow\n\nPossible elbows at 3 (2 factors) and 6 (5):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng + scale_x_continuous(limits = c(0, 8))\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/bem-scree-two-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n##  but is 2 really good?\n\n\n\n\n\n\n\n\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(bem.pc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                          Comp.1    Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     2.7444993 2.2405789 1.55049106 1.43886350 1.30318840\nProportion of Variance 0.1711881 0.1140953 0.05463688 0.04705291 0.03859773\nCumulative Proportion  0.1711881 0.2852834 0.33992029 0.38697320 0.42557093\n                           Comp.6     Comp.7     Comp.8     Comp.9    Comp.10\nStandard deviation     1.18837867 1.15919129 1.07838912 1.07120568 1.04901318\nProportion of Variance 0.03209645 0.03053919 0.02643007 0.02607913 0.02500974\nCumulative Proportion  0.45766738 0.48820657 0.51463664 0.54071577 0.56572551\n                          Comp.11    Comp.12    Comp.13    Comp.14   Comp.15\nStandard deviation     1.03848656 1.00152287 0.97753974 0.95697572 0.9287543\nProportion of Variance 0.02451033 0.02279655 0.02171782 0.02081369 0.0196042\nCumulative Proportion  0.59023584 0.61303238 0.63475020 0.65556390 0.6751681\n                          Comp.16    Comp.17   Comp.18    Comp.19    Comp.20\nStandard deviation     0.92262649 0.90585705 0.8788668 0.86757525 0.84269120\nProportion of Variance 0.01934636 0.01864948 0.0175547 0.01710652 0.01613928\nCumulative Proportion  0.69451445 0.71316392 0.7307186 0.74782514 0.76396443\n                          Comp.21    Comp.22    Comp.23    Comp.24    Comp.25\nStandard deviation     0.83124925 0.80564654 0.78975423 0.78100835 0.77852606\nProportion of Variance 0.01570398 0.01475151 0.01417527 0.01386305 0.01377506\nCumulative Proportion  0.77966841 0.79441992 0.80859519 0.82245823 0.83623330\n                          Comp.26    Comp.27    Comp.28    Comp.29    Comp.30\nStandard deviation     0.74969868 0.74137885 0.72343693 0.71457305 0.70358645\nProportion of Variance 0.01277382 0.01249188 0.01189457 0.01160488 0.01125077\nCumulative Proportion  0.84900712 0.86149899 0.87339356 0.88499844 0.89624921\n                          Comp.31     Comp.32     Comp.33    Comp.34\nStandard deviation     0.69022738 0.654861232 0.640339974 0.63179848\nProportion of Variance 0.01082759 0.009746437 0.009318984 0.00907203\nCumulative Proportion  0.90707680 0.916823235 0.926142219 0.93521425\n                           Comp.35     Comp.36     Comp.37     Comp.38\nStandard deviation     0.616621295 0.602404917 0.570025368 0.560881809\nProportion of Variance 0.008641405 0.008247538 0.007384748 0.007149736\nCumulative Proportion  0.943855654 0.952103192 0.959487940 0.966637677\n                           Comp.39     Comp.40     Comp.41     Comp.42\nStandard deviation     0.538149460 0.530277613 0.512370708 0.505662309\nProportion of Variance 0.006581928 0.006390781 0.005966449 0.005811236\nCumulative Proportion  0.973219605 0.979610386 0.985576834 0.991388070\n                           Comp.43     Comp.44\nStandard deviation     0.480413465 0.384873772\nProportion of Variance 0.005245389 0.003366541\nCumulative Proportion  0.996633459 1.000000000\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n\n\n\n\n\n\n\n\n##  Comments\n\n\n* Want overall fraction of variance explained (``cumulative\nproportion'') to be reasonably high.\n\n* 2 factors, 28.5\\%. Terrible!\n\n* Even 56\\% (10 factors) not that good!\n\n* Have to live with that.\n\n\n\n\n##  Biplot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbiplot(bem.pc, alpha = 0.3)\n```\n\n::: {.cell-output-display}\n![](factor_files/figure-beamer/bem-biplot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n##  Comments\n\n\n* Ignore individuals for now.\n\n* Most variables point to 1 o'clock or 4 o'clock.\n\n* Suggests factor analysis with rotation will get interpretable\nfactors (rotate to 12 o'clock and 3 o'clock, for example).\n\n* Try for 2-factor solution (rough interpretation, will be bad):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem %>%\nselect(-subno) %>%\nfactanal(factors = 2) -> bem.2\n```\n:::\n\n\n\n\n\n\n* Show output in pieces (just print `bem.2` to see all of it).\n\n\n\n##  Uniquenesses, sorted\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort(bem.2$uniquenesses)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n leaderab   leadact      warm    tender  dominant    gentle \n0.4091894 0.4166153 0.4764762 0.4928919 0.4942909 0.5064551 \n forceful   strpers   compass     stand  undstand    assert \n0.5631857 0.5679398 0.5937073 0.6024001 0.6194392 0.6329347 \n   soothe    affect    decide  selfsuff  sympathy     indpt \n0.6596103 0.6616625 0.6938578 0.7210246 0.7231450 0.7282742 \n  helpful    defbel      risk   reliant   individ   compete \n0.7598223 0.7748448 0.7789761 0.7808058 0.7941998 0.7942910 \n conscien     happy  sensitiv     loyal  ambitiou       shy \n0.7974820 0.8008966 0.8018851 0.8035264 0.8101599 0.8239496 \n softspok  cheerful  masculin  yielding  feminine  truthful \n0.8339058 0.8394916 0.8453368 0.8688473 0.8829927 0.8889983 \n  lovchil    analyt    athlet   flatter  gullible     moody \n0.8924392 0.8968744 0.9229702 0.9409500 0.9583435 0.9730607 \n childlik  foullang \n0.9800360 0.9821662 \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n## Comments\n\n* Mostly high or very high (bad).\n\n* Some smaller, eg.: Leadership ability (0.409),\nActs like leader (0.417),\nWarm (0.476),\nTender (0.493).\n\n* Smaller uniquenesses captured by one of our two factors.\n\n- Larger uniquenesses are not: need more factors to capture them.\n\n\n\n##  Factor loadings, some\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem.2$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Factor1 Factor2\nhelpful   0.314   0.376 \nreliant   0.453   0.117 \ndefbel    0.434   0.193 \nyielding -0.131   0.338 \ncheerful  0.152   0.371 \nindpt     0.521         \nathlet    0.267         \nshy      -0.414         \nassert    0.605         \nstrpers   0.657         \nforceful  0.649  -0.126 \naffect    0.178   0.554 \nflatter           0.223 \nloyal     0.151   0.417 \nanalyt    0.295   0.127 \nfeminine  0.113   0.323 \nsympathy          0.526 \nmoody            -0.162 \nsensitiv  0.135   0.424 \nundstand          0.610 \ncompass   0.114   0.627 \nleaderab  0.765         \nsoothe            0.580 \nrisk      0.442   0.161 \ndecide    0.542   0.113 \nselfsuff  0.511   0.134 \nconscien  0.328   0.308 \ndominant  0.668  -0.245 \nmasculin  0.276  -0.280 \nstand     0.607   0.172 \nhappy     0.119   0.430 \nsoftspok -0.230   0.336 \nwarm              0.719 \ntruthful  0.109   0.315 \ntender            0.710 \ngullible -0.153   0.135 \nleadact   0.763         \nchildlik -0.101         \nindivid   0.445         \nfoullang          0.133 \nlovchil           0.327 \ncompete   0.450         \nambitiou  0.414   0.137 \ngentle            0.702 \n\n               Factor1 Factor2\nSS loadings      6.083   5.127\nProportion Var   0.138   0.117\nCumulative Var   0.138   0.255\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n\n\n##  Making a data frame\nThere are too many to read easily, so make a data frame. A\nbit tricky:\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem.2$loadings %>% \nunclass() %>% \nas_tibble() %>% \nmutate(trait = rownames(bem.2$loadings)) -> loadings\nloadings %>% slice(1:8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 3\n  Factor1  Factor2 trait   \n    <dbl>    <dbl> <chr>   \n1   0.314  0.376   helpful \n2   0.453  0.117   reliant \n3   0.434  0.193   defbel  \n4  -0.131  0.338   yielding\n5   0.152  0.371   cheerful\n6   0.521  0.00587 indpt   \n7   0.267  0.0755  athlet  \n8  -0.414 -0.0654  shy     \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\n\n##  Pick out the big ones on factor 1\n\nArbitrarily defining $>0.4$ or $<-0.4$ as \"big\":\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>% filter(abs(Factor1) > 0.4) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 17 x 3\n   Factor1  Factor2 trait   \n     <dbl>    <dbl> <chr>   \n 1   0.453  0.117   reliant \n 2   0.434  0.193   defbel  \n 3   0.521  0.00587 indpt   \n 4  -0.414 -0.0654  shy     \n 5   0.605  0.0330  assert  \n 6   0.657  0.0208  strpers \n 7   0.649 -0.126   forceful\n 8   0.765  0.0695  leaderab\n 9   0.442  0.161   risk    \n10   0.542  0.113   decide  \n11   0.511  0.134   selfsuff\n12   0.668 -0.245   dominant\n13   0.607  0.172   stand   \n14   0.763 -0.0407  leadact \n15   0.445  0.0891  individ \n16   0.450  0.0532  compete \n17   0.414  0.137   ambitiou\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n\n\n##  Factor 2, the big ones\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>% filter(abs(Factor2) > 0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 3\n   Factor1 Factor2 trait   \n     <dbl>   <dbl> <chr>   \n 1  0.178    0.554 affect  \n 2  0.151    0.417 loyal   \n 3  0.0230   0.526 sympathy\n 4  0.135    0.424 sensitiv\n 5  0.0911   0.610 undstand\n 6  0.114    0.627 compass \n 7  0.0606   0.580 soothe  \n 8  0.119    0.430 happy   \n 9  0.0796   0.719 warm    \n10  0.0511   0.710 tender  \n11 -0.0187   0.702 gentle  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\n\n##  Plotting the two factors\n- A bi-plot, this time with the variables reduced in size. Looking for\nunusual individuals.\n\n- Have to run `factanal` again to get factor scores for plotting.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem %>% select(-subno) %>% \nfactanal(factors = 2, scores = \"r\") -> bem.2a\nbiplot(bem.2a$scores, bem.2a$loadings, cex = c(0.5, 0.5))\n```\n:::\n\n\n\n\n\n\n- Numbers on plot are row numbers of `bem`\ndata frame.\n\n\n##  The (awful) biplot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](factor_files/figure-beamer/biplot-two-ag-1.pdf)\n:::\n:::\n\n\n\n\n\n\n\n##  Comments\n\n\n* Variables mostly up (\"feminine\") and right (\"masculine\"),\naccomplished by rotation.\n\n* Some unusual individuals: 311, 214 (low on factor 2), 366\n(high on factor 2),\n359, 258\n(low on factor 1), 230 (high on factor 1).\n\n\n\n##  Individual 366\n\n\\tiny\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem %>% slice(366) %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1\nColumns: 45\n$ subno    <dbl> 755\n$ helpful  <dbl> 7\n$ reliant  <dbl> 7\n$ defbel   <dbl> 5\n$ yielding <dbl> 7\n$ cheerful <dbl> 7\n$ indpt    <dbl> 7\n$ athlet   <dbl> 7\n$ shy      <dbl> 2\n$ assert   <dbl> 1\n$ strpers  <dbl> 3\n$ forceful <dbl> 1\n$ affect   <dbl> 7\n$ flatter  <dbl> 9\n$ loyal    <dbl> 7\n$ analyt   <dbl> 7\n$ feminine <dbl> 7\n$ sympathy <dbl> 7\n$ moody    <dbl> 1\n$ sensitiv <dbl> 7\n$ undstand <dbl> 7\n$ compass  <dbl> 6\n$ leaderab <dbl> 3\n$ soothe   <dbl> 7\n$ risk     <dbl> 7\n$ decide   <dbl> 7\n$ selfsuff <dbl> 7\n$ conscien <dbl> 7\n$ dominant <dbl> 1\n$ masculin <dbl> 1\n$ stand    <dbl> 7\n$ happy    <dbl> 7\n$ softspok <dbl> 7\n$ warm     <dbl> 7\n$ truthful <dbl> 7\n$ tender   <dbl> 7\n$ gullible <dbl> 1\n$ leadact  <dbl> 2\n$ childlik <dbl> 1\n$ individ  <dbl> 5\n$ foullang <dbl> 7\n$ lovchil  <dbl> 7\n$ compete  <dbl> 7\n$ ambitiou <dbl> 7\n$ gentle   <dbl> 7\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Comments\n\n\n\n* Individual 366 high on factor 2, but hard to see which traits should have high scores\n(unless we remember).\n\n- Idea 1: use percentile ranks as before.\n\n* Idea 2: Rating scale is easy to interpret. So\n*tidy* original data frame to make easier to look\nthings up.\n\n\n\n##  Tidying original data\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem %>%\nungroup() %>% \nmutate(row = row_number()) %>%\npivot_longer(c(-subno, -row), names_to=\"trait\", \n             values_to=\"score\") -> bem_tidy\nbem_tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16,236 x 4\n   subno   row trait    score\n   <dbl> <int> <chr>    <dbl>\n 1     1     1 helpful      7\n 2     1     1 reliant      7\n 3     1     1 defbel       5\n 4     1     1 yielding     5\n 5     1     1 cheerful     7\n 6     1     1 indpt        7\n 7     1     1 athlet       7\n 8     1     1 shy          1\n 9     1     1 assert       7\n10     1     1 strpers      7\n# i 16,226 more rows\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\n\n##  Recall data frame of loadings\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>% slice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 3\n   Factor1  Factor2 trait   \n     <dbl>    <dbl> <chr>   \n 1   0.314  0.376   helpful \n 2   0.453  0.117   reliant \n 3   0.434  0.193   defbel  \n 4  -0.131  0.338   yielding\n 5   0.152  0.371   cheerful\n 6   0.521  0.00587 indpt   \n 7   0.267  0.0755  athlet  \n 8  -0.414 -0.0654  shy     \n 9   0.605  0.0330  assert  \n10   0.657  0.0208  strpers \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nWant to add the factor scores for each trait to our tidy data frame\n`bem_tidy`. This is a left-join (over), matching on the column\n`trait` that is in both data frames (thus, the default):\n\n\n##  Looking up loadings\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem_tidy %>% left_join(loadings) -> bem_tidy\nbem_tidy %>% sample_n(12)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 6\n   subno   row trait    score Factor1  Factor2\n   <dbl> <int> <chr>    <dbl>   <dbl>    <dbl>\n 1    53    32 leadact      7  0.763  -0.0407 \n 2   247   141 lovchil      7 -0.0271  0.327  \n 3   577   337 lovchil      6 -0.0271  0.327  \n 4   551   320 affect       6  0.178   0.554  \n 5   345   203 indpt        2  0.521   0.00587\n 6    70    40 leadact      3  0.763  -0.0407 \n 7   527   306 compete      7  0.450   0.0532 \n 8   337   198 lovchil      6 -0.0271  0.327  \n 9   502   289 athlet       4  0.267   0.0755 \n10    14    12 masculin     1  0.276  -0.280  \n11   117    74 leadact      4  0.763  -0.0407 \n12   235   132 compass      7  0.114   0.627  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\n\n##  Individual 366, high on Factor 2\nSo now pick out the rows of the tidy data frame that belong to\nindividual 366 (`row=366`) and for which the `Factor2`\nscore exceeds 0.4 in absolute value (our \"big\" from before):\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem_tidy %>% filter(row == 366, abs(Factor2) > 0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 6\n   subno   row trait    score Factor1 Factor2\n   <dbl> <int> <chr>    <dbl>   <dbl>   <dbl>\n 1   755   366 affect       7  0.178    0.554\n 2   755   366 loyal        7  0.151    0.417\n 3   755   366 sympathy     7  0.0230   0.526\n 4   755   366 sensitiv     7  0.135    0.424\n 5   755   366 undstand     7  0.0911   0.610\n 6   755   366 compass      6  0.114    0.627\n 7   755   366 soothe       7  0.0606   0.580\n 8   755   366 happy        7  0.119    0.430\n 9   755   366 warm         7  0.0796   0.719\n10   755   366 tender       7  0.0511   0.710\n11   755   366 gentle       7 -0.0187   0.702\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\nAs expected, high scorer on these.\n\n\n##  Several individuals\nRows 311 and 214 were *low* on Factor 2, so their scores should\nbe low. Can we do them all at once?\n\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem_tidy %>% filter(\nrow %in% c(366, 311, 214),\nabs(Factor2) > 0.4\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 33 x 6\n   subno   row trait    score Factor1 Factor2\n   <dbl> <int> <chr>    <dbl>   <dbl>   <dbl>\n 1   369   214 affect       1  0.178    0.554\n 2   369   214 loyal        7  0.151    0.417\n 3   369   214 sympathy     4  0.0230   0.526\n 4   369   214 sensitiv     7  0.135    0.424\n 5   369   214 undstand     5  0.0911   0.610\n 6   369   214 compass      5  0.114    0.627\n 7   369   214 soothe       3  0.0606   0.580\n 8   369   214 happy        4  0.119    0.430\n 9   369   214 warm         1  0.0796   0.719\n10   369   214 tender       3  0.0511   0.710\n# i 23 more rows\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nCan we display each individual in own column?\n\n\n##  Individual by column\nUn-`tidy`, that is, `pivot_wider`:\n\n\\tiny\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem_tidy %>%\nfilter(\n  row %in% c(366, 311, 214),\n  abs(Factor2) > 0.4\n) %>%\nselect(-subno, -Factor1, -Factor2) %>%\npivot_wider(names_from=row, values_from=score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 4\n   trait    `214` `311` `366`\n   <chr>    <dbl> <dbl> <dbl>\n 1 affect       1     5     7\n 2 loyal        7     4     7\n 3 sympathy     4     4     7\n 4 sensitiv     7     4     7\n 5 undstand     5     3     7\n 6 compass      5     4     6\n 7 soothe       3     4     7\n 8 happy        4     3     7\n 9 warm         1     3     7\n10 tender       3     4     7\n11 gentle       2     3     7\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n366 high, 311 middling, 214 (sometimes) low.\n\n\n##  Individuals 230, 258, 359\nThese were high, low, low on factor 1. Adapt code:\n\n\\tiny\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem_tidy %>%\nfilter(row %in% c(359, 258, 230), abs(Factor1) > 0.4) %>%\nselect(-subno, -Factor1, -Factor2) %>%\npivot_wider(names_from=row, values_from=score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 17 x 4\n   trait    `230` `258` `359`\n   <chr>    <dbl> <dbl> <dbl>\n 1 reliant      7     4     1\n 2 defbel       7     1     1\n 3 indpt        7     7     1\n 4 shy          2     7     5\n 5 assert       7     3     1\n 6 strpers      7     1     3\n 7 forceful     7     1     1\n 8 leaderab     7     1     1\n 9 risk         7     5     7\n10 decide       7     1     2\n11 selfsuff     7     4     1\n12 dominant     7     1     1\n13 stand        7     1     6\n14 leadact      7     1     1\n15 individ      7     3     3\n16 compete      6     2     1\n17 ambitiou     7     2     4\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n\n\n##  Is 2 factors enough?\nSuspect not:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem.2$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    objective \n1.458183e-150 \n```\n\n\n:::\n:::\n\n\n\n\n \n\n2 factors resoundingly rejected. Need more. Have to go all the way to\n15 factors to not reject:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem %>%\nselect(-subno) %>%\nfactanal(factors = 15) -> bem.15\nbem.15$PVAL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nobjective \n 0.132617 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nEven then, only just over 50\\% of variability explained.\n\n## What's important in 15 factors?\n\n- Let's take a look at the important things in those 15 factors.\n\n- Get 15-factor loadings into a data frame, as before:  \n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbem.15$loadings %>% \nunclass() %>% \nas_tibble() %>% \nmutate(trait = rownames(bem.15$loadings)) -> loadings\n```\n:::\n\n\n\n\\normalsize\n \n\n- then show the highest few loadings on each factor.\n\n\n\n##  Factor 1 (of 15)\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor1))) %>%\nselect(Factor1, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor1 trait   \n     <dbl> <chr>   \n 1   0.813 compass \n 2   0.676 undstand\n 3   0.661 sympathy\n 4   0.641 sensitiv\n 5   0.597 soothe  \n 6   0.348 warm    \n 7   0.280 gentle  \n 8   0.279 tender  \n 9   0.250 helpful \n10   0.234 conscien\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \nCompassionate, understanding, sympathetic, soothing: thoughtful of\nothers. \n\n\n\n##  Factor 2\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor2))) %>%\nselect(Factor2, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor2 trait   \n     <dbl> <chr>   \n 1   0.762 strpers \n 2   0.716 forceful\n 3   0.698 assert  \n 4   0.504 dominant\n 5   0.393 leaderab\n 6   0.367 stand   \n 7   0.351 leadact \n 8  -0.313 softspok\n 9  -0.287 shy     \n10   0.260 analyt  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nStrong personality, forceful, assertive, dominant: getting ahead. \n\n\n\n##  Factor 3\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor3))) %>%\nselect(Factor3, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor3 trait   \n     <dbl> <chr>   \n 1   0.670 reliant \n 2   0.648 selfsuff\n 3   0.620 indpt   \n 4   0.390 helpful \n 5  -0.339 gullible\n 6   0.333 individ \n 7   0.332 decide  \n 8   0.329 conscien\n 9   0.288 leaderab\n10   0.280 defbel  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nSelf-reliant, self-sufficient, independent: going it alone.\n\n\n\n##  Factor 4\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor4))) %>%\nselect(Factor4, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor4 trait   \n     <dbl> <chr>   \n 1   0.696 gentle  \n 2   0.692 tender  \n 3   0.599 warm    \n 4   0.447 affect  \n 5   0.394 softspok\n 6   0.278 lovchil \n 7   0.244 undstand\n 8   0.244 happy   \n 9   0.213 loyal   \n10   0.202 soothe  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nGentle, tender, warm (affectionate): caring for others.\n\n\n\n##  Factor 5\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor5))) %>%\nselect(Factor5, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor5 trait   \n     <dbl> <chr>   \n 1   0.696 compete \n 2   0.674 ambitiou\n 3   0.345 risk    \n 4   0.342 individ \n 5   0.281 athlet  \n 6   0.270 leaderab\n 7   0.245 decide  \n 8   0.206 dominant\n 9   0.193 leadact \n10   0.185 strpers \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nAmbitious, competitive (with a bit of risk-taking and individualism):\nBeing the best.\n\n\n\n##  Factor 6\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor6))) %>%\nselect(Factor6, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor6 trait   \n     <dbl> <chr>   \n 1   0.868 leadact \n 2   0.608 leaderab\n 3   0.338 dominant\n 4   0.201 forceful\n 5  -0.192 shy     \n 6   0.179 risk    \n 7   0.170 masculin\n 8   0.164 decide  \n 9   0.159 compete \n10   0.147 athlet  \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nActs like a leader, leadership ability (with a bit of Dominant):\nTaking charge.\n\n\n\n##  Factor 7\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor7))) %>%\nselect(Factor7, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor7 trait   \n     <dbl> <chr>   \n 1   0.670 happy   \n 2   0.667 cheerful\n 3  -0.522 moody   \n 4   0.219 athlet  \n 5   0.213 warm    \n 6   0.172 gentle  \n 7  -0.164 masculin\n 8   0.160 reliant \n 9   0.147 yielding\n10   0.141 lovchil \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \nHappy and cheerful.\n\n\n##  Factor 8\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor8))) %>%\nselect(Factor8, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor8 trait   \n     <dbl> <chr>   \n 1   0.630 affect  \n 2   0.516 flatter \n 3  -0.251 softspok\n 4   0.221 warm    \n 5   0.188 tender  \n 6   0.185 strpers \n 7  -0.180 shy     \n 8   0.180 compete \n 9   0.166 loyal   \n10   0.155 helpful \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \nAffectionate, flattering: Making others feel good.\n\n\n\n##  Factor 9\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor9))) %>%\nselect(Factor9, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor9 trait   \n     <dbl> <chr>   \n 1   0.863 stand   \n 2   0.340 defbel  \n 3   0.245 individ \n 4   0.194 risk    \n 5  -0.172 shy     \n 6   0.171 decide  \n 7   0.120 assert  \n 8   0.116 conscien\n 9   0.112 analyt  \n10  -0.112 gullible\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nTaking a stand.\n\n\n\n##  Factor 10\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor10))) %>%\nselect(Factor10, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor10 trait   \n      <dbl> <chr>   \n 1   0.808  feminine\n 2  -0.264  masculin\n 3   0.245  softspok\n 4   0.232  conscien\n 5   0.202  selfsuff\n 6   0.176  yielding\n 7   0.141  gentle  \n 8   0.113  flatter \n 9   0.109  decide  \n10  -0.0941 lovchil \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n \n\nFeminine. (A little bit of not-masculine!)\n\n\n\n##  Factor 11\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor11))) %>%\nselect(Factor11, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor11 trait   \n      <dbl> <chr>   \n 1   0.916  loyal   \n 2   0.189  affect  \n 3   0.159  truthful\n 4   0.125  helpful \n 5   0.104  analyt  \n 6   0.101  tender  \n 7   0.0972 lovchil \n 8   0.0964 gullible\n 9   0.0935 cheerful\n10   0.0821 conscien\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nLoyal.\n\n\n\n##  Factor 12\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor12))) %>%\nselect(Factor12, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor12 trait   \n      <dbl> <chr>   \n 1    0.611 childlik\n 2   -0.285 selfsuff\n 3   -0.279 conscien\n 4    0.259 moody   \n 5    0.201 shy     \n 6   -0.167 decide  \n 7    0.154 masculin\n 8    0.146 dominant\n 9    0.138 compass \n10   -0.130 leaderab\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nChildlike. (With a bit of moody, shy, not-self-sufficient, not-conscientious.)\n\n\n\n##  Factor 13\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor13))) %>%\nselect(Factor13, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor13 trait   \n      <dbl> <chr>   \n 1    0.573 truthful\n 2   -0.278 gullible\n 3    0.263 happy   \n 4    0.189 warm    \n 5   -0.167 shy     \n 6    0.165 loyal   \n 7   -0.144 yielding\n 8   -0.130 assert  \n 9    0.114 defbel  \n10   -0.111 lovchil \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nTruthful. (With a bit of happy and not-gullible.)\n\n\n\n##  Factor 14\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor14))) %>%\nselect(Factor14, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor14 trait   \n      <dbl> <chr>   \n 1    0.443 decide  \n 2    0.237 selfsuff\n 3    0.195 forceful\n 4   -0.186 softspok\n 5    0.160 risk    \n 6   -0.148 strpers \n 7    0.146 dominant\n 8    0.128 happy   \n 9    0.115 compass \n10    0.105 masculin\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nDecisive. (With a bit of self-sufficient and not-soft-spoken.)\n\n\n\n##  Factor 15\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloadings %>%\narrange(desc(abs(Factor15))) %>%\nselect(Factor15, trait) %>%\nslice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   Factor15 trait   \n      <dbl> <chr>   \n 1   -0.324 compass \n 2    0.247 athlet  \n 3    0.229 sensitiv\n 4    0.199 risk    \n 5   -0.164 affect  \n 6    0.163 moody   \n 7   -0.112 individ \n 8    0.110 warm    \n 9    0.105 cheerful\n10    0.101 reliant \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nNot-compassionate, athletic, sensitive: A mixed bag. (\"Cares about self\"?)\n\n\n##  Anything left out? Uniquenesses\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nenframe(bem.15$uniquenesses, name=\"quality\", value=\"uniq\") %>%\n  slice_max(uniq, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 2\n   quality   uniq\n   <chr>    <dbl>\n 1 foullang 0.914\n 2 lovchil  0.824\n 3 analyt   0.812\n 4 yielding 0.791\n 5 masculin 0.723\n 6 athlet   0.722\n 7 shy      0.703\n 8 gullible 0.700\n 9 flatter  0.663\n10 helpful  0.652\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n \n\nUses foul language especially, also loves children and analytical. So\ncould use even more factors.\n\n\n\n",
    "supporting": [
      "factor_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}