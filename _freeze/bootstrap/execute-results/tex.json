{
  "hash": "e4202d081334b44e9e2d8d7b2199cdfe",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The bootstrap revisited\"\n---\n\n\n\n\n\n## Packages for this section\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(bootstrap)\n```\n:::\n\n\n\n\nSource: [Hesterberg et al](https://www.researchgate.net/publication/265399426_Bootstrap_Methods_and_Permutation_Tests)\n\n\n## Is my sampling distribution normal enough?\n\n- Recall IRS data (used as a motivation for the sign test) :\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(irs, aes(x=Time))+geom_histogram(bins=10)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n- $t$ procedure for the mean would not be a good idea because the distribution is skewed.\n\n## What *actually* matters\n\n- It's not the distribution of the *data* that has to be approx normal (for a $t$ procedure).\n- What matters is the *sampling distribution of the sample mean*.\n- If the sample size is large enough, the sampling distribution will be normal enough even if the data distribution is not.\n  - This is why we had to consider the sample size as well as the shape.\n- But how do we know whether this is the case or not? We only have *one* sample.\n\n## The (nonparametric) bootstrap\n\n- Typically, our sample will be reasonably representative of the population.\n- Idea: pretend the sample *is* the population, and sample from it *with replacement*.\n- Calculate test statistic, and repeat many times.\n- This gives an idea of how our statistic might vary in repeated samples: that is, its sampling distribution.\n- Called the **bootstrap distribution** of the test statistic.\n- If the bootstrap distribution is approx normal, infer that the true sampling distribution also approx normal, therefore inference about the mean such as $t$ is good enough.\n- If not, we should be more careful.\n\n## Why it works\n\n- We typically estimate population parameters by using the corresponding sample thing: eg. estimate population mean using sample mean.\n- This called **plug-in principle**.\n- The fraction of sample values less than a value $x$ called the **empirical distribution function** (as a function of $x$).\n- By plug-in principle, the empirical distribution function is an estimate of the population CDF.\n- In this sense, the sample *is* an estimate of the population, and so sampling from it is an estimate of sampling from the population.\n\n## Bootstrapping the IRS data\n\n- Sampling with replacement is done like this (the default sample size is as long as the original data):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot <- sample(irs$Time, replace=T)\nmean(boot)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 206.4\n```\n\n\n:::\n:::\n\n\n\n\n- That's one bootstrapped mean. We need a whole bunch.\n\n## A whole bunch\n\n- Use the same idea as for simulating power:\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(boot_sample = list(sample(irs$Time, replace = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 2\n# Rowwise: \n     sim boot_sample\n   <int> <list>     \n 1     1 <dbl [30]> \n 2     2 <dbl [30]> \n 3     3 <dbl [30]> \n 4     4 <dbl [30]> \n 5     5 <dbl [30]> \n 6     6 <dbl [30]> \n 7     7 <dbl [30]> \n 8     8 <dbl [30]> \n 9     9 <dbl [30]> \n10    10 <dbl [30]> \n# i 990 more rows\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Get the mean of each of those\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(boot_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(boot_sample)) -> samples\nsamples\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim boot_sample my_mean\n   <int> <list>        <dbl>\n 1     1 <dbl [30]>     196 \n 2     2 <dbl [30]>     202.\n 3     3 <dbl [30]>     263.\n 4     4 <dbl [30]>     173.\n 5     5 <dbl [30]>     204.\n 6     6 <dbl [30]>     197.\n 7     7 <dbl [30]>     210.\n 8     8 <dbl [30]>     160.\n 9     9 <dbl [30]>     198.\n10    10 <dbl [30]>     178.\n# i 990 more rows\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Sampling distribution of sample mean\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(samples, aes(x=my_mean)) + geom_histogram(bins=10)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n- Is that a slightly long right tail?\n\n## Normal quantile plot\n\nmight be better than a histogram:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(samples, aes(sample = my_mean)) + \n  stat_qq()+stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n- a very very slight right-skewness, but very close to normal.\n\n## Confidence interval from the bootstrap distribution\n\nThere are two ways (at least):\n\n- percentile bootstrap interval: take the 2.5 and 97.5 percentiles (to get the middle 95%). This is easy, but not always the best:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(b_p=quantile(samples$my_mean, c(0.025, 0.975)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    2.5%    97.5% \n162.5775 246.9092 \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n- bootstrap $t$: use the SD of the bootstrapped sampling distribution as the SE of the estimator of the mean and make a $t$ interval:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- length(irs$Time)\nt_star <- qt(0.975, n-1)\nb_t <- with(samples, mean(my_mean)+c(-1, 1)*t_star*sd(my_mean))\nb_t\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 156.5070 246.4032\n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Comparing\n\n- get ordinary $t$ interval:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_names=c(\"LCL\", \"UCL\")\no_t <- t.test(irs$Time)$conf.int\n```\n:::\n\n\n\n\n\n- Compare the 2 bootstrap intervals with the ordinary $t$-interval: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(limit=my_names, o_t, b_t, b_p)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 4\n  limit   o_t   b_t   b_p\n  <chr> <dbl> <dbl> <dbl>\n1 LCL    155.  157.  163.\n2 UCL    247.  246.  247.\n```\n\n\n:::\n:::\n\n\n\n\n- The bootstrap $t$ and the ordinary $t$ are very close\n- The percentile bootstrap interval is noticeably shorter (common) and higher (skewness).\n  \n## Which to prefer?\n\n- If the intervals agree, then they are all good.\n- If they disagree, they are all bad! \n- In that case, use BCA interval (over).\n\n  \n## Bias correction and acceleration\n\n- this from \n\"An introduction to the bootstrap\", by\nBrad Efron and Robert J. Tibshirani.\n- there is way of correcting the CI for skewness in the bootstrap distribution, called the BCa method\n- complicated (see the Efron and Tibshirani book), but implemented in `bootstrap` package.\n\n## Run this on the IRS data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbca=bcanon(irs$Time, 1000, mean)\nbca$confpoints\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     alpha bca point\n[1,] 0.025  161.8333\n[2,] 0.050  168.0667\n[3,] 0.100  174.8333\n[4,] 0.160  180.7667\n[5,] 0.840  224.1333\n[6,] 0.900  232.3000\n[7,] 0.950  241.9333\n[8,] 0.975  253.7333\n```\n\n\n:::\n:::\n\n\n\n\n## use 2.5% and 97.5% points for CI\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbca$confpoints %>% as_tibble() %>% \n  filter(alpha %in% c(0.025, 0.975)) %>% \n  pull(`bca point`) -> b_bca\nb_bca\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 161.8333 253.7333\n```\n\n\n:::\n:::\n\n\n\n\n## Comparing\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(limit=my_names, o_t, b_t, b_p, b_bca)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 5\n  limit   o_t   b_t   b_p b_bca\n  <chr> <dbl> <dbl> <dbl> <dbl>\n1 LCL    155.  157.  163.  162.\n2 UCL    247.  246.  247.  254.\n```\n\n\n:::\n:::\n\n\n\n\n- The BCA interval says that the mean should be estimated even higher than the bootstrap percentile interval does. \n- The BCA interval is the one to trust.\n\n\n## Bootstrapping the correlation\n\nRecall the soap data:\n\n\\small \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"http://ritsokiguess.site/datafiles/soap.txt\"\nsoap <- read_delim(url,\" \")\nsoap\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 27 x 4\n    case scrap speed line \n   <dbl> <dbl> <dbl> <chr>\n 1     1   218   100 a    \n 2     2   248   125 a    \n 3     3   360   220 a    \n 4     4   351   205 a    \n 5     5   470   300 a    \n 6     6   394   255 a    \n 7     7   332   225 a    \n 8     8   321   175 a    \n 9     9   410   270 a    \n10    10   260   170 a    \n# i 17 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Scatterplot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(soap, aes(x=speed, y=scrap, colour=line))+\n  geom_point()+geom_smooth(method=\"lm\", se=F)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-18-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n- Line B produces less scrap for any given speed.\n- For line B, estimate the correlation between speed and scrap (with a confidence interval.)\n\n## Extract the line B data; standard correlation test \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsoap %>% filter(line==\"b\") -> line_b\nwith(line_b, cor.test(speed, scrap))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  speed and scrap\nt = 15.829, df = 10, p-value = 2.083e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9302445 0.9947166\nsample estimates:\n      cor \n0.9806224 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Bootstrapping a correlation 1/2\n\n- This illustrates a different technique: we need to keep the $x$ and $y$ values *together*.\n- Sample *rows* of the data frame rather than individual values of `speed` and `scrap`:\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nline_b %>% sample_frac(replace=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 4\n    case scrap speed line \n   <dbl> <dbl> <dbl> <chr>\n 1    24   252   155 b    \n 2    22   260   200 b    \n 3    16   140   105 b    \n 4    25   422   320 b    \n 5    16   140   105 b    \n 6    19   341   255 b    \n 7    19   341   255 b    \n 8    19   341   255 b    \n 9    17   277   215 b    \n10    16   140   105 b    \n11    20   215   175 b    \n12    18   384   270 b    \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n## Bootstrapping a correlation 2/2\n\n1000 times:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(boot_df = list(sample_frac(line_b, replace = TRUE))) %>% \n  mutate(my_cor = with(boot_df, cor(speed, scrap))) -> cors\n```\n:::\n\n\n\n\n## A picture of this\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cors, aes(x=my_cor))+geom_histogram(bins=15)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-23-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments and next steps\n\n- This is very left-skewed.\n- Bootstrap percentile interval is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(b_p=quantile(cors$my_cor, c(0.025, 0.975)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     2.5%     97.5% \n0.9415748 0.9962462 \n```\n\n\n:::\n:::\n\n\n\n\n- We probably need the BCA interval instead.\n\n## Getting the BCA interval 1/2\n\n- To use `bcanon`, write a function that takes a vector of row numbers and returns the correlation between `speed` and `scrap` for those rows:\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta=function(rows, d) {\n  d %>% slice(rows) %>% with(., cor(speed, scrap))\n}\ntheta(1:3, line_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9928971\n```\n\n\n:::\n\n```{.r .cell-code}\nline_b %>% slice(1:3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 4\n   case scrap speed line \n  <dbl> <dbl> <dbl> <chr>\n1    16   140   105 b    \n2    17   277   215 b    \n3    18   384   270 b    \n```\n\n\n:::\n:::\n\n\n\n\\normalsize\n\n- That looks about right.\n\n## Getting the BCA interval 2/2\n\n- Inputs to `bcanon` are now:\n  - row numbers (1 through 12 in our case: 12 rows in `line_b`)\n  - number of bootstrap samples\n  - the function we just wrote\n  - the data frame:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoints=bcanon(1:12, 1000, theta, line_b)$confpoints\npoints %>% as_tibble() %>% \n  filter(alpha %in% c(0.025, 0.975)) %>% \n  pull(`bca point`) -> b_bca\nb_bca\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9314334 0.9947799\n```\n\n\n:::\n:::\n\n\n\n\n## Comparing the results\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(limit=my_names, o_c, b_p, b_bca)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 4\n  limit   o_c   b_p b_bca\n  <chr> <dbl> <dbl> <dbl>\n1 LCL   0.930 0.942 0.931\n2 UCL   0.995 0.996 0.995\n```\n\n\n:::\n:::\n\n\n\n\n- The bootstrap percentile interval doesn't go down far enough. \n- The BCA interval seems to do a better job in capturing the skewness of the distribution.\n- The ordinary confidence interval for the correlation is very similar to the BCA one, and thus seems to be trustworthy here even though the correlation has a very skewed distribution. (`cor.test` uses the Fisher $z$ transformation which \"spreads out\" correlations close to 1).\n\n## The $z$-transformed bootstrapped correlations\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncors %>% \n  mutate(z = 0.5 * log((1+my_cor)/(1-my_cor))) %>% \n  ggplot(aes(sample=z)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-beamer/bootstrap-28-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\\normalsize\n\n",
    "supporting": [
      "bootstrap_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}