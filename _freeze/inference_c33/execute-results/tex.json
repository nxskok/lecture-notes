{
  "hash": "47f10c33a35635744a7f02aab31fc667",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Basic statistical inference\"\n---\n\n## Packages for this section\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n## Inference for means (from STAB57)\n\nThree kinds of inference for means of normally-distributed data:\n\n- **One-sample $t$**: a single sample from a population, estimate that population's mean\n- **Two-sample $t$**: one sample from each of 2 populations, estimate difference in population means\n- **Matched pairs $t$**: two paired measurements on same (or matched) individuals, estimate population mean difference\n\nTwo forms of inference for a population parameter:\n \n- **Confidence interval**: \"what is the population parameter?\"\n- **Hypothesis test**: \"could the population parameter be equal to this value?\"\n\n\n## Examples:\n\n- Blue jays attendances (one-sample)\n- Kids learning to read (two-sample)\n- Pain relief (matched pairs)\n\n## Confidence interval\n\n- You have a sample from some population\n- Imagine repeated sampling from that population\n- Procedure that gives an interval containing the true parameter in 95% (or 90% or 99%) of all possible samples\n\n## Hypothesis test\n\n- Null hypothesis gives value for population parameter\n- Alternative hypothesis says how you are trying to prove the null hypothesis wrong (not equal, greater, less).\n- Test statistic measures \"distance\" between data and null hypothesis\n- P-value gives probability of observing test statistic *as extreme or more extreme*, **if the null hypothesis is true**.\n- Reject null hypothesis if P-value small enough (eg smaller than 0.05).\n\n## Why 0.05? This man.\n\n::: columns\n::: {.column width=\"40%\"}\n![](fisher.png)\n:::\n\n::: {.column width=\"60%\"}\n-   analysis of variance\n-   Fisher information\n-   Linear discriminant analysis\n-   Fisher's $z$-transformation\n-   Fisher-Yates shuffle\n-   Behrens-Fisher problem\n\nSir Ronald A. Fisher, 1890--1962.\n:::\n:::\n\n## Why 0.05? (2)\n\n-   From The Arrangement of Field Experiments (1926):\n\n![](fisher1.png){width=\"100%\"}\n\n-   and\n\n![](fisher2.png){width=\"100%\"}\n\n## $\\alpha$ and errors\n\n-   Hypothesis test ends with decision:\n    -   reject null hypothesis\n    -   do not reject null hypothesis.\n-   but decision may be wrong:\n\n|                | Decision          |                 |\n|----------------|-------------------|-----------------|\n| **Truth**      | **Do not reject** | **reject null** |\n| **Null true**  | Correct           | Type I error    |\n| **Null false** | Type II error     | Correct         |\n\n-   Either type of error is bad, but for now focus on controlling Type I\n    error: write $\\alpha$ = P(type I error), and devise test so that\n    $\\alpha$ small, typically 0.05.\n-   That is, **if null hypothesis true**, have only small chance to\n    reject it (which would be a mistake).\n-   Worry about type II errors later (when we consider power of test).\n\n\n\n## One sample: the Blue Jays attendances\n\n\n-   The Toronto Blue Jays' average home attendance in part of 2015\n    season was 25,070 (up to May 27 2015, from baseball-reference.com).\n-   Does that mean the attendance at every game was exactly 25,070?\n    Certainly not. Actual attendance depends on many things, eg.:\n    -   how well the Jays are playing\n    -   the opposition\n    -   day of week\n    -   weather\n    -   random chance\n\n\n## Reading the attendances\n\n...as a `.csv` file:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/jays15-home.csv\"\njays <- read_csv(my_url) \njays\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 25 x 21\n     row  game date   box   team  venue opp   result  runs Oppruns innings wl   \n   <dbl> <dbl> <chr>  <chr> <chr> <lgl> <chr> <chr>  <dbl>   <dbl>   <dbl> <chr>\n 1    82     7 Monda~ boxs~ TOR   NA    TBR   L          1       2      NA 4-3  \n 2    83     8 Tuesd~ boxs~ TOR   NA    TBR   L          2       3      NA 4-4  \n 3    84     9 Wedne~ boxs~ TOR   NA    TBR   W         12       7      NA 5-4  \n 4    85    10 Thurs~ boxs~ TOR   NA    TBR   L          2       4      NA 5-5  \n 5    86    11 Frida~ boxs~ TOR   NA    ATL   L          7       8      NA 5-6  \n 6    87    12 Satur~ boxs~ TOR   NA    ATL   W-wo       6       5      10 6-6  \n 7    88    13 Sunda~ boxs~ TOR   NA    ATL   L          2       5      NA 6-7  \n 8    89    14 Tuesd~ boxs~ TOR   NA    BAL   W         13       6      NA 7-7  \n 9    90    15 Wedne~ boxs~ TOR   NA    BAL   W          4       2      NA 8-7  \n10    91    16 Thurs~ boxs~ TOR   NA    BAL   W          7       6      NA 9-7  \n# i 15 more rows\n# i 9 more variables: position <dbl>, gb <chr>, winner <chr>, loser <chr>,\n#   save <chr>, `game time` <time>, Daynight <chr>, attendance <dbl>,\n#   streak <chr>\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n## Another way\n\n-   This is a \"big\" data set: only 25 observations, but a lot of\n    *variables*.\n\n-   To see the first few values in all the variables, can also use\n    `glimpse`:\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(jays)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 25\nColumns: 21\n$ row         <dbl> 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96~\n$ game        <dbl> 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 27, 28, 29, 30, 31, 3~\n$ date        <chr> \"Monday, Apr 13\", \"Tuesday, Apr 14\", \"Wednesday, Apr 15\", ~\n$ box         <chr> \"boxscore\", \"boxscore\", \"boxscore\", \"boxscore\", \"boxscore\"~\n$ team        <chr> \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"TOR\", \"T~\n$ venue       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n$ opp         <chr> \"TBR\", \"TBR\", \"TBR\", \"TBR\", \"ATL\", \"ATL\", \"ATL\", \"BAL\", \"B~\n$ result      <chr> \"L\", \"L\", \"W\", \"L\", \"L\", \"W-wo\", \"L\", \"W\", \"W\", \"W\", \"W\", ~\n$ runs        <dbl> 1, 2, 12, 2, 7, 6, 2, 13, 4, 7, 3, 3, 5, 7, 7, 3, 10, 2, 3~\n$ Oppruns     <dbl> 2, 3, 7, 4, 8, 5, 5, 6, 2, 6, 1, 6, 1, 0, 1, 6, 6, 3, 4, 4~\n$ innings     <dbl> NA, NA, NA, NA, NA, 10, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n$ wl          <chr> \"4-3\", \"4-4\", \"5-4\", \"5-5\", \"5-6\", \"6-6\", \"6-7\", \"7-7\", \"8~\n$ position    <dbl> 2, 3, 2, 4, 4, 3, 4, 2, 2, 1, 4, 5, 3, 3, 3, 3, 5, 5, 5, 5~\n$ gb          <chr> \"1\", \"2\", \"1\", \"1.5\", \"2.5\", \"1.5\", \"1.5\", \"2\", \"1\", \"Tied~\n$ winner      <chr> \"Odorizzi\", \"Geltz\", \"Buehrle\", \"Archer\", \"Martin\", \"Cecil~\n$ loser       <chr> \"Dickey\", \"Castro\", \"Ramirez\", \"Sanchez\", \"Cecil\", \"Marimo~\n$ save        <chr> \"Boxberger\", \"Jepsen\", NA, \"Boxberger\", \"Grilli\", NA, \"Gri~\n$ `game time` <time> 02:30:00, 03:06:00, 03:02:00, 03:00:00, 03:09:00, 02:41:0~\n$ Daynight    <chr> \"N\", \"N\", \"N\", \"N\", \"N\", \"D\", \"D\", \"N\", \"N\", \"N\", \"N\", \"N\"~\n$ attendance  <dbl> 48414, 17264, 15086, 14433, 21397, 34743, 44794, 14184, 15~\n$ streak      <chr> \"-\", \"--\", \"+\", \"-\", \"--\", \"+\", \"-\", \"+\", \"++\", \"+++\", \"+\"~\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n## Attendance histogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(jays, aes(x = attendance)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](inference_c33_files/figure-beamer/inference-1-R-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Comments\n\n-   Attendances have substantial variability, ranging from just over\n    10,000 to around 50,000.\n-   Distribution somewhat skewed to right (but no outliers).\n-   These are a sample of \"all possible games\" (or maybe \"all possible\n    games played in April and May\"). What can we say about mean\n    attendance in all possible games based on this evidence?\n\n## CI for mean attendance\n\n-   `t.test` function does CI and test. Look at CI first:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n-   From 20,500 to 29,600.\n\n## Or, 90% CI\n\n-   by including a value for conf.level:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance, conf.level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n90 percent confidence interval:\n 21303.93 28836.39\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n-   From 21,300 to 28,800. (Shorter, as it should be.)\n\n## Comments\n\n-   Need to say \"column attendance within data frame `jays`\" using `$`.\n-   95% CI from about 20,000 to about 30,000.\n-   Not estimating mean attendance well at all!\n-   Generally want confidence interval to be shorter, which happens if:\n    -   SD smaller\n    -   sample size bigger\n    -   confidence level smaller\n-   Last one is a cheat, really, since reducing confidence level\n    increases chance that interval won't contain pop. mean at all!\n\n## Another way to access data frame columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(jays, t.test(attendance))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  attendance\nt = 11.389, df = 24, p-value = 3.661e-11\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n## Hypothesis testing for Blue Jays attendances\n\n\n- Previous year's mean attendance was 29,327, so test to see whether the mean is different from that in any way (two-sided test):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(jays$attendance, mu = 29327)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  jays$attendance\nt = -1.9338, df = 24, p-value = 0.06502\nalternative hypothesis: true mean is not equal to 29327\n95 percent confidence interval:\n 20526.82 29613.50\nsample estimates:\nmean of x \n 25070.16 \n```\n\n\n:::\n:::\n\n\n-   See test statistic $-1.93$, P-value 0.065.\n-   Do not reject null at $\\alpha=0.05$: no evidence that mean\n    attendance has changed.\n\n## Another example: learning to read\n\n- You devised new method for teaching children to read.\n- Guess it will be more effective than current methods.\n- To support this guess, collect data.\n- Want to generalize to “all children in Canada”.\n- So take random sample of all children in Canada.\n- Or, argue that sample you actually have is “typical” of all children in\nCanada.\n- Randomization (1): whether or not a child in sample or not has\nnothing to do with anything else about that child.\n- Randomization (2): randomly choose whether each child gets new\nreading method (t) or standard one (c).\n\n## Reading in data \n- File at <http://ritsokiguess.site/datafiles/drp.txt>.\n- Proper reading-in function is `read_delim` (check file to see)\n- Read in thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/drp.txt\"\nkids <- read_delim(my_url,\" \")\n```\n:::\n\n\n## The data (some) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nkids\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 44 x 2\n   group score\n   <chr> <dbl>\n 1 t        24\n 2 t        61\n 3 t        59\n 4 t        46\n 5 t        43\n 6 t        44\n 7 t        52\n 8 t        43\n 9 t        58\n10 t        67\n# i 34 more rows\n```\n\n\n:::\n:::\n\n\n## Boxplots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kids, aes(x = group, y = score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](inference_c33_files/figure-beamer/inference-1-R-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Two kinds of two-sample t-test\n\n- Do the two groups have same spread (SD, variance)?\n    - If yes (shaky assumption here), can use pooled t-test.\n    - If not, use Welch-Satterthwaite t-test (safe).\n- Pooled test derived in STAB57 (easier to derive, but assumes equal variances).\n- Welch-Satterthwaite does not assume equality of variances.\n- Assess (approx) equality of spreads using boxplot.\n\n## The (Welch-Satterthwaite) t-test\n- `c` (control) before `t` (treatment) alphabetically, so proper alternative\nis “less”.\n- R does Welch-Satterthwaite test by default \n- Answer to \"does the new reading program really help?\"\n- (in a moment) how to get R to do pooled test?\n\n## Welch-Satterthwaite \n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids, alternative = \"less\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  score by group\nt = -2.3109, df = 37.855, p-value = 0.01319\nalternative hypothesis: true difference in means between group c and group t is less than 0\n95 percent confidence interval:\n      -Inf -2.691293\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n## The pooled t-test \n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids, \n       alternative = \"less\", var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  score by group\nt = -2.2666, df = 42, p-value = 0.01431\nalternative hypothesis: true difference in means between group c and group t is less than 0\n95 percent confidence interval:\n      -Inf -2.567497\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n## Two-sided test; CI\n- To do 2-sided test, leave out `alternative`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(score ~ group, data = kids)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  score by group\nt = -2.3109, df = 37.855, p-value = 0.02638\nalternative hypothesis: true difference in means between group c and group t is not equal to 0\n95 percent confidence interval:\n -18.67588  -1.23302\nsample estimates:\nmean in group c mean in group t \n       41.52174        51.47619 \n```\n\n\n:::\n:::\n\n\n\n## Comments:\n\n- P-values for pooled and Welch-Satterthwaite tests very similar (even though the pooled test seemed inferior): 0.013 vs.\\ 0.014.\n- Two-sided test also gives CI: new reading program increases average scores by\nsomewhere between about 1 and 19 points.\n- Confidence intervals inherently two-sided, so do 2-sided test to get\nthem.\n\n## Pain relief\n\nSome data: \n\n\\centering{\n  \\includegraphics[height=0.7\\textheight]{Screenshot_2019-04-26_13-41-29}\n}\n\n\n## Matched pairs data\n\n- Data are comparison of 2 drugs for effectiveness at reducing pain.\n\n     - 12 subjects (cases) were arthritis sufferers\n     - Response is #hours of pain relief from each drug.\n      \n- In reading example, each child tried only one reading method.\n- But here, each subject tried out both drugs, giving us two\nmeasurements.\n\n    - Possible because, if you wait long enough, one drug has no influence\nover effect of other.\n    - Advantage: focused comparison of drugs. Compare one drug with\nanother on same person, removes a lot of variability due to differences between people. \n    - Matched pairs, requires different analysis.\n      \n- Design: randomly choose 6 of 12 subjects to get drug A first, other 6\nget drug B first.\n\n## Paired t test: reading the data\nValues aligned in columns:  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/analgesic.txt\"\npain <- read_table(my_url)\n```\n:::\n\n\n## The data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npain\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 3\n   subject druga drugb\n     <dbl> <dbl> <dbl>\n 1       1   2     3.5\n 2       2   3.6   5.7\n 3       3   2.6   2.9\n 4       4   2.6   2.4\n 5       5   7.3   9.9\n 6       6   3.4   3.3\n 7       7  14.9  16.7\n 8       8   6.6   6  \n 9       9   2.3   3.8\n10      10   2     4  \n11      11   6.8   9.1\n12      12   8.5  20.9\n```\n\n\n:::\n:::\n\n\n## Paired *t*-test \n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(pain, t.test(druga, drugb, paired = T))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  druga and drugb\nt = -2.1677, df = 11, p-value = 0.05299\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -4.29941513  0.03274847\nsample estimates:\nmean difference \n      -2.133333 \n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n- P-value is 0.053. \n- Not quite evidence of difference between drugs.\n\n## t-testing the differences\n\n- Likewise, you can calculate the differences yourself and\ndo a 1-sample t-test on them.\n- First calculate a column of differences:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(pain %>% mutate(diff=druga-drugb) -> pain)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 4\n   subject druga drugb    diff\n     <dbl> <dbl> <dbl>   <dbl>\n 1       1   2     3.5  -1.5  \n 2       2   3.6   5.7  -2.1  \n 3       3   2.6   2.9  -0.300\n 4       4   2.6   2.4   0.200\n 5       5   7.3   9.9  -2.6  \n 6       6   3.4   3.3   0.100\n 7       7  14.9  16.7  -1.80 \n 8       8   6.6   6     0.600\n 9       9   2.3   3.8  -1.5  \n10      10   2     4    -2    \n11      11   6.8   9.1  -2.3  \n12      12   8.5  20.9 -12.4  \n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n## t-test on the differences\n- then throw them into t.test, testing that the mean is zero, with\nsame result as before:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(pain, t.test(diff, mu=0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  diff\nt = -2.1677, df = 11, p-value = 0.05299\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -4.29941513  0.03274847\nsample estimates:\nmean of x \n-2.133333 \n```\n\n\n:::\n:::\n\n\n",
    "supporting": [
      "inference_c33_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}