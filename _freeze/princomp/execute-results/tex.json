{
  "hash": "16a029cde70d4c8bbbdb97626844df78",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Principal components\"\n---\n\n\n\n\n## Principal Components\n\n\n* Have measurements on (possibly large) number of variables on some individuals.\n\n* Question: can we describe data using fewer variables (because original variables correlated in some way)?\n\n* Look for direction (linear combination of original variables) in which values *most spread out*. This is *first principal component*.\n\n* Second principal component then direction uncorrelated with this in which values then most spread out. And so on.\n\n\n\n\n## Principal components\n\n\n* See whether small number of principal components captures most of variation in data.\n\n* Might try to interpret principal components.\n\n* If 2 components good, can make plot of data.\n\n* (Like discriminant analysis, but for individuals rather than groups.)\n\n* \"What are important ways that these data vary?\"\n\n\n\n##  Packages\n\nYou might not have installed the first of these. See over for\ninstructions. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggbiplot) \nlibrary(tidyverse)\nlibrary(ggrepel)\n```\n:::\n\n\n\n`ggbiplot` has a special installation: see over.\n\n\n##   Installing `ggbiplot`\n\n\n* `ggbiplot` not on CRAN, so usual\n`install.packages` will not work. This is same procedure you used for `smmr` in C32:\n\n* Install package `devtools` first (once):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"devtools\")\n```\n:::\n\n\n\n     \n\n* Then install `ggbiplot` (once):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(devtools)\ninstall_github(\"vqv/ggbiplot\")\n```\n:::\n\n\n\n     \n\n\n\n##  Small example: 2 test scores for 8 people\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/test12.txt\"\ntest12 <- read_table(my_url)\ntest12\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 3\n  first second id   \n  <dbl>  <dbl> <chr>\n1     2      9 A    \n2    16     40 B    \n3     8     17 C    \n4    18     43 D    \n5    10     25 E    \n6     4     10 F    \n7    10     27 G    \n8    12     30 H    \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(test12, aes(x = first, y = second, label = id)) +\n  geom_point() + geom_text_repel()\n```\n:::\n\n\n\n\\normalsize\n \n\n\n##  The plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng + geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/ff2-1.pdf)\n:::\n:::\n\n\n\n\n##  Principal component analysis\n\n\n* Grab just the numeric columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest12 %>% select(where(is.numeric)) -> test12_numbers\n```\n:::\n\n\n     \n\n\n* Strongly correlated, so data nearly 1-dimensional:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(test12_numbers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          first   second\nfirst  1.000000 0.989078\nsecond 0.989078 1.000000\n```\n\n\n:::\n:::\n\n\n\n \n## Finding principal components\n\n* Make a score summarizing this one dimension. Like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest12.pc <- princomp(test12_numbers, cor = TRUE)\nsummary(test12.pc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                         Comp.1      Comp.2\nStandard deviation     1.410347 0.104508582\nProportion of Variance 0.994539 0.005461022\nCumulative Proportion  0.994539 1.000000000\n```\n\n\n:::\n:::\n\n\n\n \n\n\n\n\n\n## Comments\n\n\n* \"Standard deviation\" shows relative importance of components\n(as for LDs in discriminant analysis)\n\n* Here, first one explains almost all (99.4\\%) of variability.\n\n* That is, look only at first component and ignore second.\n\n* `cor=TRUE` standardizes all variables first. Usually wanted,\nbecause variables measured on different scales. (Only omit if\nvariables measured on same scale and expect similar variability.)\n\n\n##   Scree plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggscreeplot(test12.pc)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-6-1.pdf)\n:::\n:::\n\n\n\n   \n\nImagine scree plot continues at zero, so 2 components is a *big*\nelbow (take one component).\n\n\n##  Component loadings\nexplain how each principal component depends on (standardized)\noriginal variables (test scores):\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest12.pc$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n       Comp.1 Comp.2\nfirst   0.707  0.707\nsecond  0.707 -0.707\n\n               Comp.1 Comp.2\nSS loadings       1.0    1.0\nProportion Var    0.5    0.5\nCumulative Var    0.5    1.0\n```\n\n\n:::\n:::\n\n\n\\normalsize\n   \n\nFirst component basically sum of (standardized) test\nscores. That is, person tends to score similarly on two tests, and a\ncomposite score would summarize performance.\n\n\n##  Component scores\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- data.frame(test12, test12.pc$scores)\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  first second id       Comp.1       Comp.2\n1     2      9  A -2.071819003 -0.146981782\n2    16     40  B  1.719862811 -0.055762223\n3     8     17  C -0.762289708  0.207589512\n4    18     43  D  2.176267535  0.042533250\n5    10     25  E -0.007460609  0.007460609\n6     4     10  F -1.734784030  0.070683441\n7    10     27  G  0.111909141 -0.111909141\n8    12     30  H  0.568313864 -0.013613668\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n\n\n\n* Person A is a low scorer, very negative `comp.1` score.\n\n* Person D is high scorer, high positive `comp.1` score.\n\n* Person E average scorer, near-zero `comp.1` score.\n\n* `comp.2` says basically nothing.\n\n\n\n\n##  Plot of scores\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d, aes(x = Comp.1, y = Comp.2, label = id)) +\n  geom_point() + geom_text_repel()\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/score-plot-1.pdf)\n:::\n:::\n\n\n  \n\n\n\n##  Comments\n\n\n* Vertical scale exaggerates importance of `comp.2`.\n\n* Fix up to get axes on same scale:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d, aes(x = Comp.1, y = Comp.2, label = id)) +\n  geom_point() + geom_text_repel() +\n  coord_fixed() -> g\n```\n:::\n\n\n\n\n\n* Shows how exam scores really spread out along one dimension:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/eqsc2-1.pdf)\n:::\n:::\n\n\n\n\n\n\n\n##  The biplot\n\n\n* Plotting variables and individuals on one plot.\n\n* Shows how components and original variables related.\n\n* Shows how individuals score on each component, and therefore\nsuggests how they score on each variable.\n\n* Add `labels` option to identify individuals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggbiplot(test12.pc, labels = test12$id)\n```\n:::\n\n\n\n     \n\n\n\n##  The biplot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/ff3-1.pdf)\n:::\n:::\n\n\n  \n\n\n\n##  Comments\n\n\n* Variables point almost same direction (right). Thus very\npositive value on `comp.1` goes with high scores on both\ntests, and test scores highly correlated.\n\n* Position of individuals on plot according to scores on\nprincipal components, implies values on original variables. Eg.:\n\n\n* D very positive on `comp.1`, high scorer on both tests.\n\n* A and F very negative on `comp.1`, poor scorers on\nboth tests.\n\n* C positive on `comp.2`, high score on first\ntest relative to second.\n\n* A negative on `comp.2`, high score on second test\nrelative to first.\n\n\n\n## Places rated\n\nEvery year, a new edition of the Places Rated Almanac is produced. This rates a large number (in our data 329) of American cities on a number of different criteria, to help people find the ideal place for them to live (based on what are important criteria for them).\n\nThe data for one year are in [http://ritsokiguess.site/datafiles/places.txt](http://ritsokiguess.site/datafiles/places.txt). The data columns are aligned but the column headings are not.\n\n## The criteria {.smaller}\n\nThere are nine of them:\n\n- `climate`: a higher value means that the weather is better\n- `housing`: a higher value means that there is more good housing or a greater choice of different types of housing\n- `health`: higher means better healthcare facilities\n- `crime`: higher means more crime (bad)\n- `trans`: higher means better transportation (this being the US, probably more roads)\n- `educate`: higher means better educational facilities, schools, colleges etc.\n- `arts`: higher means better access to the arts (theatre, music etc)\n- `recreate`: higher means better access to recreational facilities\n- `econ`: higher means a better economy (more jobs, spending power etc)\n\nEach city also has a numbered `id`.\n\n## Read in the data\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/places.txt\"\nplaces0 <- read_table(my_url)\n```\n:::\n\n\n\\normalsize\n\n## Look at distributions of everything\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces0 %>% \n  pivot_longer(-id, names_to = \"criterion\", \n               values_to = \"rating\") %>% \n  ggplot(aes(x = rating)) + geom_histogram(bins = 10) + \n  facet_wrap(~criterion, scales = \"free\") -> g\n```\n:::\n\n\n\n## The histograms\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-12-1.pdf)\n:::\n:::\n\n\n\n## Transformations\n\n- Several of these variables have long right tails\n\n- Take logs of everything but id:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces0 %>% \n  mutate(across(-id, \\(x) log(x))) -> places\n```\n:::\n\n\n\n## Just the numerical columns\n\n- get rid of the id column\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces %>% select(-id) -> places_numeric\n```\n:::\n\n\n\n## Principal components\n\n\n\n\n\n\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.1 <- princomp(places_numeric, cor = TRUE)\nsummary(places.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                          Comp.1    Comp.2    Comp.3    Comp.4     Comp.5\nStandard deviation     1.8159827 1.1016178 1.0514418 0.9525124 0.92770076\nProportion of Variance 0.3664214 0.1348402 0.1228367 0.1008089 0.09562541\nCumulative Proportion  0.3664214 0.5012617 0.6240983 0.7249072 0.82053259\n                           Comp.6     Comp.7     Comp.8     Comp.9\nStandard deviation     0.74979050 0.69557215 0.56397886 0.50112689\nProportion of Variance 0.06246509 0.05375785 0.03534135 0.02790313\nCumulative Proportion  0.88299767 0.93675552 0.97209687 1.00000000\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n\n\n\n\n\n\n## scree plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggscreeplot(places.1)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-18-1.pdf)\n:::\n:::\n\n\n\n- big elbow at 2 (1 component); smaller elbow at 6 (5) and maybe 4 (3).\n\n## What is in each component?\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces.1$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7\nclimate   0.158         0.800  0.377         0.217  0.151\nhousing   0.384  0.139         0.197 -0.580         0.275\nhealth    0.410 -0.372         0.113        -0.535 -0.135\ncrime     0.259  0.474  0.128         0.692 -0.140 -0.110\ntrans     0.375 -0.141 -0.141 -0.430  0.191  0.324  0.679\neducate   0.274 -0.452 -0.241  0.457  0.225  0.527 -0.262\narts      0.474 -0.104        -0.147        -0.321 -0.120\nrecreate  0.353  0.292        -0.404 -0.306  0.394 -0.553\necon      0.164  0.540 -0.507  0.476                0.147\n         Comp.8 Comp.9\nclimate   0.341       \nhousing  -0.606       \nhealth    0.150  0.594\ncrime    -0.420       \ntrans     0.119  0.136\neducate  -0.211 -0.110\narts      0.260 -0.747\nrecreate  0.138  0.226\necon      0.415       \n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6\nSS loadings     1.000  1.000  1.000  1.000  1.000  1.000\nProportion Var  0.111  0.111  0.111  0.111  0.111  0.111\nCumulative Var  0.111  0.222  0.333  0.444  0.556  0.667\n               Comp.7 Comp.8 Comp.9\nSS loadings     1.000  1.000  1.000\nProportion Var  0.111  0.111  0.111\nCumulative Var  0.778  0.889  1.000\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n## Assessing the components\n\nLook at component loadings and make a call about \"large\" (in absolute value) vs \"small\". Large loadings are a part of the component and small ones are not. Thus, if we use 0.4 as cutoff:\n\n- component #1 depends on health and arts\n- #2 depends on economy and crime, and negatively on education. \n- #3 depends on climate, and negatively on economy.\n- #4 depends on education and the economy, negatively on transportation and recreation opportunities.\n- #5 depends on crime and negatively on housing.\n\n## Comments\n\n- The use of 0.4 is arbitrary; you can use whatever you like. It can be difficult to decide whether a variable is \"in\" or \"out\". \n\n- The large (far from zero) loadings indicate what distinguishes the cities as places to live, for example:\n\n  - places that are rated high for health also tend to be rated high for arts\n  - places that have a good economy tend to have a bad climate (and vice versa)\n  - places that have a lot of crime tend to have bad housing.\n\n## Making a plot 1/3\n\nHow can we make a visual showing the cities? We need a \"score\" for each city on each component, and we need to identify the cities (we have a numerical `id` in the original dataset):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(city_id = places$id, places.1$scores) %>% \n  as_tibble() -> places_score\n```\n:::\n\n\n\nThe `as_tibble` is needed at the end because the scores are a `matrix`.\n\n## Making a plot 2/3\n\n- Plot the first two scores against each other, labelling each point by the `id` of the city it belongs to:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(places_score, aes(x = Comp.1, y = Comp.2, \n                         label = city_id)) +\n  geom_text() -> g\n```\n:::\n\n\n\n## Making a plot 3/3\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-22-1.pdf)\n:::\n:::\n\n\n\n\n## Comments\n\n- Cities 213 and 270 are high on component 1, and city 116 is low. City 195 is high on component 2, and city 322 is low.\n\n- This suggests that cities 213 and 270 are high on health and arts, and city 116 is low. City 195 should be high on economy and crime and low on education, and city 322 should be the other way around. \n\n## Checking this 1/2\n\n- The obvious way of checking this is in two steps: first, work out what high or low means for each variable:\n\n\n\n\n\n\n\n\n\\tiny\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(places)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    climate         housing           health          crime      \n Min.   :4.654   Min.   : 8.548   Min.   :3.761   Min.   :5.730  \n 1st Qu.:6.174   1st Qu.: 8.819   1st Qu.:6.368   1st Qu.:6.561  \n Median :6.295   Median : 8.972   Median :6.725   Median :6.853  \n Mean   :6.260   Mean   : 8.997   Mean   :6.805   Mean   :6.796  \n 3rd Qu.:6.384   3rd Qu.: 9.107   3rd Qu.:7.276   3rd Qu.:7.053  \n Max.   :6.813   Max.   :10.071   Max.   :8.968   Max.   :7.823  \n     trans          educate           arts           recreate    \n Min.   :7.043   Min.   :7.439   Min.   : 3.951   Min.   :5.704  \n 1st Qu.:8.052   1st Qu.:7.871   1st Qu.: 6.657   1st Qu.:7.182  \n Median :8.314   Median :7.935   Median : 7.534   Median :7.421  \n Mean   :8.283   Mean   :7.936   Mean   : 7.383   Mean   :7.429  \n 3rd Qu.:8.557   3rd Qu.:8.010   3rd Qu.: 8.254   3rd Qu.:7.685  \n Max.   :9.062   Max.   :8.238   Max.   :10.946   Max.   :8.476  \n      econ             id     \n Min.   :8.021   Min.   :  1  \n 1st Qu.:8.485   1st Qu.: 83  \n Median :8.591   Median :165  \n Mean   :8.598   Mean   :165  \n 3rd Qu.:8.718   3rd Qu.:247  \n Max.   :9.208   Max.   :329  \n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n\n\n\n\n\n\n## Checking this 2/2\n\n- and then find the values on the variables of interest for our cities of interest, and see where they sit on here.\n\n- Cities 270, 213, and 116 were extreme on component 1, which depended mainly on health and arts:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces %>% select(id, health, arts) %>% \n  filter(id %in% c(270, 213, 166))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 3\n     id health  arts\n  <dbl>  <dbl> <dbl>\n1   166   6.14  5.01\n2   213   8.97 10.9 \n3   270   8.22  9.56\n```\n\n\n:::\n:::\n\n\n\nCity 166 is near or below Q1 on both variables. City 213 is the highest of all on both `health` and `arts`, while city 270 is well above Q3 on both.\n\n## Checking component 2\n\n- Component 2 depended positively on economy and crime and negatively on education. City 195 was high and 322 was low:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces %>% select(id, econ, crime, educate) %>% \n  filter(id %in% c(195, 322))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 4\n     id  econ crime educate\n  <dbl> <dbl> <dbl>   <dbl>\n1   195  9.21  7.06    7.79\n2   322  8.10  6.14    7.97\n```\n\n\n:::\n:::\n\n\n\n- City 195 is the highest on economy, just above Q3 on crime, and below Q1 on education. City 322 should be the other way around: nearly the lowest on economy, below Q1 on crime, and between the median and Q3 on education. This is as we'd expect.\n\n## A better way: percentile ranks\n\n- It is a lot of work to find the value of each city on each variable in the data summary. \n\n- A  better way is to work out the percentile ranks of each city on each variable and then look at those:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces %>% \n  mutate(across(-id, \\(x) percent_rank(x))) -> places_pr\n```\n:::\n\n\n\n## Look up cities and variables again\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_pr %>% select(id, health, arts) %>% \n  filter(id %in% c(270, 213, 166))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 3\n     id health   arts\n  <dbl>  <dbl>  <dbl>\n1   166  0.152 0.0488\n2   213  1     1     \n3   270  0.970 0.982 \n```\n\n\n:::\n:::\n\n\n\nThis shows that city 270 was also really high on these two variables: in the 97th percentile for `health` and the 98th for `arts`. \n\n## Component 2\n\n- What about the extreme cities on component 2?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaces_pr %>% select(id, econ, crime, educate) %>% \n  filter(id %in% c(195, 322)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 4\n     id    econ  crime educate\n  <dbl>   <dbl>  <dbl>   <dbl>\n1   195 1       0.762   0.0884\n2   322 0.00610 0.0732  0.631 \n```\n\n\n:::\n:::\n\n\n\n- City 322 was really low on economy and crime, but only just above average on education. City 195 was the highest on economy and really low on education, but only somewhat high on crime (76th percentile).\n\n- This, as you see, is much easier once you have set it up.\n\n## The biplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbiplot(places.1, labels = places$id)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-31-1.pdf)\n:::\n:::\n\n\n\n## Comments\n\n- This is hard to read!\n- There are a lot of cities that overshadow the red arrows for the variables.\n- reduce the size of the city labels\n\n## Biplot, attempt 2\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbiplot(places.1, labels = places$id,\n         labels.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/bPrincomp-32-1.pdf)\n:::\n:::\n\n\n\n## Comments on attempt #2\n\n- Now at least can see the variables\n- All of them point somewhat right (all belong partly to component 1)\n- Some of them (economy, crime, education) point up/down, belong to component 2 as well.\n- In this case, cannot really see both observations (cities) and variables (criteria) together, which defeats the purpose of the biplot. \n- Have to try it and see.\n\n\n##  Principal components from correlation matrix\nCreate data file like this:\n\n```\n 1        0.9705 -0.9600\n 0.9705   1      -0.9980\n-0.9600  -0.9980  1\n```\n\nand read in like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/cov.txt\"\nmat <- read_table(my_url, col_names = F)\nmat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 3\n      X1     X2     X3\n   <dbl>  <dbl>  <dbl>\n1  1      0.970 -0.96 \n2  0.970  1     -0.998\n3 -0.96  -0.998  1    \n```\n\n\n:::\n:::\n\n\n\n   \n\n\n##  Pre-processing\nA little pre-processing required:\n\n\n* Turn into matrix (from data frame)\n\n* Feed into `princomp` as `covmat=`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat.pc <- mat %>%\n  as.matrix() %>%\n  princomp(covmat = .)\n```\n:::\n\n\n\n   \n\n\n##  Scree plot: one component fine\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggscreeplot(mat.pc)\n```\n\n::: {.cell-output-display}\n![](princomp_files/figure-beamer/palermo-1.pdf)\n:::\n:::\n\n\n  \n\n\n\n##  Component loadings\nCompare correlation matrix:\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 3\n      X1     X2     X3\n   <dbl>  <dbl>  <dbl>\n1  1      0.970 -0.96 \n2  0.970  1     -0.998\n3 -0.96  -0.998  1    \n```\n\n\n:::\n:::\n\n\n\\normalsize\n  \n\nwith component loadings\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat.pc$loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n   Comp.1 Comp.2 Comp.3\nX1  0.573  0.812  0.112\nX2  0.581 -0.306 -0.755\nX3 -0.578  0.498 -0.646\n\n               Comp.1 Comp.2 Comp.3\nSS loadings     1.000  1.000  1.000\nProportion Var  0.333  0.333  0.333\nCumulative Var  0.333  0.667  1.000\n```\n\n\n:::\n:::\n\n\n\\normalsize\n\n## Comments\n\n* When X1 large, X2 also large, X3 small.\n\n  * Then `comp.1` *positive*.\n\n* When X1 small, X2 small, X3 large.\n\n  * Then `comp.1` *negative*.\n\n\n##  No scores\n\n\n* With correlation matrix rather than data, no component scores\n\n  * So no principal component plot\n\n  * and no biplot. \n\n\n\n\n\n",
    "supporting": [
      "princomp_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}