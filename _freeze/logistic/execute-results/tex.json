{
  "hash": "f64f2649a70545f0ebaadae0250801e9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Logistic Regression\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Logistic regression\n\n-   When response variable is measured/counted, regression can work\n    well.\n\n-   But what if response is yes/no, lived/died, success/failure?\n\n-   Model *probability* of success.\n\n-   Probability must be between 0 and 1; need method that ensures this.\n\n-   *Logistic regression* does this. In R, is a *generalized linear\n    model* with binomial \"family\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y ~ x, family=\"binomial\")\n```\n:::\n\n\n\n\n-   Begin with simplest case.\n\n## Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS, exclude = \"select\")\nlibrary(tidyverse)\nlibrary(marginaleffects)\nlibrary(broom)\nlibrary(nnet)\n# library(conflicted)\n# conflict_prefer(\"select\", \"dplyr\")\n# conflict_prefer(\"filter\", \"dplyr\")\n# conflict_prefer(\"rename\", \"dplyr\")\n# conflict_prefer(\"summarize\", \"dplyr\")\n```\n:::\n\n\n\n\n## The rats, part 1\n\n-   Rats given dose of some poison; either live or die:\n\n```         \ndose status\n0 lived\n1 died\n2 lived\n3 lived\n4 died\n5 died\n```\n\n## Read in:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rat.txt\"\nrats <- read_delim(my_url, \" \")\nrats\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 2\n   dose status\n  <dbl> <chr> \n1     0 lived \n2     1 died  \n3     2 lived \n4     3 lived \n5     4 died  \n6     5 died  \n```\n\n\n:::\n:::\n\n\n\n\n## This doesn't work\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus.0 <- glm(status ~ dose, family = \"binomial\", data = rats)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(family$initialize): y values must be 0 <= y <= 1\n```\n\n\n:::\n:::\n\n\n\n\nValues of response variable (here `status`) must be either:\n\n- 1 = \"success\", 0 = \"failure\"\n- a `factor` (not text) with two levels.\n\n## Basic logistic regression\n\n-   So, make response into a factor first:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrats2 <- rats %>% mutate(status = factor(status))\nrats2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 2\n   dose status\n  <dbl> <fct> \n1     0 lived \n2     1 died  \n3     2 lived \n4     3 lived \n5     4 died  \n6     5 died  \n```\n\n\n:::\n:::\n\n\n\n\n-   then fit model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus.1 <- glm(status ~ dose, family = \"binomial\", data = rats2)\n```\n:::\n\n\n\n\n## Output\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(status.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = status ~ dose, family = \"binomial\", data = rats2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   1.6841     1.7979   0.937    0.349\ndose         -0.6736     0.6140  -1.097    0.273\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8.3178  on 5  degrees of freedom\nResidual deviance: 6.7728  on 4  degrees of freedom\nAIC: 10.773\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n## Interpreting the output\n\n-   Like (multiple) regression, get tests of significance of individual\n    $x$'s\n\n-   Here not significant (only 6 observations).\n\n-   \"Slope\" for dose is negative, meaning that as dose increases,\n    probability of event modelled (survival) decreases.\n\n## Output part 2: predicted survival probs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(status.1)) %>% \n  select(dose, estimate, conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dose  estimate    conf.low conf.high\n1    0 0.8434490 0.137095792 0.9945564\n2    1 0.7331122 0.173186479 0.9729896\n3    2 0.5834187 0.168847561 0.9061463\n4    3 0.4165813 0.093853682 0.8311524\n5    4 0.2668878 0.027010413 0.8268135\n6    5 0.1565510 0.005443589 0.8629042\n```\n\n\n:::\n:::\n\n\n\n\n## On a graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(status.1, condition = \"dose\")\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## The rats, more\n\n-   More realistic: more rats at each dose (say 10).\n\n-   Listing each rat on one line makes a big data file.\n\n-   Use format below: dose, number of survivals, number of deaths.\n\n```         \n\ndose lived died\n0    10    0\n1     7    3 \n2     6    4 \n3     4    6 \n4     2    8 \n5     1    9  \n```\n\n-   6 lines of data correspond to 60 actual rats.\n\n-   Saved in `rat2.txt`.\n\n## These data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rat2.txt\"\nrat2 <- read_delim(my_url, \" \")\nrat2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 3\n   dose lived  died\n  <dbl> <dbl> <dbl>\n1     0    10     0\n2     1     7     3\n3     2     6     4\n4     3     4     6\n5     4     2     8\n6     5     1     9\n```\n\n\n:::\n:::\n\n\n\n\n## Response matrix:\n\n-   Each row contains *multiple* observations.\n-   Create *two-column* response with `cbind`:\n    -   #survivals in first column,\n    -   #deaths in second.\n    \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(rat2, cbind(lived, died))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     lived died\n[1,]    10    0\n[2,]     7    3\n[3,]     6    4\n[4,]     4    6\n[5,]     2    8\n[6,]     1    9\n```\n\n\n:::\n:::\n\n\n\n\n\n## Fit logistic regression\n\n-   constructing the response in the `glm`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrat2.1 <- glm(cbind(lived, died) ~ dose, family = \"binomial\", data = rat2)\n```\n:::\n\n\n\n\n## Output\n\nSignificant effect of dose now:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rat2.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(lived, died) ~ dose, family = \"binomial\", \n    data = rat2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   2.3619     0.6719   3.515 0.000439 ***\ndose         -0.9448     0.2351  -4.018 5.87e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 27.530  on 5  degrees of freedom\nResidual deviance:  2.474  on 4  degrees of freedom\nAIC: 18.94\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n## Predicted survival probs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = rat2.1, dose = 0:5)\ncbind(predictions(rat2.1, newdata = new)) %>% \n  select(estimate, dose, conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   estimate dose   conf.low conf.high\n1 0.9138762    0 0.73983042 0.9753671\n2 0.8048905    1 0.61695841 0.9135390\n3 0.6159474    2 0.44876099 0.7595916\n4 0.3840526    3 0.24040837 0.5512390\n5 0.1951095    4 0.08646093 0.3830417\n6 0.0861238    5 0.02463288 0.2601697\n```\n\n\n:::\n:::\n\n\n\n\n## On a picture\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(rat2.1, condition = \"dose\")\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(rat2.1, condition = \"dose\", type = \"link\")\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n## Comments\n\n-   Significant effect of dose.\n\n-   Effect of larger dose is to *decrease* survival probability (\"slope\"\n    negative; also see in decreasing predictions.)\n\n-   Confidence intervals around prediction narrower (more data).\n\n## Multiple logistic regression\n\n-   With more than one $x$, works much like multiple regression.\n\n-   Example: study of patients with blood poisoning severe enough to\n    warrant surgery. Relate survival to other potential risk factors.\n\n-   Variables, 1=present, 0=absent:\n\n    -   survival (death from sepsis=1), response\n    -   shock\n    -   malnutrition\n    -   alcoholism\n    -   age (as numerical variable)\n    -   bowel infarction\n\n-   See what relates to death.\n\n## Read in data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \n  \"http://ritsokiguess.site/datafiles/sepsis.txt\"\nsepsis <- read_delim(my_url, \" \")\nsepsis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 106 x 6\n   death shock malnut alcohol   age bowelinf\n   <dbl> <dbl>  <dbl>   <dbl> <dbl>    <dbl>\n 1     0     0      0       0    56        0\n 2     0     0      0       0    80        0\n 3     0     0      0       0    61        0\n 4     0     0      0       0    26        0\n 5     0     0      0       0    53        0\n 6     1     0      1       0    87        0\n 7     0     0      0       0    21        0\n 8     1     0      0       1    69        0\n 9     0     0      0       0    57        0\n10     0     0      1       0    76        0\n# i 96 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Make sure categoricals really are\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis %>% \n  mutate(across(-age, \\(x) factor(x))) -> sepsis\n```\n:::\n\n\n\n\n## The data (some)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 106 x 6\n   death shock malnut alcohol   age bowelinf\n   <fct> <fct> <fct>  <fct>   <dbl> <fct>   \n 1 0     0     0      0          56 0       \n 2 0     0     0      0          80 0       \n 3 0     0     0      0          61 0       \n 4 0     0     0      0          26 0       \n 5 0     0     0      0          53 0       \n 6 1     0     1      0          87 0       \n 7 0     0     0      0          21 0       \n 8 1     0     0      1          69 0       \n 9 0     0     0      0          57 0       \n10 0     0     1      0          76 0       \n# i 96 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Fit model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.1 <- glm(death ~ shock + malnut + alcohol + age +\n  bowelinf,\nfamily = \"binomial\",\ndata = sepsis\n)\n```\n:::\n\n\n\n\n## Output part 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sepsis.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = death ~ shock + malnut + alcohol + age + bowelinf, \n    family = \"binomial\", data = sepsis)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -9.75391    2.54170  -3.838 0.000124 ***\nshock1       3.67387    1.16481   3.154 0.001610 ** \nmalnut1      1.21658    0.72822   1.671 0.094798 .  \nalcohol1     3.35488    0.98210   3.416 0.000635 ***\nage          0.09215    0.03032   3.039 0.002374 ** \nbowelinf1    2.79759    1.16397   2.403 0.016240 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 105.528  on 105  degrees of freedom\nResidual deviance:  53.122  on 100  degrees of freedom\nAIC: 65.122\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n\n```{.r .cell-code}\ntidy(sepsis.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -9.75      2.54       -3.84 0.000124\n2 shock1        3.67      1.16        3.15 0.00161 \n3 malnut1       1.22      0.728       1.67 0.0948  \n4 alcohol1      3.35      0.982       3.42 0.000635\n5 age           0.0922    0.0303      3.04 0.00237 \n6 bowelinf1     2.80      1.16        2.40 0.0162  \n```\n\n\n:::\n:::\n\n\n\n\n-   All P-values fairly small\n\n-   but `malnut` not significant: remove.\n\n## Removing `malnut`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2 <- update(sepsis.1, . ~ . - malnut)\nsummary(sepsis.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = death ~ shock + alcohol + age + bowelinf, family = \"binomial\", \n    data = sepsis)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.89459    2.31689  -3.839 0.000124 ***\nshock1       3.70119    1.10353   3.354 0.000797 ***\nalcohol1     3.18590    0.91725   3.473 0.000514 ***\nage          0.08983    0.02922   3.075 0.002106 ** \nbowelinf1    2.38647    1.07227   2.226 0.026039 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 105.528  on 105  degrees of freedom\nResidual deviance:  56.073  on 101  degrees of freedom\nAIC: 66.073\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n\n```{.r .cell-code}\ntidy(sepsis.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -8.89      2.32       -3.84 0.000124\n2 shock1        3.70      1.10        3.35 0.000797\n3 alcohol1      3.19      0.917       3.47 0.000514\n4 age           0.0898    0.0292      3.07 0.00211 \n5 bowelinf1     2.39      1.07        2.23 0.0260  \n```\n\n\n:::\n:::\n\n\n\n\n-   Everything significant now.\n\n## Comments\n\n-   Most of the original $x$'s helped predict death. Only `malnut`\n    seemed not to add anything.\n\n-   Removed `malnut` and tried again.\n\n-   Everything remaining is significant (though `bowelinf` actually\n    became *less* significant).\n\n-   All coefficients are *positive*, so having any of the risk factors\n    (or being older) *increases* risk of death.\n\n## Predictions from model without \"malnut\"\n\n-   A few (rows of original dataframe) chosen \"at random\":\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis %>% slice(c(4, 1, 2, 11, 32)) -> new\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 6\n  death shock malnut alcohol   age bowelinf\n  <fct> <fct> <fct>  <fct>   <dbl> <fct>   \n1 0     0     0      0          26 0       \n2 0     0     0      0          56 0       \n3 0     0     0      0          80 0       \n4 1     0     0      1          66 1       \n5 1     0     0      1          49 0       \n```\n\n\n:::\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, conf.low, conf.high, shock:bowelinf) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     estimate     conf.low  conf.high shock malnut alcohol age bowelinf\n1 0.001415347 6.272642e-05 0.03103047     0      0       0  26        0\n2 0.020552383 4.102504e-03 0.09656596     0      0       0  56        0\n3 0.153416834 5.606838e-02 0.35603441     0      0       0  80        0\n4 0.931290137 5.490986e-01 0.99341482     0      0       1  66        1\n5 0.213000997 7.639063e-02 0.46967947     0      0       1  49        0\n```\n\n\n:::\n:::\n\n\n\n\n## Comments\n\n-   Survival chances pretty good if no risk factors, though decreasing\n    with age.\n\n-   Having more than one risk factor reduces survival chances\n    dramatically.\n\n-   Usually good job of predicting survival; sometimes death predicted\n    to survive.\n\n## Another way to assess effects\n\nof `age`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = sepsis.2, age = seq(30, 70, 10))\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  shock alcohol bowelinf age rowid\n1     0       0        0  30     1\n2     0       0        0  40     2\n3     0       0        0  50     3\n4     0       0        0  60     4\n5     0       0        0  70     5\n```\n\n\n:::\n:::\n\n\n\n\n## Assessing age effect\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, shock:age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     estimate shock alcohol bowelinf age\n1 0.002026053     0       0        0  30\n2 0.004960283     0       0        0  40\n3 0.012092515     0       0        0  50\n4 0.029179226     0       0        0  60\n5 0.068729752     0       0        0  70\n```\n\n\n:::\n:::\n\n\n\n\n## Assessing shock effect\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(shock = c(0, 1), model = sepsis.2)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  alcohol      age bowelinf shock rowid\n1       0 51.28302        0     0     1\n2       0 51.28302        0     1     2\n```\n\n\n:::\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, death:shock)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    estimate death shock\n1 0.01354973     0     0\n2 0.35742607     0     1\n```\n\n\n:::\n:::\n\n\n\n\n## Assessing proportionality of odds for age\n\n-   An assumption we made is that log-odds of survival depends linearly\n    on age.\n\n-   Hard to get your head around, but basic idea is that survival\n    chances go continuously up (or down) with age, instead of (for\n    example) going up and then down.\n\n-   In this case, seems reasonable, but should check:\n\n## Residuals vs. age\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2 %>% augment(sepsis) %>% \n  ggplot(aes(x = age, y = .resid, colour = death)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/virtusentella-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   No apparent problems overall.\n\n-   Confusing \"line\" across: no risk factors, survived.\n\n## Probability and odds\n\nFor probability $p$, odds is $p/(1-p)$:\n\n| Prob | Odds             | Log-odds | Words      |\n|------|------------------|----------|------------|\n| 0.5  | 0.5 / 0.5 = 1.00 | 0.00     | even money |\n| 0.1  | 0.1 / 0.9 = 0.11 | -2.20    | 9 to 1     |\n| 0.4  | 0.4 / 0.6 = 0.67 | -0.41    | 1.5 to 1   |\n| 0.8  | 0.8 / 0.2 = 4.00 | 1.39     | 4 to 1 on  |\n\n-   Gamblers use odds: if you win at 9 to 1 odds, get original stake\n    back plus 9 times the stake.\n\n-   Probability has to be between 0 and 1\n\n-   Odds between 0 and infinity\n\n-   *Log*-odds can be anything: any log-odds corresponds to valid\n    probability.\n    \n-   Thus, predict *log-odds of probability* from explanatory variable(s), rather than probability itself.\n\n## Odds ratio\n\n-   Suppose 90 of 100 men drank wine last week, but only 20 of 100\n    women.\n\n-   Prob of man drinking wine $90/100=0.9$, woman $20/100=0.2$.\n\n-   Odds of man drinking wine $0.9/0.1=9$, woman $0.2/0.8=0.25$.\n\n-   Ratio of odds is $9/0.25=36$.\n\n-   Way of quantifying difference between men and women: \"odds of\n    drinking wine 36 times larger for males than females\".\n\n## Sepsis data again\n\n-   Recall prediction of probability of death from risk factors:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 106 x 6\n   death shock malnut alcohol   age bowelinf\n   <fct> <fct> <fct>  <fct>   <dbl> <fct>   \n 1 0     0     0      0          56 0       \n 2 0     0     0      0          80 0       \n 3 0     0     0      0          61 0       \n 4 0     0     0      0          26 0       \n 5 0     0     0      0          53 0       \n 6 1     0     1      0          87 0       \n 7 0     0     0      0          21 0       \n 8 1     0     0      1          69 0       \n 9 0     0     0      0          57 0       \n10 0     0     1      0          76 0       \n# i 96 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(sepsis.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = death ~ shock + alcohol + age + bowelinf, family = \"binomial\", \n    data = sepsis)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -8.89459    2.31689  -3.839 0.000124 ***\nshock1       3.70119    1.10353   3.354 0.000797 ***\nalcohol1     3.18590    0.91725   3.473 0.000514 ***\nage          0.08983    0.02922   3.075 0.002106 ** \nbowelinf1    2.38647    1.07227   2.226 0.026039 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 105.528  on 105  degrees of freedom\nResidual deviance:  56.073  on 101  degrees of freedom\nAIC: 66.073\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n\n```{.r .cell-code}\nsepsis.2.tidy <- tidy(sepsis.2)\nsepsis.2.tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -8.89      2.32       -3.84 0.000124\n2 shock1        3.70      1.10        3.35 0.000797\n3 alcohol1      3.19      0.917       3.47 0.000514\n4 age           0.0898    0.0292      3.07 0.00211 \n5 bowelinf1     2.39      1.07        2.23 0.0260  \n```\n\n\n:::\n:::\n\n\n\n\n-   Slopes in column `estimate`.\n\n## Multiplying the odds\n\n-   Can interpret slopes by taking \"exp\" of them. We ignore intercept.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2.tidy %>% \n  mutate(exp_coeff=exp(estimate)) %>% \n  select(term, exp_coeff)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  term        exp_coeff\n  <chr>           <dbl>\n1 (Intercept)  0.000137\n2 shock1      40.5     \n3 alcohol1    24.2     \n4 age          1.09    \n5 bowelinf1   10.9     \n```\n\n\n:::\n:::\n\n\n\n\n## Interpretation\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  term        exp_coeff\n  <chr>           <dbl>\n1 (Intercept)  0.000137\n2 shock1      40.5     \n3 alcohol1    24.2     \n4 age          1.09    \n5 bowelinf1   10.9     \n```\n\n\n:::\n:::\n\n\n\n\n-   These say \"how much do you *multiply* odds of death by for increase\n    of 1 in corresponding risk factor?\" Or, what is odds ratio for that\n    factor being 1 (present) vs. 0 (absent)?\n\n-   Eg. being alcoholic vs. not increases odds of death by 24 times\n\n-   One year older multiplies odds by about 1.1 times. Over 40 years,\n    about $1.09^{40}=31$ times.\n\n## Odds ratio and relative risk\n\n-   **Relative risk** is ratio of probabilities.\n\n-   Above: 90 of 100 men (0.9) drank wine, 20 of 100 women (0.2).\n\n-   Relative risk 0.9/0.2=4.5. (odds ratio was 36).\n\n-   When probabilities small, relative risk and odds ratio similar.\n\n-   Eg. prob of man having disease 0.02, woman 0.01.\n\n-   Relative risk $0.02/0.01=2$.\n\n## Odds ratio vs. relative risk\n\n-   Odds for men and for women:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(od1 <- 0.02 / 0.98) # men\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02040816\n```\n\n\n:::\n\n```{.r .cell-code}\n(od2 <- 0.01 / 0.99) # women\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01010101\n```\n\n\n:::\n:::\n\n\n\n\n-   Odds ratio\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nod1 / od2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.020408\n```\n\n\n:::\n:::\n\n\n\n\n-   Very close to relative risk of 2.\n\n## More than 2 response categories\n\n-   With 2 response categories, model the probability of one, and prob\n    of other is one minus that. So doesn't matter which category you\n    model.\n\n-   With more than 2 categories, have to think more carefully about the\n    categories: are they\n\n-   *ordered*: you can put them in a natural order (like low, medium,\n    high)\n\n-   *nominal*: ordering the categories doesn't make sense (like red,\n    green, blue).\n\n-   R handles both kinds of response; learn how.\n\n## Ordinal response: the miners\n\n-   Model probability of being in given category *or lower*.\n\n-   Example: coal-miners often suffer disease pneumoconiosis. Likelihood\n    of disease believed to be greater among miners who have worked\n    longer.\n\n-   Severity of disease measured on categorical scale: none, moderate,\n    severe.\n\n## Miners data\n\n-   Data are frequencies:\n\n```         \nExposure None Moderate Severe\n5.8       98      0       0\n15.0      51      2       1\n21.5      34      6       3\n27.5      35      5       8\n33.5      32     10       9\n39.5      23      7       8\n46.0      12      6      10\n51.5       4      2       5\n```\n\n## Reading the data\n\nData in aligned columns with more than one space between, so:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/miners-tab.txt\"\nfreqs <- read_table(my_url)\n```\n:::\n\n\n\n\n## The data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 4\n  Exposure  None Moderate Severe\n     <dbl> <dbl>    <dbl>  <dbl>\n1      5.8    98        0      0\n2     15      51        2      1\n3     21.5    34        6      3\n4     27.5    35        5      8\n5     33.5    32       10      9\n6     39.5    23        7      8\n7     46      12        6     10\n8     51.5     4        2      5\n```\n\n\n:::\n:::\n\n\n\n\n## Tidying\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs %>%\n  pivot_longer(-Exposure, names_to = \"Severity\", values_to = \"Freq\") %>%\n  mutate(Severity = fct_inorder(Severity)) -> miners\n```\n:::\n\n\n\n\n## Result\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24 x 3\n   Exposure Severity  Freq\n      <dbl> <fct>    <dbl>\n 1      5.8 None        98\n 2      5.8 Moderate     0\n 3      5.8 Severe       0\n 4     15   None        51\n 5     15   Moderate     2\n 6     15   Severe       1\n 7     21.5 None        34\n 8     21.5 Moderate     6\n 9     21.5 Severe       3\n10     27.5 None        35\n# i 14 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(miners$Severity)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"None\"     \"Moderate\" \"Severe\"  \n```\n\n\n:::\n:::\n\n\n\n\n\n## Plot proportions against exposure 1/2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers %>% \n  group_by(Exposure) %>% \n  mutate(proportion = Freq / sum(Freq)) -> prop\nprop\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24 x 4\n# Groups:   Exposure [8]\n   Exposure Severity  Freq proportion\n      <dbl> <fct>    <dbl>      <dbl>\n 1      5.8 None        98     1     \n 2      5.8 Moderate     0     0     \n 3      5.8 Severe       0     0     \n 4     15   None        51     0.944 \n 5     15   Moderate     2     0.0370\n 6     15   Severe       1     0.0185\n 7     21.5 None        34     0.791 \n 8     21.5 Moderate     6     0.140 \n 9     21.5 Severe       3     0.0698\n10     27.5 None        35     0.729 \n# i 14 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Plot proportions against exposure 2/2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(prop, aes(x = Exposure, y = proportion,\n                   colour = Severity)) + \n  geom_point() + geom_smooth(se = F)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n## Reminder of data setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24 x 3\n   Exposure Severity  Freq\n      <dbl> <fct>    <dbl>\n 1      5.8 None        98\n 2      5.8 Moderate     0\n 3      5.8 Severe       0\n 4     15   None        51\n 5     15   Moderate     2\n 6     15   Severe       1\n 7     21.5 None        34\n 8     21.5 Moderate     6\n 9     21.5 Severe       3\n10     27.5 None        35\n# i 14 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Fitting ordered logistic model\n\nUse function `polr` from package `MASS`. Like `glm`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.1 <- polr(Severity ~ Exposure,\n  weights = Freq,\n  data = miners\n)\n```\n:::\n\n\n\n\n## Output: not very illuminating\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.1 <- polr(Severity ~ Exposure,\n  weights = Freq,\n  data = miners,\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sev.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\npolr(formula = Severity ~ Exposure, data = miners, weights = Freq)\n\nCoefficients:\n          Value Std. Error t value\nExposure 0.0959    0.01194   8.034\n\nIntercepts:\n                Value   Std. Error t value\nNone|Moderate    3.9558  0.4097     9.6558\nModerate|Severe  4.8690  0.4411    11.0383\n\nResidual Deviance: 416.9188 \nAIC: 422.9188 \n```\n\n\n:::\n:::\n\n\n\n\n## Does exposure have an effect?\n\nFit model without `Exposure`, and compare using `anova`. Note `1` for\nmodel with just intercept:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.0 <- polr(Severity ~ 1, weights = Freq, data = miners)\nanova(sev.0, sev.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of ordinal regression models\n\nResponse: Severity\n     Model Resid. df Resid. Dev   Test    Df LR stat.\n1        1       369   505.1621                      \n2 Exposure       368   416.9188 1 vs 2     1 88.24324\n  Pr(Chi)\n1        \n2       0\n```\n\n\n:::\n:::\n\n\n\n\nExposure definitely has effect on severity of disease.\n\n## Another way\n\n-   What (if anything) can we drop from model with `exposure`?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(sev.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nSeverity ~ Exposure\n         Df    AIC    LRT  Pr(>Chi)    \n<none>      422.92                     \nExposure  1 509.16 88.243 < 2.2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n-   Nothing. Exposure definitely has effect.\n\n## Predicted probabilities 1/2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs %>% select(Exposure) -> new\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 1\n  Exposure\n     <dbl>\n1      5.8\n2     15  \n3     21.5\n4     27.5\n5     33.5\n6     39.5\n7     46  \n8     51.5\n```\n\n\n:::\n:::\n\n\n\n\n## Predicted probabilities 2/2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(sev.1, newdata = new)) %>%\n  select(group, estimate, Exposure) %>% \n  pivot_wider(names_from = group, values_from = estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 4\n  Exposure  None Moderate Severe\n     <dbl> <dbl>    <dbl>  <dbl>\n1      5.8 0.968   0.0191 0.0132\n2     15   0.925   0.0433 0.0314\n3     21.5 0.869   0.0739 0.0569\n4     27.5 0.789   0.114  0.0969\n5     33.5 0.678   0.162  0.160 \n6     39.5 0.542   0.205  0.253 \n7     46   0.388   0.224  0.388 \n8     51.5 0.272   0.210  0.517 \n```\n\n\n:::\n:::\n\n\n\n\n## Plot of predicted probabilities\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(model = sev.1, condition = c(\"Exposure\", \"group\"), type = \"probs\") + \n  geom_point(data = prop, aes(x = Exposure, y = proportion, colour = Severity)) -> ggg\n```\n:::\n\n\n\n\n## The graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggg\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   Model appears to match data well enough.\n\n-   As exposure goes up, prob of None goes down, Severe goes up (sharply\n    for high exposure).\n\n-   So more exposure means worse disease.\n\n## Unordered responses\n\n-   With unordered (nominal) responses, can use *generalized logit*.\n\n-   Example: 735 people, record age and sex (male 0, female 1), which of\n    3 brands of some product preferred.\n\n-   Data in `mlogit.csv` separated by commas (so `read_csv` will work):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/mlogit.csv\"\nbrandpref <- read_csv(my_url)\n```\n:::\n\n\n\n\n## The data (some)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 735 x 3\n   brand   sex   age\n   <dbl> <dbl> <dbl>\n 1     1     0    24\n 2     1     0    26\n 3     1     0    26\n 4     1     1    27\n 5     1     1    27\n 6     3     1    27\n 7     1     0    27\n 8     1     0    27\n 9     1     1    27\n10     1     0    27\n# i 725 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Bashing into shape\n\n-   `sex` and `brand` not meaningful as numbers, so turn into factors:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref %>%\n  mutate(sex = ifelse(sex == 1, \"female\", \"male\"), \n         sex = factor(sex),\n         brand = factor(brand)\n         ) -> brandpref\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 735 x 3\n   brand sex      age\n   <fct> <fct>  <dbl>\n 1 1     male      24\n 2 1     male      26\n 3 1     male      26\n 4 1     female    27\n 5 1     female    27\n 6 3     female    27\n 7 1     male      27\n 8 1     male      27\n 9 1     female    27\n10 1     male      27\n# i 725 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nbrandpref %>% count(sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  sex        n\n  <fct>  <int>\n1 female   466\n2 male     269\n```\n\n\n:::\n:::\n\n\n\n\n## Fitting model\n\n-   We use `multinom` from package `nnet`. Works like `polr`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nnet)\n# levels(brandpref$sex)\n\nbrands.1 <- multinom(brand ~ age + sex, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# weights:  12 (6 variable)\ninitial  value 807.480032 \niter  10 value 702.990572\nfinal  value 702.970704 \nconverged\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nmultinom(formula = brand ~ age + sex, data = brandpref)\n\nCoefficients:\n  (Intercept)       age    sexmale\n2   -11.25127 0.3682202 -0.5237736\n3   -22.25571 0.6859149 -0.4658215\n\nStd. Errors:\n  (Intercept)        age   sexmale\n2    1.765184 0.05500373 0.1942473\n3    2.042636 0.06262721 0.2260901\n\nResidual Deviance: 1405.941 \nAIC: 1417.941 \n```\n\n\n:::\n:::\n\n\n\n\n## Can we drop anything?\n\n-   Unfortunately `drop1` seems not to work:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(brands.1, test = \"Chisq\", trace = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntrying - age \n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError in if (trace) {: argument is not interpretable as logical\n```\n\n\n:::\n:::\n\n\n\n\n-   So, fall back on fitting model without what you want to test, and\n    comparing using `anova`.\n\n## Do age/sex help predict brand? 1/3\n\nFit models without each of age and sex:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrands.2 <- multinom(brand ~ age, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# weights:  9 (4 variable)\ninitial  value 807.480032 \niter  10 value 706.796323\niter  10 value 706.796322\nfinal  value 706.796322 \nconverged\n```\n\n\n:::\n\n```{.r .cell-code}\nbrands.3 <- multinom(brand ~ sex, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# weights:  9 (4 variable)\ninitial  value 807.480032 \nfinal  value 791.861266 \nconverged\n```\n\n\n:::\n:::\n\n\n\n\n## Do age/sex help predict brand? 2/3\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(brands.2, brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       age      1466   1413.593                      \n2 age + sex      1464   1405.941 1 vs 2     2 7.651236\n     Pr(Chi)\n1           \n2 0.02180496\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(brands.3, brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       sex      1466   1583.723                      \n2 age + sex      1464   1405.941 1 vs 2     2 177.7811\n  Pr(Chi)\n1        \n2       0\n```\n\n\n:::\n:::\n\n\n\n\n## Do age/sex help predict brand? 3/3\n\n-   `age` definitely significant (second `anova`)\n\n-   `sex` significant also (first `anova`), though P-value less dramatic\n\n-   Keep both.\n\n-   Expect to see a large effect of `age`, and a smaller one of `sex`.\n\n## Another way to build model\n\n-   Start from model with everything and run `step`:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=1417.94\nbrand ~ age + sex\n\ntrying - age \n# weights:  9 (4 variable)\ninitial  value 807.480032 \nfinal  value 791.861266 \nconverged\ntrying - sex \n# weights:  9 (4 variable)\ninitial  value 807.480032 \niter  10 value 706.796323\niter  10 value 706.796322\nfinal  value 706.796322 \nconverged\n       Df      AIC\n<none>  6 1417.941\n- sex   4 1421.593\n- age   4 1591.723\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nmultinom(formula = brand ~ age + sex)\n\nCoefficients:\n  (Intercept)       age    sexmale\n2   -11.25127 0.3682202 -0.5237736\n3   -22.25571 0.6859149 -0.4658215\n\nResidual Deviance: 1405.941 \nAIC: 1417.941 \n```\n\n\n:::\n\n```{.r .cell-code}\nstep(brands.1, trace = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntrying - age \ntrying - sex \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nmultinom(formula = brand ~ age + sex)\n\nCoefficients:\n  (Intercept)       age    sexmale\n2   -11.25127 0.3682202 -0.5237736\n3   -22.25571 0.6859149 -0.4658215\n\nResidual Deviance: 1405.941 \nAIC: 1417.941 \n```\n\n\n:::\n:::\n\n\n\n\n-   Final model contains both `age` and `sex` so neither could be\n    removed.\n\n## Making predictions\n\nFind age 5-number summary, and the two sexes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n brand       sex           age      \n 1:207   female:466   Min.   :24.0  \n 2:307   male  :269   1st Qu.:32.0  \n 3:221                Median :32.0  \n                      Mean   :32.9  \n                      3rd Qu.:34.0  \n                      Max.   :38.0  \n```\n\n\n:::\n:::\n\n\n\n\nSpace the ages out a bit for prediction (see over).\n\n## Combinations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(age = seq(24, 40, 4), # cover the entire range of ages\n                sex = c(\"female\", \"male\"), model = brands.1)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   age    sex rowid\n1   24 female     1\n2   24   male     2\n3   28 female     3\n4   28   male     4\n5   32 female     5\n6   32   male     6\n7   36 female     7\n8   36   male     8\n9   40 female     9\n10  40   male    10\n```\n\n\n:::\n\n```{.r .cell-code}\n# new <- datagrid(age = seq(24, 40, 4), # cover the entire range of ages\n                # model = brands.1)\n```\n:::\n\n\n\n\n## The predictions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(brands.1, newdata = new)) %>%\n  select(group, estimate, age, sex) %>% \n  pivot_wider(names_from = group, values_from = estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 x 5\n     age sex        `1`    `2`     `3`\n   <dbl> <fct>    <dbl>  <dbl>   <dbl>\n 1    24 female 0.915   0.0819 0.00279\n 2    24 male   0.948   0.0502 0.00181\n 3    28 female 0.696   0.271  0.0329 \n 4    28 male   0.793   0.183  0.0236 \n 5    32 female 0.291   0.495  0.214  \n 6    32 male   0.405   0.408  0.187  \n 7    36 female 0.0503  0.374  0.576  \n 8    36 male   0.0795  0.350  0.571  \n 9    40 female 0.00473 0.153  0.842  \n10    40 male   0.00759 0.146  0.847  \n```\n\n\n:::\n:::\n\n\n\n\n## Comments\n\n-   Young males prefer brand 1, but older males prefer brand 3.\n\n-   Females similar, but like brand 1 less and brand 2 more.\n\n-   A clear `brand` effect, but the `sex` effect is less clear.\n\n## Making a plot\n\n-   I thought `plot_predictions` doesn't work as we want, but I was\n    (sort of) wrong about that:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.1, condition = c(\"age\", \"sex\"), \n         type = \"probs\")\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-21-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n## Making it go \n\n-   We have to include `group` in the `condition`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.1, condition = c(\"age\", \"group\"))\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n- This picks the most common `sex` in the data (females).\n- See younger females prefer brand 1, older ones preferring brand 3.\n\n## For each `sex`\n\nIf we add the\nother variable to the *end*, we get facets for `sex`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.1, condition = c(\"age\", \"group\", \"sex\"))\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-23-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nNot actually much difference between males and\nfemales.\n\n## A better graph\n\n- but the male-female difference *was* significant. How?\n- *don't* actually plot the graph, then plot the right things:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.1, condition = c(\"age\", \"brand\", \"sex\"), \n         type = \"probs\", draw = FALSE) %>% \n  ggplot(aes(x = age, y = estimate, colour = group, \n             linetype = sex)) +\n  geom_line() -> g\n```\n:::\n\n\n\n\n\n## The graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-25-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Digesting the plot\n\n-   Brand vs. age: younger people (of both genders) prefer brand 1, but\n    older people (of both genders) prefer brand 3. (Explains significant\n    age effect.)\n\n-   Brand vs. sex: females (solid) like brand 1 less than males\n    (dashed), like brand 2 more (for all ages).\n\n-   Not much brand difference between genders (solid and dashed lines of\n    same colours close), but enough to be significant.\n\n-   Model didn't include interaction, so modelled effect of gender on\n    brand same for each age, modelled effect of age same for each\n    gender. (See also later.)\n\n## Alternative data format\n\nSummarize all people of same brand preference, same sex, same age on one\nline of data file with frequency on end:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 735 x 3\n   brand sex      age\n   <fct> <fct>  <dbl>\n 1 1     male      24\n 2 1     male      26\n 3 1     male      26\n 4 1     female    27\n 5 1     female    27\n 6 3     female    27\n 7 1     male      27\n 8 1     male      27\n 9 1     female    27\n10 1     male      27\n# i 725 more rows\n```\n\n\n:::\n:::\n\n\n\n\n```         \n1 0 24 1\n1 0 26 2\n1 0 27 4\n1 0 28 4\n1 0 29 7\n1 0 30 3\n...\n```\n\nWhole data set in 65 lines not 735! But how?\n\n## Getting alternative data format\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref %>%\n  group_by(age, sex, brand) %>%\n  summarize(Freq = n()) %>%\n  ungroup() -> b\nb\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 65 x 4\n     age sex    brand  Freq\n   <dbl> <fct>  <fct> <int>\n 1    24 male   1         1\n 2    26 male   1         2\n 3    27 female 1         4\n 4    27 female 3         1\n 5    27 male   1         4\n 6    28 female 1         6\n 7    28 female 2         2\n 8    28 female 3         1\n 9    28 male   1         4\n10    28 male   3         2\n# i 55 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Fitting models, almost the same\n\n-   Just have to remember `weights` to incorporate frequencies.\n\n-   Otherwise `multinom` assumes you have just 1 obs on each line!\n\n-   Again turn (numerical) `sex` and `brand` into factors:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb %>%\n  mutate(sex = factor(sex)) %>%\n  mutate(brand = factor(brand)) -> bf\nb.1 <- multinom(brand ~ age + sex, data = bf, weights = Freq)\nb.2 <- multinom(brand ~ age, data = bf, weights = Freq)\n```\n:::\n\n\n\n\n## P-value for `sex` identical\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(b.2, b.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       age       126   1413.593                      \n2 age + sex       124   1405.941 1 vs 2     2 7.651236\n     Pr(Chi)\n1           \n2 0.02180496\n```\n\n\n:::\n:::\n\n\n\n\nSame P-value as before, so we haven't changed anything important.\n\n## Trying interaction between age and gender\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbrands.4 <- update(brands.1, . ~ . + age:sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# weights:  15 (8 variable)\ninitial  value 807.480032 \niter  10 value 703.191146\niter  20 value 702.572260\niter  30 value 702.570900\niter  30 value 702.570893\niter  30 value 702.570893\nfinal  value 702.570893 \nconverged\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(brands.1, brands.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n                Model Resid. df Resid. Dev   Test    Df\n1           age + sex      1464   1405.941             \n2 age + sex + age:sex      1462   1405.142 1 vs 2     2\n   LR stat.   Pr(Chi)\n1                    \n2 0.7996223 0.6704466\n```\n\n\n:::\n:::\n\n\n\n\n-   No evidence that effect of age on brand preference differs for the\n    two genders.\n\n## Make graph again\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.4, condition = c(\"age\", \"brand\", \"sex\"), \n         type = \"probs\", draw = FALSE)  %>% \n  ggplot(aes(x = age, y = estimate, colour = group, \n             linetype = sex)) +\n  geom_line() -> g4\n```\n:::\n\n\n\n\n## Not much difference in the graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng4\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-28-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Compare model without interaction\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-29-1.pdf){fig-pos='H'}\n:::\n:::\n",
    "supporting": [
      "logistic_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}