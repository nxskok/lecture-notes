{
  "hash": "7c4489538183816e4ac84eb9790d7b3b",
  "result": {
    "markdown": "---\ntitle: \"Analysis of variance revisited\"\n---\n\n\n\n\n\n## Analysis of variance \n\n\n* Analysis of variance used with: \n\n\n  * counted/measured response\n\n  * categorical explanatory variable(s)\n\n  * that is, data divided into groups, and see if response significantly different among groups\n\n  * or, see whether knowing group membership helps to predict response.\n\n\n## Two stages\n\n* Typically two stages: \n\n\n  * $F$-test to detect *any* differences among/due to groups\n\n  * if $F$-test significant, do *multiple comparisons* to see which groups significantly different from which.\n\n* Need special multiple comparisons method because just doing (say) two-sample $t$-tests on each pair of groups gives too big a chance of finding \"significant\" differences by accident.\n\n\n\n\n## Packages\nThese: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(car) # for Levene's text\n```\n:::\n\n\n\n   \n\n\n## Example: Pain threshold and hair colour\n\n\n* Do people with different hair colour have different abilities\nto deal with pain?\n\n* Men and women of various ages divided into 4 groups by hair\ncolour: light and dark blond, light and dark brown.\n\n* Each subject given a pain sensitivity test resulting in pain\nthreshold score: higher score is higher pain tolerance.\n\n* 19 subjects altogether.\n\n\n\n\n## The data \nIn `hairpain.txt` (some):\n\n![](Screenshot_2023-08-10_11-37-10.png)\n\n\n\n\n## Summarizing the groups \n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/hairpain.txt\"\nhairpain <- read_delim(my_url, \" \")\nhairpain %>%\n  group_by(hair) %>%\n  summarize(\n    n = n(),\n    xbar = mean(pain),\n    s = sd(pain)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 4\n  hair           n  xbar     s\n  <chr>      <int> <dbl> <dbl>\n1 darkblond      5  51.2  9.28\n2 darkbrown      5  37.4  8.32\n3 lightblond     5  59.2  8.53\n4 lightbrown     4  42.5  5.45\n```\n:::\n:::\n\n\n\\normalsize\n\n\n\nBrown-haired people seem to have lower pain tolerance.\n\n\n## Boxplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(hairpain, aes(x = hair, y = pain)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/tartuffo-1.pdf)\n:::\n:::\n\n\n\n   \n\n\n## Assumptions\n\n\n* Data should be:\n\n\n  * normally distributed within each group\n\n  * same spread for each group\n\n\n* `darkbrown` group has upper outlier (suggests not normal)\n\n* `darkblond` group has smaller IQR than other groups.\n\n* But, groups *small*.\n\n* Shrug shoulders and continue for moment. \n\n\n\n## Testing equality of SDs\n\n\n*   via **Levene's test** in package `car`:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleveneTest(pain ~ hair, data = hairpain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  3  0.3927   0.76\n      15               \n```\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n\n* No evidence (at all) of difference among group SDs.\n\n* Possibly because groups *small*.\n\n\n\n## Analysis of variance\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhairpain.1 <- aov(pain ~ hair, data = hairpain)\nsummary(hairpain.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nhair         3   1361   453.6   6.791 0.00411 **\nResiduals   15   1002    66.8                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n\n\n* P-value small: the mean pain tolerances for the four groups are\n*not* all the same.\n\n* Which groups differ from which, and how?\n\n\n## Multiple comparisons\n\n\n* Which groups differ from which? Multiple\ncomparisons method. Lots.\n\n* Problem: by comparing all the groups with each other, doing\nmany tests, have large chance to (possibly incorrectly) reject\n$H_0:$ groups have equal means.\n\n* 4 groups: 6 comparisons (1 vs 2, 1 vs 3, \\ldots, 3 vs 4). 5 groups: 10\ncomparisons. Thus 6 (or 10) chances to make mistake.\n\n* Get \"familywise error rate\" of 0.05 (whatever), no\nmatter how many comparisons youâ€™re doing.\n\n* My favourite: Tukey, or \"honestly\nsignificant differences\": how far apart might largest, smallest\ngroup means be (if actually no differences). Group means more\ndifferent: significantly different.\n\n\n\n## Tukey\n\n\n* `TukeyHSD:`\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(hairpain.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = pain ~ hair, data = hairpain)\n\n$hair\n                       diff        lwr        upr     p adj\ndarkbrown-darkblond   -13.8 -28.696741  1.0967407 0.0740679\nlightblond-darkblond    8.0  -6.896741 22.8967407 0.4355768\nlightbrown-darkblond   -8.7 -24.500380  7.1003795 0.4147283\nlightblond-darkbrown   21.8   6.903259 36.6967407 0.0037079\nlightbrown-darkbrown    5.1 -10.700380 20.9003795 0.7893211\nlightbrown-lightblond -16.7 -32.500380 -0.8996205 0.0366467\n```\n:::\n:::\n\n\n \n\\normalsize\n\n\n\n## The old-fashioned way\n\n\n* List group means in order\n\n* Draw lines connecting groups that are *not* significantly\ndifferent:\n\n```\ndarkbrown lightbrown  darkblond lightblond\n37.4      42.5       51.2       59.2\n-------------------------\n                     ---------------\n```\n\n\n* `lightblond` significantly higher than everything\nexcept `darkblond` (at $\\alpha=0.05$).\n\n* `darkblond` in middle ground: not significantly less\nthan `lightblond`, not significantly greater than\n`darkbrown` and `lightbrown`.\n\n* More data might resolve this.\n\n* Looks as if blond-haired people do have higher pain tolerance,\nbut not completely clear.\n\n\n## Some other multiple-comparison methods\n\n\n* Work any time you do $k$ tests at once (not just ANOVA).\n\n  * **Bonferroni**: multiply all P-values by $k$.\n\n  * **Holm**: multiply smallest P-value by $k$, next-smallest by\n$k-1$, etc.\n\n  * **False discovery rate**: multiply smallest P-value by $k/1$,\n2nd-smallest by $k/2$, \\ldots, $i$-th smallest by $k/i$.\n\n* Stop after non-rejection.\n\n\n\n## Example\n\n\n* P-values 0.005, 0.015, 0.03, 0.06 (4 tests all done at once)\nUse $\\alpha=0.05$.\n\n\n* Bonferroni: \n\n\n  * Multiply all P-values by 4 (4 tests).\n\n  * Reject only 1st null.\n\n\n\n* Holm: \n\n\n  * Times smallest P-value by 4: $0.005*4=0.020<0.05$, reject.\n\n  * Times next smallest by 3: $0.015*3=0.045<0.05$, reject.\n\n  * Times next smallest by 2: $0.03*2=0.06>0.05$, do not reject. Stop.\n\n\n\n\n\n## \\ldots Continued\n\n\n* With P-values 0.005, 0.015, 0.03, 0.06:\n\n* False discovery rate:\n\n\n  * Times smallest P-value by 4: $0.005*4=0.02<0.05$: reject.\n\n  * Times second smallest by $4/2$: $0.015*4/2=0.03<0.05$, reject.\n\n  * Times third smallest by $4/3$: $0.03*4/3=0.04<0.05$, reject.\n\n  * Times fourth smallest by $4/4$: $0.06*4/4=0.06>0.05$, do not reject. Stop. \n\n\n\n\n## `pairwise.t.test`\n\n\\tiny\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(hairpain, pairwise.t.test(pain, hair, p.adj = \"none\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  pain and hair \n\n           darkblond darkbrown lightblond\ndarkbrown  0.01748   -         -         \nlightblond 0.14251   0.00075   -         \nlightbrown 0.13337   0.36695   0.00817   \n\nP value adjustment method: none \n```\n:::\n\n```{.r .cell-code}\nwith(hairpain, pairwise.t.test(pain, hair, p.adj = \"holm\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  pain and hair \n\n           darkblond darkbrown lightblond\ndarkbrown  0.0699    -         -         \nlightblond 0.4001    0.0045    -         \nlightbrown 0.4001    0.4001    0.0408    \n\nP value adjustment method: holm \n```\n:::\n:::\n\n\n\\normalsize\n\n## `pairwise.t.test` part 2 \n\n\\tiny\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(hairpain, pairwise.t.test(pain, hair, p.adj = \"fdr\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  pain and hair \n\n           darkblond darkbrown lightblond\ndarkbrown  0.0350    -         -         \nlightblond 0.1710    0.0045    -         \nlightbrown 0.1710    0.3670    0.0245    \n\nP value adjustment method: fdr \n```\n:::\n\n```{.r .cell-code}\nwith(hairpain, pairwise.t.test(pain, hair, p.adj = \"bon\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  pain and hair \n\n           darkblond darkbrown lightblond\ndarkbrown  0.1049    -         -         \nlightblond 0.8550    0.0045    -         \nlightbrown 0.8002    1.0000    0.0490    \n\nP value adjustment method: bonferroni \n```\n:::\n:::\n\n\n\n\\normalsize \n\n\n## Comments\n\n\n* P-values all adjusted upwards from \"none\".\n\n* Required because 6 tests at once.\n\n* Highest P-values for Bonferroni: most \"conservative\".\n\n* Prefer Tukey or FDR or Holm.\n\n* Tukey only applies to ANOVA, not to other cases of multiple\ntesting. \n\n\n\n## Rats and vitamin B\n\n\n* What is the effect of dietary vitamin B on the kidney?\n\n* A number of rats were randomized to receive either a\nB-supplemented diet or a regular diet.\n\n* Desired to control for initial size of rats, so classified\ninto size classes `lean` and `obese`.\n\n* After 20 weeks, rats' kidneys weighed.\n\n* Variables:\n\n\n  * Response: `kidneyweight` (grams).\n\n  * Explanatory: `diet`, `ratsize`.\n\n\n* Read in data:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/vitaminb.txt\"\nvitaminb <- read_delim(my_url, \" \")\n```\n:::\n\n\n\\normalsize\n     \n\n\n\n## The data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvitaminb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 28 x 3\n   ratsize diet     kidneyweight\n   <chr>   <chr>           <dbl>\n 1 lean    regular          1.62\n 2 lean    regular          1.8 \n 3 lean    regular          1.71\n 4 lean    regular          1.81\n 5 lean    regular          1.47\n 6 lean    regular          1.37\n 7 lean    regular          1.71\n 8 lean    vitaminb         1.51\n 9 lean    vitaminb         1.65\n10 lean    vitaminb         1.45\n# i 18 more rows\n```\n:::\n:::\n\n\n\n   \n\n\n## Grouped boxplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(vitaminb, aes(\n  x = ratsize, y = kidneyweight,\n  fill = diet\n)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-10-1.pdf)\n:::\n:::\n\n\n\n   \n\n\n## What's going on?\n\n\n* Calculate group means: \n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary <- vitaminb %>%\n  group_by(ratsize, diet) %>%\n  summarize(mean = mean(kidneyweight))\nsummary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 3\n# Groups:   ratsize [2]\n  ratsize diet      mean\n  <chr>   <chr>    <dbl>\n1 lean    regular   1.64\n2 lean    vitaminb  1.53\n3 obese   regular   2.64\n4 obese   vitaminb  2.67\n```\n:::\n:::\n\n\n\\normalsize\n   \n\n* Rat size: a large and consistent effect.\n\n* Diet: small/no effect (compare same rat size, different\ndiet).\n\n* Effect of rat size *same* for each diet: no interaction.\n\n\n\n\n## ANOVA with interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvitaminb.1 <- aov(kidneyweight ~ ratsize * diet,\n  data = vitaminb\n)\nsummary(vitaminb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nratsize       1  8.068   8.068 141.179 1.53e-11 ***\ndiet          1  0.012   0.012   0.218    0.645    \nratsize:diet  1  0.036   0.036   0.638    0.432    \nResiduals    24  1.372   0.057                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n   \n\n- Significance/nonsignificance as we expected. \n- Note no significant\ninteraction (can be removed). \n\n\n## Interaction plot\n\n\n* Plot mean of response variable against one of the explanatory, using\nother one as groups. Start from `summary`: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(summary, aes(\n  x = ratsize, y = mean,\n  colour = diet, group = diet\n)) +\n  geom_point() + geom_line()\n```\n:::\n\n\n\n    \n\n\n* For this, have to give *both* `group` and `colour`.\n\n\n\n## The interaction plot \n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-14-1.pdf)\n:::\n:::\n\n\n\n\n\nLines basically parallel, indicating no interaction.\n\n\n## Take out interaction\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvitaminb.2 <- update(vitaminb.1, . ~ . - ratsize:diet)\nsummary(vitaminb.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nratsize      1  8.068   8.068 143.256 7.59e-12 ***\ndiet         1  0.012   0.012   0.221    0.643    \nResiduals   25  1.408   0.056                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n\n\n* No Tukey for `diet`: not significant.\n\n* No Tukey for `ratsize`: only two sizes, and already know\nthat obese rats have larger kidneys than lean ones.\n\n* Bottom line: diet has no effect on kidney size once you control\nfor size of rat.\n\n## Assessing assumptions: residuals\n\n- In two-way ANOVA, not many observations per treatment group.\n- Difficult to check for normality / equal spreads.\n- *But*, any regular ANOVA also a regression.\n- Use regression residual ideas.\n- In ANOVA, one fitted value per treatment group (based on means).\n- Residual: observation minus fitted value.\n\n## Previous ANOVA as regression\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvitaminb.3 <- lm(kidneyweight ~ ratsize + diet, data = vitaminb)\nsummary(vitaminb.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = kidneyweight ~ ratsize + diet, data = vitaminb)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62893 -0.12625  0.04071  0.14607  0.35321 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   1.60536    0.07768   20.67  < 2e-16 ***\nratsizeobese  1.07357    0.08970   11.97 7.59e-12 ***\ndietvitaminb -0.04214    0.08970   -0.47    0.643    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2373 on 25 degrees of freedom\nMultiple R-squared:  0.8516,\tAdjusted R-squared:  0.8397 \nF-statistic: 71.74 on 2 and 25 DF,  p-value: 4.39e-11\n```\n:::\n:::\n\n\n\\normalsize\n\n## Reproduce ANOVA\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  drop1(vitaminb.3, test = \"F\") \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nkidneyweight ~ ratsize + diet\n        Df Sum of Sq    RSS     AIC  F value    Pr(>F)    \n<none>               1.4079 -77.722                       \nratsize  1    8.0679 9.4758 -26.337 143.2563 7.593e-12 ***\ndiet     1    0.0124 1.4204 -79.476   0.2207    0.6425    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\\normalsize\n\n- ANOVA and regression `drop1` output always the same.\n- this time, ANOVA and regression `summary` output have same P-values, but only because categorical variables both have two levels.\n\n\n## Are the residuals normal?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(vitaminb.3, aes(sample=.resid)) + \n  stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-18-1.pdf)\n:::\n:::\n\n\n\n## Residuals against fitted\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(vitaminb.3, aes(x=.fitted, y=.resid)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-19-1.pdf)\n:::\n:::\n\n\n\n## Comments\n\n- 2 rat sizes, 2 diets: only $2 \\times 2 = 4$ different fitted values\n- larger fitted values have greater spread (fan-out, transformation?)\n- add residuals to data to plot residuals against size, diet (`augment` from `broom`):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvitaminb.3 %>% augment(vitaminb) -> vitaminb.3a\n```\n:::\n\n\n\n- explanatory `ratsize`, `diet` categorical, so plot resid vs. them with *boxplots*.\n\n## Residuals vs rat size \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(vitaminb.3a, aes(x = ratsize, y = .resid)) + \n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-21-1.pdf)\n:::\n:::\n\n\n\n## Residuals vs diet\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(vitaminb.3a, aes(x = diet, y = .resid)) + \n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-22-1.pdf)\n:::\n:::\n\n\n\n## Comments\n\n- there are low outliers on the plot against diet\n- residuals for obese rats seem more spread out than for lean rats\n- case for transformation of rat weights\n- however, story from our analysis very clear:\n    - rat size strongly significant\n    - diet nowhere near significant\n- and so expect transformation to make no difference to conclusions.\n\n\n\n## The auto noise data\nIn 1973, the President of Texaco cited an automobile filter\ndeveloped by Associated Octel Company as effective in reducing\npollution. However, questions had been raised about the effects of\nfilter silencing. He referred to the data included in the report\n(and below) as evidence\nthat the silencing properties of the Octel filter were at least\nequal to those of standard silencers. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nu <- \"http://ritsokiguess.site/datafiles/autonoise.txt\"\nautonoise <- read_table(u)\n```\n:::\n\n\n\n \n\n\n## The data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 36 x 4\n   noise size  type  side \n   <dbl> <chr> <chr> <chr>\n 1   840 M     Std   R    \n 2   770 L     Octel L    \n 3   820 M     Octel R    \n 4   775 L     Octel R    \n 5   825 M     Octel L    \n 6   840 M     Std   R    \n 7   845 M     Std   L    \n 8   825 M     Octel L    \n 9   815 M     Octel L    \n10   845 M     Std   R    \n# i 26 more rows\n```\n:::\n:::\n\n\n\n   \n\n\n## Making boxplot\n\n\n* Make a boxplot, but have combinations of filter type and\nengine size.\n\n* Use grouped boxplot again, thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- autonoise %>%\n  ggplot(aes(x = size, y = noise, fill = type)) +\n  geom_boxplot()\n```\n:::\n\n\n\n   \n\n\n\n## The boxplot\n\n* See difference in engine noise between Octel and standard is larger for\nmedium engine size than for large or small.\n\n* Some evidence of differences in spreads (ignore for now):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-26-1.pdf)\n:::\n:::\n\n\n\n   \n\n\n\n\n\n## ANOVA\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise.1 <- aov(noise ~ size * type, data = autonoise)\nsummary(autonoise.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nsize         2  26051   13026 199.119  < 2e-16 ***\ntype         1   1056    1056  16.146 0.000363 ***\nsize:type    2    804     402   6.146 0.005792 ** \nResiduals   30   1963      65                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n\n\n* The interaction is significant, as we suspected from the boxplots.\n\n* The within-group spreads don't look very equal, but only based\non 6 obs each.\n\n\n\n## Tukey: ouch! \n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise.2 <- TukeyHSD(autonoise.1)\nautonoise.2$`size:type`\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       diff        lwr        upr        p adj\nM:Octel-L:Octel  51.6666667  37.463511  65.869823 6.033496e-11\nS:Octel-L:Octel  52.5000000  38.296844  66.703156 4.089762e-11\nL:Std-L:Octel     5.0000000  -9.203156  19.203156 8.890358e-01\nM:Std-L:Octel    75.8333333  61.630177  90.036489 4.962697e-14\nS:Std-L:Octel    55.8333333  41.630177  70.036489 9.002910e-12\nS:Octel-M:Octel   0.8333333 -13.369823  15.036489 9.999720e-01\nL:Std-M:Octel   -46.6666667 -60.869823 -32.463511 6.766649e-10\nM:Std-M:Octel    24.1666667   9.963511  38.369823 1.908995e-04\nS:Std-M:Octel     4.1666667 -10.036489  18.369823 9.454142e-01\nL:Std-S:Octel   -47.5000000 -61.703156 -33.296844 4.477636e-10\nM:Std-S:Octel    23.3333333   9.130177  37.536489 3.129974e-04\nS:Std-S:Octel     3.3333333 -10.869823  17.536489 9.787622e-01\nM:Std-L:Std      70.8333333  56.630177  85.036489 6.583623e-14\nS:Std-L:Std      50.8333333  36.630177  65.036489 8.937329e-11\nS:Std-M:Std     -20.0000000 -34.203156  -5.796844 2.203265e-03\n```\n:::\n:::\n\n\n\n\\normalsize\n\n \n\n\n## Interaction plot\n\n\n* This time, don't have summary of mean noise for each size-type\ncombination. \n\n* One way is to compute summaries (means) first, and feed into\n`ggplot` as in vitamin B example.\n\n* Or, have `ggplot` compute them for us, thus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(autonoise, aes(\n  x = size, y = noise,\n  colour = type, group = type\n)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun = mean, geom = \"line\")\n```\n:::\n\n\n\n     \n\n\n\n## Interaction plot\n\nThe lines are definitely *not* parallel, showing that the effect\nof `type` is different for medium-sized engines than for others:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-30-1.pdf)\n:::\n:::\n\n\n\n\n\n\n\n\n## If you don't like that\\ldots\n\\ldots then compute the means first, in a pipeline: \n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  group_by(size, type) %>%\n  summarize(mean_noise = mean(noise)) %>%\n  ggplot(aes(\n    x = size, y = mean_noise, group = type,\n    colour = type\n  )) + geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-beamer/bAnova-31-1.pdf)\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n## Simple effects for auto noise example\n\n\n* In auto noise example, weren't interested in all comparisons\nbetween car size and filter type combinations.\n\n* Wanted to demonstrate (lack of) difference between filter types\n*for each car type*. \n\n* These are called **simple effects** of one variable\n(filter type)\nconditional on other variable (car type).\n\n* To do this, pull out just the data for small cars, compare\nnoise for the two filter types. Then repeat for medium and large\ncars. (Three one-way ANOVAs.)\n\n\n\n## Do it using `dplyr tools`\n\n\n* Small cars:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"S\") %>%\n  aov(noise ~ type, data = .) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)\ntype         1   33.3   33.33   0.548  0.476\nResiduals   10  608.3   60.83               \n```\n:::\n:::\n\n\n\n     \n\n\n* No filter difference for small cars.\n\n* For Medium, change `S` to `M` and repeat.\n\n\n\n## Simple effect of filter type for medium cars\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"M\") %>%\n  aov(noise ~ type, data = .) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ntype         1 1752.1  1752.1   68.93 8.49e-06 ***\nResiduals   10  254.2    25.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n   \n\\normalsize\n\n\n\n* There *is* an effect of filter type for medium cars. Look\nat means to investigate (over). \n\n## Mean noise for each filter type\n\n\\ldots for medium engine size: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"M\") %>%\n  group_by(type) %>%\n  summarize(m = mean(noise))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  type      m\n  <chr> <dbl>\n1 Octel  822.\n2 Std    846.\n```\n:::\n:::\n\n\n\n* Octel filters produce *less* noise for medium cars.\n   \n\n\n\n## Large cars \n\n\n\n* Large cars:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"L\") %>%\n  aov(noise ~ type, data = .) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)\ntype         1     75      75   0.682  0.428\nResiduals   10   1100     110               \n```\n:::\n:::\n\n\n\n   \n\n\n* No significant difference again. \n\n\n## All at once, using split/apply/combine\n\nThe \"split\" part:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  group_by(size) %>%\n  nest()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 2\n# Groups:   size [3]\n  size  data             \n  <chr> <list>           \n1 M     <tibble [12 x 3]>\n2 L     <tibble [12 x 3]>\n3 S     <tibble [12 x 3]>\n```\n:::\n:::\n\n\n\n   \n\nNow have *three* rows, with the data frame for each size encoded\nas *one element* of this data frame.\n\n\n\n## Apply\n\n\n*   Write function to do `aov` on a\ndata frame with columns `noise` and `type`,\nreturning P-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_pval <- function(x) {\n  noise.1 <- aov(noise ~ type, data = x)\n  gg <- tidy(noise.1)\n  gg$p.value[1]\n}\n```\n:::\n\n\n     \n\n* Test it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"L\") %>%\n  aov_pval()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.428221\n```\n:::\n:::\n\n\n\n   \n\n\n* Check.\n\n\n## Combine\n\n\n* Apply this function to each of the nested data frames (one per\nengine size):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  nest_by(size) %>% \n  rowwise() %>% \n  mutate(p_val = aov_pval(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 3\n# Rowwise: \n  size                data      p_val\n  <chr> <list<tibble[,3]>>      <dbl>\n1 L               [12 x 3] 0.428     \n2 M               [12 x 3] 0.00000849\n3 S               [12 x 3] 0.476     \n```\n:::\n:::\n\n\n\n\n\n## Tidy up\n\n\n* The `data` column was stepping-stone to getting\nanswer. Don't need it any more:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  nest_by(size) %>% \n  rowwise() %>% \n  mutate(p_val = aov_pval(data)) %>% \n  select(-data) -> simple_effects\nsimple_effects\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 2\n# Rowwise: \n  size       p_val\n  <chr>      <dbl>\n1 L     0.428     \n2 M     0.00000849\n3 S     0.476     \n```\n:::\n:::\n\n\n\n\\normalsize\n\n     \n\n\n\n## Simultaneous tests\n\n\n* When testing simple effects, doing several tests at once. (In\nthis case, 3.) Have to adjust P-values for this. Eg.\\ Holm:\n\n\\footnotesize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_effects %>% ungroup() %>% arrange(p_val) %>%\n  mutate(multiplier = 4 - row_number()) %>%\n  mutate(p_val_adj = p_val * multiplier)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  size       p_val multiplier p_val_adj\n  <chr>      <dbl>      <dbl>     <dbl>\n1 M     0.00000849          3 0.0000255\n2 L     0.428               2 0.856    \n3 S     0.476               1 0.476    \n```\n:::\n:::\n\n\n\n\\normalsize\n\n     \n\n\\footnotesize\n\n* No change in rejection decisions.\n\n* Octel filters sig.\\ better in terms of noise for\nmedium cars, and not sig.\\ different for other sizes.\n\n* Octel filters never significantly worse than standard\nones. \n\n\\normalsize\n\n\n\n## Confidence intervals\n\n\n* Perhaps better way of assessing simple effects: look at\n*confidence intervals* rather than tests.\n\n* Gives us sense of accuracy of estimation, and thus whether\nnon-significance might be lack of power: ``absence of evidence is\nnot evidence of absence''.\n\n* Works here because *two* filter types, using\n`t.test` for each engine type.\n\n* Want to show that the Octel filter is equivalent to or better\nthan the standard filter, in terms of engine noise.\n\n\n\n## Equivalence and noninferiority\n\n\n* Known as \"equivalence testing\" in medical world. A good\nread:\n[link](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3019319/). Basic\nidea: decide on size of difference $\\delta$ that would be considered\n\"equivalent\", and if CI entirely inside $\\pm \\delta$, have\nevidence in favour of equivalence.\n\n* We really want to show that the Octel filters are \"no worse\"\nthan the standard one: that is, equivalent *or better* than\nstandard filters.\n\n* Such a \"noninferiority test\" done by checking that\n`upper limit` of CI, new minus old, is *less* than\n$\\delta$. (This requires careful thinking about (i) which way\naround the difference is and (ii) whether a higher or lower value\nis better.)\n\n\n## CI for small cars\nSame idea as for simple effect test:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"S\") %>%\n  t.test(noise ~ type, data = .) %>%\n  pluck(\"conf.int\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -14.517462   7.850795\nattr(,\"conf.level\")\n[1] 0.95\n```\n:::\n:::\n\n\n\n \n\n## CI for medium cars\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"M\") %>%\n  t.test(noise ~ type, data = .) %>%\n  pluck(\"conf.int\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -30.75784 -17.57549\nattr(,\"conf.level\")\n[1] 0.95\n```\n:::\n:::\n\n\n\n \n\n## CI for large cars\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautonoise %>%\n  filter(size == \"L\") %>%\n  t.test(noise ~ type, data = .) %>%\n  pluck(\"conf.int\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -19.270673   9.270673\nattr(,\"conf.level\")\n[1] 0.95\n```\n:::\n:::\n\n\n\n \n\n\n## Or, all at once: split/apply/combine\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci_func <- function(x) {\n  tt <- t.test(noise ~ type, data = x)\n  tt$conf.int\n}\n\nautonoise %>% nest_by(size) %>%\n  rowwise() %>% \n  mutate(ci = list(ci_func(data))) %>%\n  unnest_wider(ci, names_sep = \"_\") -> cis\n```\n:::\n\n\n\n\\normalsize\n\n## Results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncis %>% select(size, starts_with(\"ci\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 3\n  size   ci_1   ci_2\n  <chr> <dbl>  <dbl>\n1 L     -19.3   9.27\n2 M     -30.8 -17.6 \n3 S     -14.5   7.85\n```\n:::\n:::\n\n\n\n## Procedure \n\n* Function to get CI of difference in noise means for types\nof filter on input data frame\n\n* Nest by `size` (mini-df `data` per size)\n\n* Calculate CI for each thing in `data`: CI is two numbers long\n\n* `unnest` `ci` column (wider) to see two numbers\nin each CI.\n\n\n## CIs and noninferiority test\n\n\n* Suppose we decide that a 20 dB difference would be considered\nequivalent. (I have no idea whether that is reasonable.)\n\n* Intervals: \\vspace{2ex} \n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncis %>% select(-data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 3\n  size   ci_1   ci_2\n  <chr> <dbl>  <dbl>\n1 L     -19.3   9.27\n2 M     -30.8 -17.6 \n3 S     -14.5   7.85\n```\n:::\n:::\n\n\n\n\\normalsize\n\n## Comments \n\n* In all cases, upper limit of CI is less than 20 dB. The Octel\nfilters are \"noninferior\" to the standard ones.\n\n* Caution: we did 3 procedures at once again. The true\nconfidence level is not 95\\%. (Won't worry about that here.)\n\n\n\n## Contrasts in ANOVA\n\n\n* Sometimes, don't want to compare *all* groups, only\n*some* of them.\n\n* Might be able to specify these comparisons ahead of time;\nother comparisons of no interest.\n\n* Wasteful to do ANOVA and Tukey.\n\n\n\n## Example: chainsaw kickback\n\n\n* From [link](http://www.ohio.edu/plantbio/staff/mccarthy/quantmet/lectures/ANOVA2.pdf).\n\n* Forest manager concerned about safety of chainsaws issued to\nfield crew. 4 models of chainsaws, measure \"kickback\" (degrees\nof deflection) for 5 of each:\n\n```\n\n A  B  C  D\n-----------\n42 28 57 29\n17 50 45 29\n24 44 48 22\n39 32 41 34\n43 61 54 30\n\n```\n\n\n* So far, standard 1-way ANOVA: what differences are there\namong models?\n\n\n\n## chainsaw kickback (2)\n\n\n* But: models A and D are designed to be used at home, while\nmodels B and C are industrial models.\n\n* Suggests these comparisons of interest:\n\n\n* home vs.\\ industrial\n\n* the two home models A vs.\\ D\n\n* the two industrial models B vs.\\ C.\n\n\n* Don't need to compare *all* the pairs of models.\n\n\n\n## What is a contrast?\n\n\n* Contrast is a linear combination of group means.\n\n* Notation: $\\mu_A$ for (population) mean of group $A$, and so on.\n\n* In example, compare two home models: $H_0: \\mu_A-\\mu_D=0$.\n\n* Compare two industrial models: $H_0: \\mu_B-\\mu_C=0$.\n\n* Compare average of two home models vs.\\ average of two\nindustrial models: $H_0: \\frac{1}{2}(\\mu_A+\\mu_D)-{1\\over\n2}(\\mu_B+\\mu_C)=0$ or $H_0: 0.5\\mu_A-0.5\\mu_B-0.5\\mu_C+0.5\\mu_D=0$.\n\n* Note that coefficients of contrasts add to 0, and right-hand\nside is 0.\n\n\n\n## Contrasts in R\n\n\n* Comparing two home models A and D ($\\mu_A-\\mu_D=0$):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.home <- c(1, 0, 0, -1)\n```\n:::\n\n\n\n     \n\n\n* Comparing two industrial models B and C ($\\mu_B-\\mu_C=0$):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.industrial <- c(0, 1, -1, 0)\n```\n:::\n\n\n\n   \n\n\n* Comparing home average vs.\\ industrial average ($0.5\\mu_A-0.5\\mu_B-0.5\\mu_C+0.5\\mu_D=0$):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.home.ind <- c(0.5, -0.5, -0.5, 0.5)\n```\n:::\n\n\n\n   \n\n\n\n## Orthogonal contrasts\n\n\n* What happens if we multiply the contrast coefficients one by one?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.home * c.industrial\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0 0 0 0\n```\n:::\n\n```{.r .cell-code}\nc.home * c.home.ind\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  0.5  0.0  0.0 -0.5\n```\n:::\n\n```{.r .cell-code}\nc.industrial * c.home.ind\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  0.0 -0.5  0.5  0.0\n```\n:::\n:::\n\n\n\n     \n\n* in each case, the results **add up to zero**. Such\ncontrasts are called **orthogonal**.\n\n\n\n## Orthogonal contrasts (2)\n\n\n* Compare these:\n\n\\normalsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 <- c(1, -1, 0)\nc2 <- c(0, 1, -1)\nsum(c1 * c2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1\n```\n:::\n:::\n\n\n\\normalsize\n \nNot zero, so `c1` and `c2` are *not*\northogonal.\n\n* Orthogonal contrasts are much easier to deal with. \n\n\n* Can use non-orthogonal contrasts, but more trouble \n(beyond us).\n\n\n## Read in data\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"http://ritsokiguess.site/datafiles/chainsaw.txt\"\nchain.wide <- read_table(url)\nchain.wide\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 4\n      A     B     C     D\n  <dbl> <dbl> <dbl> <dbl>\n1    42    28    57    29\n2    17    50    45    29\n3    24    44    48    22\n4    39    32    41    34\n5    43    61    54    30\n```\n:::\n:::\n\n\n\n\\normalsize\n\n   \n\n\n## Tidying\n\nNeed all the kickbacks in *one* column:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchain.wide %>% \n  pivot_longer(A:D, names_to = \"model\", \n               names_ptypes = list(model=factor()), \n               values_to = \"kickback\") -> chain\n```\n:::\n\n\n\n \n\n\n## Starting the analysis (2)\nThe proper data frame:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchain \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 x 2\n   model kickback\n   <fct>    <dbl>\n 1 A           42\n 2 B           28\n 3 C           57\n 4 D           29\n 5 A           17\n 6 B           50\n 7 C           45\n 8 D           29\n 9 A           24\n10 B           44\n11 C           48\n12 D           22\n13 A           39\n14 B           32\n15 C           41\n16 D           34\n17 A           43\n18 B           61\n19 C           54\n20 D           30\n```\n:::\n:::\n\n\n \n\n \n\n\n## Setting up contrasts\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.home, c.industrial, c.home.ind)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     c.home c.industrial c.home.ind\n[1,]      1            0        0.5\n[2,]      0            1       -0.5\n[3,]      0           -1       -0.5\n[4,]     -1            0        0.5\n```\n:::\n\n```{.r .cell-code}\ncontrasts(chain$model) <- m\n```\n:::\n\n\n\n   \n\n\n## ANOVA *as if regression*\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchain.1 <- lm(kickback ~ model, data = chain)\nsummary(chain.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = kickback ~ model, data = chain)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-16.00  -7.10   0.60   6.25  18.00 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         38.450      2.179  17.649 6.52e-12 ***\nmodelc.home          2.100      3.081   0.682  0.50524    \nmodelc.industrial   -3.000      3.081  -0.974  0.34469    \nmodelc.home.ind    -15.100      4.357  -3.466  0.00319 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.743 on 16 degrees of freedom\nMultiple R-squared:  0.4562,\tAdjusted R-squared:  0.3542 \nF-statistic: 4.474 on 3 and 16 DF,  p-value: 0.01833\n```\n:::\n:::\n\n\n\n\\normalsize \n\n\n\n## Conclusions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(chain.1) %>% select(term, p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 2\n  term               p.value\n  <chr>                <dbl>\n1 (Intercept)       6.52e-12\n2 modelc.home       5.05e- 1\n3 modelc.industrial 3.45e- 1\n4 modelc.home.ind   3.19e- 3\n```\n:::\n:::\n\n\n\n     \n\n\n* Two home models not sig.\\ diff.\\ (P-value 0.51)\n\n* Two industrial models not sig.\\ diff.\\ (P-value 0.34)\n\n* Home, industrial\nmodels *are* sig.\\ diff.\\ (P-value 0.0032).\n\n\n\n## Means by model\n\n\n* The means:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchain %>%\n  group_by(model) %>%\n  summarize(mean.kick = mean(kickback)) %>%\n  arrange(desc(mean.kick))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 2\n  model mean.kick\n  <fct>     <dbl>\n1 C          49  \n2 B          43  \n3 A          33  \n4 D          28.8\n```\n:::\n:::\n\n\n\n\\small\n\n* Home models A \\& D have less kickback than industrial ones B \\& C.\n\n* Makes sense because industrial users should get training to cope\nwith additional kickback.\n\n\\normalsize\n \n\n\n",
    "supporting": [
      "anova_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}