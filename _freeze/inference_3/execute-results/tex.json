{
  "hash": "dd6d1f0bf49ea4bcdcd6f17000936083",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The sign test\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(smmr)\n```\n:::\n\n\n\n\n`smmr` is new. See later how to install it.\n\n## Duality between confidence intervals and hypothesis tests\n\n-   Tests and CIs really do the same thing, if you look at them the\n    right way. They are both telling you something about a parameter,\n    and they use same things about data.\n-   To illustrate, some data (two groups):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/duality.txt\"\ntwogroups <- read_delim(my_url,\" \")\n```\n:::\n\n\n\n\n## The data\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwogroups\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 2\n       y group\n   <dbl> <dbl>\n 1    10     1\n 2    11     1\n 3    11     1\n 4    13     1\n 5    13     1\n 6    14     1\n 7    14     1\n 8    15     1\n 9    16     1\n10    13     2\n11    13     2\n12    14     2\n13    17     2\n14    18     2\n15    19     2\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## 95% CI (default)\n\nfor difference in means, group 1 minus group 2:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, data = twogroups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -5.5625675  0.2292342\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## 90% CI\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, data = twogroups, conf.level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n90 percent confidence interval:\n -5.010308 -0.323025\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## Hypothesis test\n\nNull is that difference in means is zero:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, mu=0, data = twogroups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -5.5625675  0.2292342\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## Comparing results\n\nRecall null here is $H_0 : \\mu_1 - \\mu_2 = 0$. P-value 0.0668.\n\n-   95% CI from $-5.6$ to $0.2$, contains $0$.\n-   90% CI from $-5.0$ to $-0.3$, does not contain $0$.\n-   At $\\alpha = 0.05$, would not reject $H_0$ since P-value $> 0.05$.\n-   At $\\alpha = 0.10$, *would* reject $H_0$ since P-value $< 0.10$.\n\n## Test and CI\n\nNot just coincidence. Let $C = 100(1 - \\alpha)$, so C% gives\ncorresponding CI to level-$\\alpha$ test. Then following always true.\n(Symbol $\\iff$ means \"if and only if\".)\n\n| Test decision                         |        | Confidence interval                   |\n|:--------------------------|:---------------:|:--------------------------|\n| Reject $H_0$ at level $\\alpha$        | $\\iff$ | $C\\%$ CI does not contain $H_0$ value |\n| Do not reject $H_0$ at level $\\alpha$ | $\\iff$ | $C\\%$ CI contains $H_0$ value         |\n\nIdea: \"Plausible\" parameter value inside CI, not rejected; \"Implausible\"\nparameter value outside CI, rejected.\n\n## The value of this\n\n-   If you have a test procedure but no corresponding CI:\n-   you make a CI by including all the parameter values that would not\n    be rejected by your test.\n-   Use:\n    -   $\\alpha = 0.01$ for a 99% CI,\n    -   $\\alpha = 0.05$ for a 95% CI,\n    -   $\\alpha = 0.10$ for a 90% CI, and so on.\n\n## Testing for non-normal data\n\n-   The IRS (\"Internal Revenue Service\") is the US authority that deals\n    with taxes (like Revenue Canada).\n-   One of their forms is supposed to take no more than 160 minutes to\n    complete. A citizen's organization claims that it takes people\n    longer than that on average.\n-   Sample of 30 people; time to complete form recorded.\n-   Read in data, and do $t$-test of $H_0 : \\mu = 160$ vs.\n    $H_a : \\mu > 160$.\n-   For reading in, there is only one column, so can pretend it is\n    delimited by anything.\n\n## Read in data\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/irs.txt\"\nirs <- read_csv(my_url)\nirs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 x 1\n    Time\n   <dbl>\n 1    91\n 2    64\n 3   243\n 4   167\n 5   123\n 6    65\n 7    71\n 8   204\n 9   110\n10   178\n# i 20 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Test whether mean is 160 or greater\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(irs, t.test(Time, mu = 160, \n                 alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  Time\nt = 1.8244, df = 29, p-value = 0.03921\nalternative hypothesis: true mean is greater than 160\n95 percent confidence interval:\n 162.8305      Inf\nsample estimates:\nmean of x \n 201.2333 \n```\n\n\n:::\n:::\n\n\n\n\nReject null; mean (for all people to complete form) greater than 160.\n\n## But, look at a graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(irs, aes(x = Time)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-beamer/inference-3-R-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   Skewed to right.\n-   Should look at *median*, not mean.\n\n## The sign test\n\n-   But how to test whether the median is greater than 160?\n-   Idea: if the median really is 160 ($H_0$ true), the sampled values\n    from the population are equally likely to be above or below 160.\n-   If the population median is greater than 160, there will be a lot of\n    sample values greater than 160, not so many less. Idea: test\n    statistic is number of sample values greater than hypothesized\n    median.\n\n## Getting a P-value for sign test 1/3\n\n-   How to decide whether \"unusually many\" sample values are greater\n    than 160? Need a sampling distribution.\n-   If $H_0$ true, pop. median is 160, then each sample value\n    independently equally likely to be above or below 160.\n-   So number of observed values above 160 has binomial distribution\n    with $n = 30$ (number of data values) and $p = 0.5$ (160 is\n    hypothesized to be *median*).\n\n## Getting P-value for sign test 2/3\n\n-   Count values above/below 160:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nirs %>% count(Time > 160)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  `Time > 160`     n\n  <lgl>        <int>\n1 FALSE           13\n2 TRUE            17\n```\n\n\n:::\n:::\n\n\n\n\n-   17 above, 13 below. How unusual is that? Need a *binomial table*.\n\n## Getting P-value for sign test 3/3\n\n-   R function `dbinom` gives the probability of eg. exactly 17\n    successes in a binomial with $n = 30$ and $p = 0.5$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(17, 30, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1115351\n```\n\n\n:::\n:::\n\n\n\n\n-   but we want probability of 17 *or more*, so get all of those, find\n    probability of each, and add them up:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x=17:30) %>% \n  mutate(prob=dbinom(x, 30, 0.5)) %>% \n  summarize(total=sum(prob))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  total\n  <dbl>\n1 0.292\n```\n\n\n:::\n:::\n\n\n\n\n## Aside\n\n- `pbinom` gives the cumulative probability (prob. of less than or equal than the first input):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(17, 30, 0.5) # prob of <= 17\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8192027\n```\n\n\n:::\n:::\n\n\n\n\n- and hence (note first input):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(16, 30, 0.5, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2923324\n```\n\n\n:::\n:::\n\n\n\n\nThis last is $P(X \\ge 17) = P(X > 16)$.\n\n## Using my package `smmr`\n\n-   I wrote a package `smmr` to do the sign test (and some other\n    things). Installation is a bit fiddly:\n    -   Install devtools (once) with\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"devtools\")\n```\n:::\n\n\n\n\n-   then install `smmr` using `devtools` (once):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(devtools)\ninstall_github(\"nxskok/smmr\")\n```\n:::\n\n\n\n\n-   Then load it:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\n```\n:::\n\n\n\n\n## `smmr` for sign test\n\n-   `smmr`'s function `sign_test` needs three inputs: a data frame, a\n    column and a null median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(irs, Time, 160)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$above_below\nbelow above \n   13    17 \n\n$p_values\n  alternative   p_value\n1       lower 0.8192027\n2       upper 0.2923324\n3   two-sided 0.5846647\n```\n\n\n:::\n:::\n\n\n\n\n## Comments (1/4)\n\n-   Testing whether population median *greater than* 160, so want\n    *upper-tail* P-value 0.2923. Same as before.\n-   Also get table of values above and below; this too as we got.\n\n## Comments (2/4)\n\n-   P-values are:\n\n| Test | P-value |\n|:-----|--------:|\n| $t$  |  0.0392 |\n| Sign |  0.2923 |\n\n-   These are very different: we reject a mean of 160 (in favour of the\n    mean being bigger), but clearly *fail* to reject a median of 160 in\n    favour of a bigger one.\n    \n## Comments 3/4\n\n-   Why is that? Obtain mean and median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nirs %>% summarize(mean_time = mean(Time), \n                  median_time = median(Time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 2\n  mean_time median_time\n      <dbl>       <dbl>\n1      201.        172.\n```\n\n\n:::\n:::\n\n\n\n\n## Comments (4/4) {.smaller}\n\n-   The mean is pulled a long way up by the right skew, and is a fair\n    bit bigger than 160.\n-   The median is quite close to 160.\n-   We ought to be trusting the sign test and not the t-test here\n    (median and not mean), and therefore there is no evidence that the\n    \"typical\" time to complete the form is longer than 160 minutes.\n-   Having said that, there are clearly some people who take a lot\n    longer than 160 minutes to complete the form, and the IRS could\n    focus on simplifying its form for these people.\n-   In this example, looking at any kind of average is not really\n    helpful; a better question might be \"do an unacceptably large\n    fraction of people take longer than (say) 300 minutes to complete\n    the form?\": that is, thinking about worst-case rather than\n    average-case.\n\n## Confidence interval for the median\n\n-   The sign test does not naturally come with a confidence interval for\n    the median.\n-   So we use the \"duality\" between test and confidence interval to say:\n    the (95%) confidence interval for the median contains exactly those\n    values of the null median that would not be rejected by the\n    two-sided sign test (at $\\alpha = 0.05$).\n\n## For our data\n\n-   The procedure is to try some values for the null median and see\n    which ones are inside and which outside our CI.\n-   smmr has pval_sign that gets just the 2-sided P-value:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npval_sign(160, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5846647\n```\n\n\n:::\n:::\n\n\n\n\n-   Try a couple of null medians:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npval_sign(200, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3615946\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(300, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001430906\n```\n\n\n:::\n:::\n\n\n\n\n-   So 200 inside the 95% CI and 300 outside.\n\n## Doing a whole bunch\n\n-   Choose our null medians first:\n\n\\small \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(d <- tibble(null_median=seq(100,300,20)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 1\n   null_median\n         <dbl>\n 1         100\n 2         120\n 3         140\n 4         160\n 5         180\n 6         200\n 7         220\n 8         240\n 9         260\n10         280\n11         300\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## ... and then\n\n\"for each null median, run the function `pval_sign` for that null median\nand get the P-value\":\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rowwise() %>% \n  mutate(p_value = pval_sign(null_median, irs, Time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 2\n# Rowwise: \n   null_median  p_value\n         <dbl>    <dbl>\n 1         100 0.000325\n 2         120 0.0987  \n 3         140 0.200   \n 4         160 0.585   \n 5         180 0.856   \n 6         200 0.362   \n 7         220 0.0428  \n 8         240 0.0161  \n 9         260 0.00522 \n10         280 0.00143 \n11         300 0.00143 \n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Make it easier for ourselves\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rowwise() %>% \n  mutate(p_value = pval_sign(null_median, irs, Time)) %>% \n  mutate(in_out = ifelse(p_value > 0.05, \"inside\", \"outside\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 x 3\n# Rowwise: \n   null_median  p_value in_out \n         <dbl>    <dbl> <chr>  \n 1         100 0.000325 outside\n 2         120 0.0987   inside \n 3         140 0.200    inside \n 4         160 0.585    inside \n 5         180 0.856    inside \n 6         200 0.362    inside \n 7         220 0.0428   outside\n 8         240 0.0161   outside\n 9         260 0.00522  outside\n10         280 0.00143  outside\n11         300 0.00143  outside\n```\n\n\n:::\n:::\n\n\n\n\n\\normalsize\n\n## confidence interval for median?\n\n-   95% CI to this accuracy from 120 to 200.\n-   Can get it more accurately by looking more closely in intervals from\n    100 to 120, and from 200 to 220.\n\n## A more efficient way: bisection\n\n-   Know that top end of CI between 200 and 220:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- 200 \nhi <- 220\n```\n:::\n\n\n\n\n-   Try the value halfway between: is it inside or outside?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntry <- (lo + hi) / 2\ntry\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(try,irs,Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09873715\n```\n\n\n:::\n:::\n\n\n\n\n-   Inside, so upper end is between 210 and 220. Repeat (over):\n\n## ... bisection continued\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- try\ntry <- (lo + hi) / 2\ntry\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 215\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(try, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06142835\n```\n\n\n:::\n:::\n\n\n\n\n-   215 is inside too, so upper end between 215 and 220.\n-   Continue until have as accurate a result as you want.\n\n## Bisection automatically\n\n-   A loop, but not a `for` since we don't know how many times we're\n    going around. Keep going `while` a condition is true:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo = 200\nhi = 220\nwhile (hi - lo > 1) {\n  try = (hi + lo) / 2\n  ptry = pval_sign(try, irs, Time)\n  print(c(try, ptry))\n  if (ptry <= 0.05)\n    hi = try\n  else\n    lo = try\n}\n```\n:::\n\n\n\n\n## The output from this loop\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.00000000   0.09873715\n[1] 215.00000000   0.06142835\n[1] 217.50000000   0.04277395\n[1] 216.25000000   0.04277395\n[1] 215.62500000   0.04277395\n```\n\n\n:::\n:::\n\n\n\n\n-   215 inside, 215.625 outside. Upper end of interval to this accuracy\n    is 215.\n\n## Using smmr\n\n-   `smmr` has function `ci_median` that does this (by default 95% CI):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 119.0065 214.9955\n```\n\n\n:::\n:::\n\n\n\n\n-   Uses a more accurate bisection than we did.\n-   Or get, say, 90% CI for median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(irs, Time, conf.level=0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 123.0031 208.9960\n```\n\n\n:::\n:::\n\n\n\n\n-   90% CI is shorter, as it should be.\n\n## Bootstrap\n\n-   but, was the sample size (30) big enough to overcome the skewness?\n-   Bootstrap, again:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(x=my_mean)) + geom_histogram(bins=10) -> g\n```\n:::\n\n\n\n\n## With normal quantile plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:10000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(sample = my_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-beamer/inference-3-R-29a-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n## The sampling distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-beamer/inference-3-R-30-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Comments\n\n-   A little skewed to right, but not nearly as much as I was expecting.\n-   The $t$-test for the mean might actually be OK for these data, *if\n    the mean is what you want*.\n-   In actual data, mean and median very different; we chose to make\n    inference about the median.\n-   Thus for us it was right to use the sign test.\n",
    "supporting": [
      "inference_3_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}