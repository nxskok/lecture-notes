{
  "hash": "dd6d1f0bf49ea4bcdcd6f17000936083",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The sign test\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(smmr)\n```\n:::\n\n\n\n\n`smmr` is new. See later how to install it.\n\n## Duality between confidence intervals and hypothesis tests\n\n-   Tests and CIs really do the same thing, if you look at them the\n    right way. They are both telling you something about a parameter,\n    and they use same things about data.\n-   To illustrate, some data (two groups):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/duality.txt\"\ntwogroups <- read_delim(my_url,\" \")\n```\n:::\n\n\n\n\n## The data\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwogroups\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"y\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"group\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"10\",\"2\":\"1\"},{\"1\":\"11\",\"2\":\"1\"},{\"1\":\"11\",\"2\":\"1\"},{\"1\":\"13\",\"2\":\"1\"},{\"1\":\"13\",\"2\":\"1\"},{\"1\":\"14\",\"2\":\"1\"},{\"1\":\"14\",\"2\":\"1\"},{\"1\":\"15\",\"2\":\"1\"},{\"1\":\"16\",\"2\":\"1\"},{\"1\":\"13\",\"2\":\"2\"},{\"1\":\"13\",\"2\":\"2\"},{\"1\":\"14\",\"2\":\"2\"},{\"1\":\"17\",\"2\":\"2\"},{\"1\":\"18\",\"2\":\"2\"},{\"1\":\"19\",\"2\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\\normalsize\n\n## 95% CI (default)\n\nfor difference in means, group 1 minus group 2:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, data = twogroups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -5.5625675  0.2292342\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## 90% CI\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, data = twogroups, conf.level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n90 percent confidence interval:\n -5.010308 -0.323025\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## Hypothesis test\n\nNull is that difference in means is zero:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(y ~ group, mu=0, data = twogroups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  y by group\nt = -2.0937, df = 8.7104, p-value = 0.0668\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -5.5625675  0.2292342\nsample estimates:\nmean in group 1 mean in group 2 \n       13.00000        15.66667 \n```\n\n\n:::\n:::\n\n\n\n\n## Comparing results\n\nRecall null here is $H_0 : \\mu_1 - \\mu_2 = 0$. P-value 0.0668.\n\n-   95% CI from $-5.6$ to $0.2$, contains $0$.\n-   90% CI from $-5.0$ to $-0.3$, does not contain $0$.\n-   At $\\alpha = 0.05$, would not reject $H_0$ since P-value $> 0.05$.\n-   At $\\alpha = 0.10$, *would* reject $H_0$ since P-value $< 0.10$.\n\n## Test and CI\n\nNot just coincidence. Let $C = 100(1 - \\alpha)$, so C% gives\ncorresponding CI to level-$\\alpha$ test. Then following always true.\n(Symbol $\\iff$ means \"if and only if\".)\n\n| Test decision                         |        | Confidence interval                   |\n|:--------------------------|:---------------:|:--------------------------|\n| Reject $H_0$ at level $\\alpha$        | $\\iff$ | $C\\%$ CI does not contain $H_0$ value |\n| Do not reject $H_0$ at level $\\alpha$ | $\\iff$ | $C\\%$ CI contains $H_0$ value         |\n\nIdea: \"Plausible\" parameter value inside CI, not rejected; \"Implausible\"\nparameter value outside CI, rejected.\n\n## The value of this\n\n-   If you have a test procedure but no corresponding CI:\n-   you make a CI by including all the parameter values that would not\n    be rejected by your test.\n-   Use:\n    -   $\\alpha = 0.01$ for a 99% CI,\n    -   $\\alpha = 0.05$ for a 95% CI,\n    -   $\\alpha = 0.10$ for a 90% CI, and so on.\n\n## Testing for non-normal data\n\n-   The IRS (\"Internal Revenue Service\") is the US authority that deals\n    with taxes (like Revenue Canada).\n-   One of their forms is supposed to take no more than 160 minutes to\n    complete. A citizen's organization claims that it takes people\n    longer than that on average.\n-   Sample of 30 people; time to complete form recorded.\n-   Read in data, and do $t$-test of $H_0 : \\mu = 160$ vs.\n    $H_a : \\mu > 160$.\n-   For reading in, there is only one column, so can pretend it is\n    delimited by anything.\n\n## Read in data\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/irs.txt\"\nirs <- read_csv(my_url)\nirs\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Time\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"91\"},{\"1\":\"64\"},{\"1\":\"243\"},{\"1\":\"167\"},{\"1\":\"123\"},{\"1\":\"65\"},{\"1\":\"71\"},{\"1\":\"204\"},{\"1\":\"110\"},{\"1\":\"178\"},{\"1\":\"264\"},{\"1\":\"119\"},{\"1\":\"112\"},{\"1\":\"142\"},{\"1\":\"451\"},{\"1\":\"474\"},{\"1\":\"209\"},{\"1\":\"104\"},{\"1\":\"84\"},{\"1\":\"302\"},{\"1\":\"527\"},{\"1\":\"303\"},{\"1\":\"228\"},{\"1\":\"391\"},{\"1\":\"215\"},{\"1\":\"188\"},{\"1\":\"150\"},{\"1\":\"102\"},{\"1\":\"162\"},{\"1\":\"194\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Test whether mean is 160 or greater\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(irs, t.test(Time, mu = 160, \n                 alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  Time\nt = 1.8244, df = 29, p-value = 0.03921\nalternative hypothesis: true mean is greater than 160\n95 percent confidence interval:\n 162.8305      Inf\nsample estimates:\nmean of x \n 201.2333 \n```\n\n\n:::\n:::\n\n\n\n\nReject null; mean (for all people to complete form) greater than 160.\n\n## But, look at a graph\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(irs, aes(x = Time)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-revealjs/inference-3-R-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Comments\n\n-   Skewed to right.\n-   Should look at *median*, not mean.\n\n## The sign test\n\n-   But how to test whether the median is greater than 160?\n-   Idea: if the median really is 160 ($H_0$ true), the sampled values\n    from the population are equally likely to be above or below 160.\n-   If the population median is greater than 160, there will be a lot of\n    sample values greater than 160, not so many less. Idea: test\n    statistic is number of sample values greater than hypothesized\n    median.\n\n## Getting a P-value for sign test 1/3\n\n-   How to decide whether \"unusually many\" sample values are greater\n    than 160? Need a sampling distribution.\n-   If $H_0$ true, pop. median is 160, then each sample value\n    independently equally likely to be above or below 160.\n-   So number of observed values above 160 has binomial distribution\n    with $n = 30$ (number of data values) and $p = 0.5$ (160 is\n    hypothesized to be *median*).\n\n## Getting P-value for sign test 2/3\n\n-   Count values above/below 160:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nirs %>% count(Time > 160)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Time > 160\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"13\"},{\"1\":\"TRUE\",\"2\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n-   17 above, 13 below. How unusual is that? Need a *binomial table*.\n\n## Getting P-value for sign test 3/3\n\n-   R function `dbinom` gives the probability of eg. exactly 17\n    successes in a binomial with $n = 30$ and $p = 0.5$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(17, 30, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1115351\n```\n\n\n:::\n:::\n\n\n\n\n-   but we want probability of 17 *or more*, so get all of those, find\n    probability of each, and add them up:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x=17:30) %>% \n  mutate(prob=dbinom(x, 30, 0.5)) %>% \n  summarize(total=sum(prob))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"total\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.2923324\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Aside\n\n- `pbinom` gives the cumulative probability (prob. of less than or equal than the first input):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(17, 30, 0.5) # prob of <= 17\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8192027\n```\n\n\n:::\n:::\n\n\n\n\n- and hence (note first input):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(16, 30, 0.5, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2923324\n```\n\n\n:::\n:::\n\n\n\n\nThis last is $P(X \\ge 17) = P(X > 16)$.\n\n## Using my package `smmr`\n\n-   I wrote a package `smmr` to do the sign test (and some other\n    things). Installation is a bit fiddly:\n    -   Install devtools (once) with\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"devtools\")\n```\n:::\n\n\n\n\n-   then install `smmr` using `devtools` (once):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(devtools)\ninstall_github(\"nxskok/smmr\")\n```\n:::\n\n\n\n\n-   Then load it:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\n```\n:::\n\n\n\n\n## `smmr` for sign test\n\n-   `smmr`'s function `sign_test` needs three inputs: a data frame, a\n    column and a null median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(irs, Time, 160)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$above_below\nbelow above \n   13    17 \n\n$p_values\n  alternative   p_value\n1       lower 0.8192027\n2       upper 0.2923324\n3   two-sided 0.5846647\n```\n\n\n:::\n:::\n\n\n\n\n## Comments (1/4)\n\n-   Testing whether population median *greater than* 160, so want\n    *upper-tail* P-value 0.2923. Same as before.\n-   Also get table of values above and below; this too as we got.\n\n## Comments (2/4)\n\n-   P-values are:\n\n| Test | P-value |\n|:-----|--------:|\n| $t$  |  0.0392 |\n| Sign |  0.2923 |\n\n-   These are very different: we reject a mean of 160 (in favour of the\n    mean being bigger), but clearly *fail* to reject a median of 160 in\n    favour of a bigger one.\n    \n## Comments 3/4\n\n-   Why is that? Obtain mean and median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nirs %>% summarize(mean_time = mean(Time), \n                  median_time = median(Time))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean_time\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"median_time\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"201.2333\",\"2\":\"172.5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Comments (4/4) {.smaller}\n\n-   The mean is pulled a long way up by the right skew, and is a fair\n    bit bigger than 160.\n-   The median is quite close to 160.\n-   We ought to be trusting the sign test and not the t-test here\n    (median and not mean), and therefore there is no evidence that the\n    \"typical\" time to complete the form is longer than 160 minutes.\n-   Having said that, there are clearly some people who take a lot\n    longer than 160 minutes to complete the form, and the IRS could\n    focus on simplifying its form for these people.\n-   In this example, looking at any kind of average is not really\n    helpful; a better question might be \"do an unacceptably large\n    fraction of people take longer than (say) 300 minutes to complete\n    the form?\": that is, thinking about worst-case rather than\n    average-case.\n\n## Confidence interval for the median\n\n-   The sign test does not naturally come with a confidence interval for\n    the median.\n-   So we use the \"duality\" between test and confidence interval to say:\n    the (95%) confidence interval for the median contains exactly those\n    values of the null median that would not be rejected by the\n    two-sided sign test (at $\\alpha = 0.05$).\n\n## For our data\n\n-   The procedure is to try some values for the null median and see\n    which ones are inside and which outside our CI.\n-   smmr has pval_sign that gets just the 2-sided P-value:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npval_sign(160, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5846647\n```\n\n\n:::\n:::\n\n\n\n\n-   Try a couple of null medians:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npval_sign(200, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3615946\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(300, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001430906\n```\n\n\n:::\n:::\n\n\n\n\n-   So 200 inside the 95% CI and 300 outside.\n\n## Doing a whole bunch\n\n-   Choose our null medians first:\n\n\\small \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(d <- tibble(null_median=seq(100,300,20)))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"null_median\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"100\"},{\"1\":\"120\"},{\"1\":\"140\"},{\"1\":\"160\"},{\"1\":\"180\"},{\"1\":\"200\"},{\"1\":\"220\"},{\"1\":\"240\"},{\"1\":\"260\"},{\"1\":\"280\"},{\"1\":\"300\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\\normalsize\n\n## ... and then\n\n\"for each null median, run the function `pval_sign` for that null median\nand get the P-value\":\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rowwise() %>% \n  mutate(p_value = pval_sign(null_median, irs, Time))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"null_median\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p_value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"100\",\"2\":\"0.0003249142\"},{\"1\":\"120\",\"2\":\"0.0987371467\"},{\"1\":\"140\",\"2\":\"0.2004884221\"},{\"1\":\"160\",\"2\":\"0.5846647117\"},{\"1\":\"180\",\"2\":\"0.8555355519\"},{\"1\":\"200\",\"2\":\"0.3615946081\"},{\"1\":\"220\",\"2\":\"0.0427739453\"},{\"1\":\"240\",\"2\":\"0.0161248017\"},{\"1\":\"260\",\"2\":\"0.0052228794\"},{\"1\":\"280\",\"2\":\"0.0014309064\"},{\"1\":\"300\",\"2\":\"0.0014309064\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\\normalsize\n\n## Make it easier for ourselves\n\n\\footnotesize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rowwise() %>% \n  mutate(p_value = pval_sign(null_median, irs, Time)) %>% \n  mutate(in_out = ifelse(p_value > 0.05, \"inside\", \"outside\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"null_median\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p_value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"in_out\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"100\",\"2\":\"0.0003249142\",\"3\":\"outside\"},{\"1\":\"120\",\"2\":\"0.0987371467\",\"3\":\"inside\"},{\"1\":\"140\",\"2\":\"0.2004884221\",\"3\":\"inside\"},{\"1\":\"160\",\"2\":\"0.5846647117\",\"3\":\"inside\"},{\"1\":\"180\",\"2\":\"0.8555355519\",\"3\":\"inside\"},{\"1\":\"200\",\"2\":\"0.3615946081\",\"3\":\"inside\"},{\"1\":\"220\",\"2\":\"0.0427739453\",\"3\":\"outside\"},{\"1\":\"240\",\"2\":\"0.0161248017\",\"3\":\"outside\"},{\"1\":\"260\",\"2\":\"0.0052228794\",\"3\":\"outside\"},{\"1\":\"280\",\"2\":\"0.0014309064\",\"3\":\"outside\"},{\"1\":\"300\",\"2\":\"0.0014309064\",\"3\":\"outside\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\\normalsize\n\n## confidence interval for median?\n\n-   95% CI to this accuracy from 120 to 200.\n-   Can get it more accurately by looking more closely in intervals from\n    100 to 120, and from 200 to 220.\n\n## A more efficient way: bisection\n\n-   Know that top end of CI between 200 and 220:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- 200 \nhi <- 220\n```\n:::\n\n\n\n\n-   Try the value halfway between: is it inside or outside?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntry <- (lo + hi) / 2\ntry\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(try,irs,Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09873715\n```\n\n\n:::\n:::\n\n\n\n\n-   Inside, so upper end is between 210 and 220. Repeat (over):\n\n## ... bisection continued\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- try\ntry <- (lo + hi) / 2\ntry\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 215\n```\n\n\n:::\n\n```{.r .cell-code}\npval_sign(try, irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06142835\n```\n\n\n:::\n:::\n\n\n\n\n-   215 is inside too, so upper end between 215 and 220.\n-   Continue until have as accurate a result as you want.\n\n## Bisection automatically\n\n-   A loop, but not a `for` since we don't know how many times we're\n    going around. Keep going `while` a condition is true:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlo = 200\nhi = 220\nwhile (hi - lo > 1) {\n  try = (hi + lo) / 2\n  ptry = pval_sign(try, irs, Time)\n  print(c(try, ptry))\n  if (ptry <= 0.05)\n    hi = try\n  else\n    lo = try\n}\n```\n:::\n\n\n\n\n## The output from this loop\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.00000000   0.09873715\n[1] 215.00000000   0.06142835\n[1] 217.50000000   0.04277395\n[1] 216.25000000   0.04277395\n[1] 215.62500000   0.04277395\n```\n\n\n:::\n:::\n\n\n\n\n-   215 inside, 215.625 outside. Upper end of interval to this accuracy\n    is 215.\n\n## Using smmr\n\n-   `smmr` has function `ci_median` that does this (by default 95% CI):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 119.0065 214.9955\n```\n\n\n:::\n:::\n\n\n\n\n-   Uses a more accurate bisection than we did.\n-   Or get, say, 90% CI for median:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(irs, Time, conf.level=0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 123.0031 208.9960\n```\n\n\n:::\n:::\n\n\n\n\n-   90% CI is shorter, as it should be.\n\n## Bootstrap\n\n-   but, was the sample size (30) big enough to overcome the skewness?\n-   Bootstrap, again:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(x=my_mean)) + geom_histogram(bins=10) -> g\n```\n:::\n\n\n\n\n## With normal quantile plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:10000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(sample = my_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-revealjs/inference-3-R-29a-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## The sampling distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](inference_3_files/figure-revealjs/inference-3-R-30-1.png){width=960}\n:::\n:::\n\n\n\n\n## Comments\n\n-   A little skewed to right, but not nearly as much as I was expecting.\n-   The $t$-test for the mean might actually be OK for these data, *if\n    the mean is what you want*.\n-   In actual data, mean and median very different; we chose to make\n    inference about the median.\n-   Thus for us it was right to use the sign test.\n",
    "supporting": [
      "inference_3_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"inference_3_files/libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"inference_3_files/libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}